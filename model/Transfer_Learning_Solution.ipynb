{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Most of the time you won't want to train a whole convolutional network yourself. Modern ConvNets training on huge datasets like ImageNet take weeks on multiple GPUs. Instead, most people use a pretrained network either as a fixed feature extractor, or as an initial network to fine tune. In this notebook, you'll be using [VGGNet](https://arxiv.org/pdf/1409.1556.pdf) trained on the [ImageNet dataset](http://www.image-net.org/) as a feature extractor. Below is a diagram of the VGGNet architecture.\n",
    "\n",
    "<img src=\"assets/cnnarchitecture.jpg\" width=700px>\n",
    "\n",
    "VGGNet is great because it's simple and has great performance, coming in second in the ImageNet competition. The idea here is that we keep all the convolutional layers, but replace the final fully connected layers with our own classifier. This way we can use VGGNet as a feature extractor for our images then easily train a simple classifier on top of that. What we'll do is take the first fully connected layer with 4096 units, including thresholding with ReLUs. We can use those values as a code for each image, then build a classifier on top of those codes.\n",
    "\n",
    "You can read more about transfer learning from [the CS231n course notes](http://cs231n.github.io/transfer-learning/#tf).\n",
    "\n",
    "## Pretrained VGGNet\n",
    "\n",
    "We'll be using a pretrained network from https://github.com/machrisaa/tensorflow-vgg. \n",
    "\n",
    "This is a really nice implementation of VGGNet, quite easy to work with. The network has already been trained and the parameters are available from this link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file already exists!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "vgg_dir = 'tensorflow_vgg/'\n",
    "# Make sure vgg exists\n",
    "if not isdir(vgg_dir):\n",
    "    raise Exception(\"VGG directory doesn't exist!\")\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(vgg_dir + \"vgg16.npy\"):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='VGG16 Parameters') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/content.udacity-data.com/nd101/vgg16.npy',\n",
    "            vgg_dir + 'vgg16.npy',\n",
    "            pbar.hook)\n",
    "else:\n",
    "    print(\"Parameter file already exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flower power\n",
    "\n",
    "Here we'll be using VGGNet to classify images of flowers. To get the flower dataset, run the cell below. This dataset comes from the [TensorFlow inception tutorial](https://www.tensorflow.org/tutorials/image_retraining)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet Codes\n",
    "\n",
    "Below, we'll run through all the images in our dataset and get codes for each of them. That is, we'll run the images through the VGGNet convolutional layers and record the values of the first fully connected layer. We can then write these to a file for later when we build our own classifier.\n",
    "\n",
    "Here we're using the `vgg16` module from `tensorflow_vgg`. The network takes images of size $244 \\times 224 \\times 3$ as input. Then it has 5 sets of convolutional layers. The network implemented here has this structure (copied from [the source code](https://github.com/machrisaa/tensorflow-vgg/blob/master/vgg16.py):\n",
    "\n",
    "```\n",
    "self.conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n",
    "self.conv1_2 = self.conv_layer(self.conv1_1, \"conv1_2\")\n",
    "self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "\n",
    "self.conv2_1 = self.conv_layer(self.pool1, \"conv2_1\")\n",
    "self.conv2_2 = self.conv_layer(self.conv2_1, \"conv2_2\")\n",
    "self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "\n",
    "self.conv3_1 = self.conv_layer(self.pool2, \"conv3_1\")\n",
    "self.conv3_2 = self.conv_layer(self.conv3_1, \"conv3_2\")\n",
    "self.conv3_3 = self.conv_layer(self.conv3_2, \"conv3_3\")\n",
    "self.pool3 = self.max_pool(self.conv3_3, 'pool3')\n",
    "\n",
    "self.conv4_1 = self.conv_layer(self.pool3, \"conv4_1\")\n",
    "self.conv4_2 = self.conv_layer(self.conv4_1, \"conv4_2\")\n",
    "self.conv4_3 = self.conv_layer(self.conv4_2, \"conv4_3\")\n",
    "self.pool4 = self.max_pool(self.conv4_3, 'pool4')\n",
    "\n",
    "self.conv5_1 = self.conv_layer(self.pool4, \"conv5_1\")\n",
    "self.conv5_2 = self.conv_layer(self.conv5_1, \"conv5_2\")\n",
    "self.conv5_3 = self.conv_layer(self.conv5_2, \"conv5_3\")\n",
    "self.pool5 = self.max_pool(self.conv5_3, 'pool5')\n",
    "\n",
    "self.fc6 = self.fc_layer(self.pool5, \"fc6\")\n",
    "self.relu6 = tf.nn.relu(self.fc6)\n",
    "```\n",
    "\n",
    "So what we want are the values of the first fully connected layer, after being ReLUd (`self.relu6`). To build the network, we use\n",
    "\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "```\n",
    "\n",
    "This creates the `vgg` object, then builds the graph with `vgg.build(input_)`. Then to get the values from the layer,\n",
    "\n",
    "```\n",
    "feed_dict = {input_: images}\n",
    "codes = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20', '18', '0', '3', '24', '1', '5', '6', '11', '17', '16', '8', '23', '21', '10', '9', '15', '12', '19', '13', '2', '7', '14', '4', '22']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'food_images/cid11_max2048/'\n",
    "contents = os.listdir(data_dir)\n",
    "classes = [each for each in contents if os.path.isdir(data_dir + each)]\n",
    "\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm running images through the VGG network in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the batch size higher if you can fit in in your GPU memory\n",
    "batch_size = 10\n",
    "codes_list = []\n",
    "labels = []\n",
    "batch = []\n",
    "\n",
    "codes = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vgg = vgg16.Vgg16()\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3], name='input')\n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "\n",
    "    for each in classes:\n",
    "        print(\"Starting {} images\".format(each))\n",
    "        class_path = data_dir + each\n",
    "        files = os.listdir(class_path)\n",
    "        for ii, file in enumerate(files, 1):\n",
    "            # Add images to the current batch\n",
    "            # utils.load_image crops the input images for us, from the center\n",
    "            img = utils.load_image(os.path.join(class_path, file))\n",
    "            batch.append(img.reshape((1, 224, 224, 3)))\n",
    "            labels.append(each)\n",
    "            \n",
    "            # Running the batch through the network to get the codes\n",
    "            if ii % batch_size == 0 or ii == len(files):\n",
    "                images = np.concatenate(batch)\n",
    "\n",
    "                feed_dict = {input_: images}\n",
    "                codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "                \n",
    "                # Here I'm building an array of the codes\n",
    "                if codes is None:\n",
    "                    codes = codes_batch\n",
    "                else:\n",
    "                    codes = np.concatenate((codes, codes_batch))\n",
    "                \n",
    "                # Reset to start building the next batch\n",
    "                batch = []\n",
    "                print('{} images processed'.format(ii))\n",
    "                \n",
    "# write codes to file\n",
    "with open('codes', 'w') as f:\n",
    "    codes.tofile(f)\n",
    "    \n",
    "# write labels to file\n",
    "import csv\n",
    "with open('labels', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\n')\n",
    "    writer.writerow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aleksas/labs/food_nutrition_classifier_tf/model/tensorflow_vgg/vgg16.npy\n",
      "npy file loaded\n",
      "Tensor(\"filter:0\", shape=(3, 3, 3, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vgg = vgg16.Vgg16()\n",
    "\n",
    "print(vgg.get_conv_filter('conv1_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier\n",
    "\n",
    "Now that we have codes for all the images, we can build a simple classifier on top of them. The codes behave just like normal input into a simple neural network. Below I'm going to have you do most of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read codes and labels from file\n",
    "import csv\n",
    "\n",
    "with open('labels') as f:\n",
    "    reader = csv.reader(f, delimiter='\\n')\n",
    "    labels = np.array([each for each in reader if len(each) > 0]).squeeze()\n",
    "with open('codes') as f:\n",
    "    codes = np.fromfile(f, dtype=np.float32)\n",
    "    codes = codes.reshape((len(labels), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep\n",
    "\n",
    "As usual, now we need to one-hot encode our labels and create validation/test sets. First up, creating our labels!\n",
    "\n",
    "> **Exercise:** From scikit-learn, use [LabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to create one-hot encoded vectors from the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "\n",
    "labels_vecs = lb.transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you'll want to create your training, validation, and test sets. An important thing to note here is that our labels and data aren't randomized yet. We'll want to shuffle our data so the validation and test sets contain data from all classes. Otherwise, you could end up with testing sets that are all one class. Typically, you'll also want to make sure that each smaller set has the same the distribution of classes as it is for the whole data set. The easiest way to accomplish both these goals is to use [`StratifiedShuffleSplit`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) from scikit-learn.\n",
    "\n",
    "You can create the splitter like so:\n",
    "```\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "```\n",
    "Then split the data with \n",
    "```\n",
    "splitter = ss.split(x, y)\n",
    "```\n",
    "\n",
    "`ss.split` returns a generator of indices. You can pass the indices into the arrays to get the split sets. The fact that it's a generator means you either need to iterate over it, or use `next(splitter)` to get the indices. Be sure to read the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) and the [user guide](http://scikit-learn.org/stable/modules/cross_validation.html#random-permutations-cross-validation-a-k-a-shuffle-split).\n",
    "\n",
    "> **Exercise:** Use StratifiedShuffleSplit to split the codes and labels into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "\n",
    "train_idx, val_idx = next(ss.split(codes, labels_vecs))\n",
    "\n",
    "half_val_len = int(len(val_idx)/2)\n",
    "val_idx, test_idx = val_idx[:half_val_len], val_idx[half_val_len:]\n",
    "\n",
    "train_x, train_y = codes[train_idx], labels_vecs[train_idx]\n",
    "val_x, val_y = codes[val_idx], labels_vecs[val_idx]\n",
    "test_x, test_y = codes[test_idx], labels_vecs[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (38327, 4096) (38327, 25)\n",
      "Validation shapes (x, y): (4791, 4096) (4791, 25)\n",
      "Test shapes (x, y): (4791, 4096) (4791, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)\n",
    "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did it right, you should see these sizes for the training sets:\n",
    "\n",
    "```\n",
    "Train shapes (x, y): (2936, 4096) (2936, 5)\n",
    "Validation shapes (x, y): (367, 4096) (367, 5)\n",
    "Test shapes (x, y): (367, 4096) (367, 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier layers\n",
    "\n",
    "Once you have the convolutional codes, you just need to build a classfier from some fully connected layers. You use the codes as the inputs and the image labels as targets. Otherwise the classifier is a typical neural network.\n",
    "\n",
    "> **Exercise:** With the codes and labels loaded, build the classifier. Consider the codes as your inputs, each of them are 4096D vectors. You'll want to use a hidden layer and an output layer as your classifier. Remember that the output layer needs to have one unit for each class and a softmax activation function. Use the cross entropy to calculate the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aleksas/labs/food_nutrition_classifier_tf/model/tensorflow_vgg/vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3], name='input')\n",
    "    vgg = vgg16.Vgg16()\n",
    "    vgg.build(input_)\n",
    "    \n",
    "inputs_ = vgg.relu6# tf.placeholder(tf.float32, shape=[None, codes.shape[1]], name='feature_inputs')\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, labels_vecs.shape[1]], name='labels')\n",
    "\n",
    "fc = tf.contrib.layers.fully_connected(inputs_, 256)\n",
    "logits = tf.contrib.layers.fully_connected(fc, labels_vecs.shape[1], activation_fn=None, scope='final_training_ops')\n",
    "tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "tf.summary.histogram('activations', cross_entropy)\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "predicted = tf.nn.softmax(logits, name='final_result')\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches!\n",
    "\n",
    "Here is just a simple way to do batches. I've written it so that it includes all the data. Sometimes you'll throw out some data at the end to make sure you have full batches. Here I just extend the last batch to include the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" Return a generator that yields batches from arrays x and y. \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # If we're not on the last batch, grab data with size batch_size\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # On the last batch, grab the rest of the data\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # I love generators\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here, we'll train the network.\n",
    "\n",
    "> **Exercise:** So far we've been providing the training code for you. Here, I'm going to give you a bit more of a challenge and have you write the code to train the network. Of course, you'll be able to see my solution if you need help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/300 Iteration: 0 Training loss: 2.63271\n",
      "Epoch: 1/300 Iteration: 1 Training loss: 2.65315\n",
      "Epoch: 1/300 Iteration: 2 Training loss: 2.61473\n",
      "Epoch: 1/300 Iteration: 3 Training loss: 2.64975\n",
      "Epoch: 1/300 Iteration: 4 Training loss: 2.65488\n",
      "Epoch: 0/300 Iteration: 5 Validation Acc: 0.2235\n",
      "Epoch: 1/300 Iteration: 5 Training loss: 2.64680\n",
      "Epoch: 1/300 Iteration: 6 Training loss: 2.64764\n",
      "Epoch: 1/300 Iteration: 7 Training loss: 2.57422\n",
      "Epoch: 1/300 Iteration: 8 Training loss: 2.59723\n",
      "Epoch: 1/300 Iteration: 9 Training loss: 2.62757\n",
      "Epoch: 0/300 Iteration: 10 Validation Acc: 0.2413\n",
      "Epoch: 2/300 Iteration: 10 Training loss: 2.48778\n",
      "Epoch: 2/300 Iteration: 11 Training loss: 2.51394\n",
      "Epoch: 2/300 Iteration: 12 Training loss: 2.49538\n",
      "Epoch: 2/300 Iteration: 13 Training loss: 2.53538\n",
      "Epoch: 2/300 Iteration: 14 Training loss: 2.50932\n",
      "Epoch: 1/300 Iteration: 15 Validation Acc: 0.2430\n",
      "Epoch: 2/300 Iteration: 15 Training loss: 2.50463\n",
      "Epoch: 2/300 Iteration: 16 Training loss: 2.52295\n",
      "Epoch: 2/300 Iteration: 17 Training loss: 2.45968\n",
      "Epoch: 2/300 Iteration: 18 Training loss: 2.48667\n",
      "Epoch: 2/300 Iteration: 19 Training loss: 2.49396\n",
      "Epoch: 1/300 Iteration: 20 Validation Acc: 0.2526\n",
      "Epoch: 3/300 Iteration: 20 Training loss: 2.38632\n",
      "Epoch: 3/300 Iteration: 21 Training loss: 2.40620\n",
      "Epoch: 3/300 Iteration: 22 Training loss: 2.37846\n",
      "Epoch: 3/300 Iteration: 23 Training loss: 2.41567\n",
      "Epoch: 3/300 Iteration: 24 Training loss: 2.39392\n",
      "Epoch: 2/300 Iteration: 25 Validation Acc: 0.2571\n",
      "Epoch: 3/300 Iteration: 25 Training loss: 2.40918\n",
      "Epoch: 3/300 Iteration: 26 Training loss: 2.41426\n",
      "Epoch: 3/300 Iteration: 27 Training loss: 2.35983\n",
      "Epoch: 3/300 Iteration: 28 Training loss: 2.38668\n",
      "Epoch: 3/300 Iteration: 29 Training loss: 2.38868\n",
      "Epoch: 2/300 Iteration: 30 Validation Acc: 0.2559\n",
      "Epoch: 4/300 Iteration: 30 Training loss: 2.29723\n",
      "Epoch: 4/300 Iteration: 31 Training loss: 2.30881\n",
      "Epoch: 4/300 Iteration: 32 Training loss: 2.28911\n",
      "Epoch: 4/300 Iteration: 33 Training loss: 2.32893\n",
      "Epoch: 4/300 Iteration: 34 Training loss: 2.30352\n",
      "Epoch: 3/300 Iteration: 35 Validation Acc: 0.2668\n",
      "Epoch: 4/300 Iteration: 35 Training loss: 2.31229\n",
      "Epoch: 4/300 Iteration: 36 Training loss: 2.32279\n",
      "Epoch: 4/300 Iteration: 37 Training loss: 2.27509\n",
      "Epoch: 4/300 Iteration: 38 Training loss: 2.30345\n",
      "Epoch: 4/300 Iteration: 39 Training loss: 2.30374\n",
      "Epoch: 3/300 Iteration: 40 Validation Acc: 0.2670\n",
      "Epoch: 5/300 Iteration: 40 Training loss: 2.22311\n",
      "Epoch: 5/300 Iteration: 41 Training loss: 2.22449\n",
      "Epoch: 5/300 Iteration: 42 Training loss: 2.19941\n",
      "Epoch: 5/300 Iteration: 43 Training loss: 2.25383\n",
      "Epoch: 5/300 Iteration: 44 Training loss: 2.23753\n",
      "Epoch: 4/300 Iteration: 45 Validation Acc: 0.2724\n",
      "Epoch: 5/300 Iteration: 45 Training loss: 2.23233\n",
      "Epoch: 5/300 Iteration: 46 Training loss: 2.22707\n",
      "Epoch: 5/300 Iteration: 47 Training loss: 2.20390\n",
      "Epoch: 5/300 Iteration: 48 Training loss: 2.24317\n",
      "Epoch: 5/300 Iteration: 49 Training loss: 2.23773\n",
      "Epoch: 4/300 Iteration: 50 Validation Acc: 0.2745\n",
      "Epoch: 6/300 Iteration: 50 Training loss: 2.16142\n",
      "Epoch: 6/300 Iteration: 51 Training loss: 2.16092\n",
      "Epoch: 6/300 Iteration: 52 Training loss: 2.13831\n",
      "Epoch: 6/300 Iteration: 53 Training loss: 2.19315\n",
      "Epoch: 6/300 Iteration: 54 Training loss: 2.18532\n",
      "Epoch: 5/300 Iteration: 55 Validation Acc: 0.2722\n",
      "Epoch: 6/300 Iteration: 55 Training loss: 2.18473\n",
      "Epoch: 6/300 Iteration: 56 Training loss: 2.16087\n",
      "Epoch: 6/300 Iteration: 57 Training loss: 2.13952\n",
      "Epoch: 6/300 Iteration: 58 Training loss: 2.17874\n",
      "Epoch: 6/300 Iteration: 59 Training loss: 2.17309\n",
      "Epoch: 5/300 Iteration: 60 Validation Acc: 0.2753\n",
      "Epoch: 7/300 Iteration: 60 Training loss: 2.12182\n",
      "Epoch: 7/300 Iteration: 61 Training loss: 2.11201\n",
      "Epoch: 7/300 Iteration: 62 Training loss: 2.07819\n",
      "Epoch: 7/300 Iteration: 63 Training loss: 2.12443\n",
      "Epoch: 7/300 Iteration: 64 Training loss: 2.13272\n",
      "Epoch: 6/300 Iteration: 65 Validation Acc: 0.2757\n",
      "Epoch: 7/300 Iteration: 65 Training loss: 2.15126\n",
      "Epoch: 7/300 Iteration: 66 Training loss: 2.12459\n",
      "Epoch: 7/300 Iteration: 67 Training loss: 2.10818\n",
      "Epoch: 7/300 Iteration: 68 Training loss: 2.13400\n",
      "Epoch: 7/300 Iteration: 69 Training loss: 2.13192\n",
      "Epoch: 6/300 Iteration: 70 Validation Acc: 0.2774\n",
      "Epoch: 8/300 Iteration: 70 Training loss: 2.08960\n",
      "Epoch: 8/300 Iteration: 71 Training loss: 2.06988\n",
      "Epoch: 8/300 Iteration: 72 Training loss: 2.04108\n",
      "Epoch: 8/300 Iteration: 73 Training loss: 2.09611\n",
      "Epoch: 8/300 Iteration: 74 Training loss: 2.06389\n",
      "Epoch: 7/300 Iteration: 75 Validation Acc: 0.2770\n",
      "Epoch: 8/300 Iteration: 75 Training loss: 2.09281\n",
      "Epoch: 8/300 Iteration: 76 Training loss: 2.08518\n",
      "Epoch: 8/300 Iteration: 77 Training loss: 2.08134\n",
      "Epoch: 8/300 Iteration: 78 Training loss: 2.10938\n",
      "Epoch: 8/300 Iteration: 79 Training loss: 2.09778\n",
      "Epoch: 7/300 Iteration: 80 Validation Acc: 0.2799\n",
      "Epoch: 9/300 Iteration: 80 Training loss: 2.03808\n",
      "Epoch: 9/300 Iteration: 81 Training loss: 2.03576\n",
      "Epoch: 9/300 Iteration: 82 Training loss: 1.99644\n",
      "Epoch: 9/300 Iteration: 83 Training loss: 2.04933\n",
      "Epoch: 9/300 Iteration: 84 Training loss: 2.03137\n",
      "Epoch: 8/300 Iteration: 85 Validation Acc: 0.2878\n",
      "Epoch: 9/300 Iteration: 85 Training loss: 2.01105\n",
      "Epoch: 9/300 Iteration: 86 Training loss: 1.99895\n",
      "Epoch: 9/300 Iteration: 87 Training loss: 2.01409\n",
      "Epoch: 9/300 Iteration: 88 Training loss: 2.05029\n",
      "Epoch: 9/300 Iteration: 89 Training loss: 2.06231\n",
      "Epoch: 8/300 Iteration: 90 Validation Acc: 0.2849\n",
      "Epoch: 10/300 Iteration: 90 Training loss: 1.96937\n",
      "Epoch: 10/300 Iteration: 91 Training loss: 1.95229\n",
      "Epoch: 10/300 Iteration: 92 Training loss: 1.96654\n",
      "Epoch: 10/300 Iteration: 93 Training loss: 2.00079\n",
      "Epoch: 10/300 Iteration: 94 Training loss: 1.99894\n",
      "Epoch: 9/300 Iteration: 95 Validation Acc: 0.2870\n",
      "Epoch: 10/300 Iteration: 95 Training loss: 2.00437\n",
      "Epoch: 10/300 Iteration: 96 Training loss: 1.97280\n",
      "Epoch: 10/300 Iteration: 97 Training loss: 1.96997\n",
      "Epoch: 10/300 Iteration: 98 Training loss: 1.99194\n",
      "Epoch: 10/300 Iteration: 99 Training loss: 2.01105\n",
      "Epoch: 9/300 Iteration: 100 Validation Acc: 0.2853\n",
      "Epoch: 11/300 Iteration: 100 Training loss: 1.95685\n",
      "Epoch: 11/300 Iteration: 101 Training loss: 1.92978\n",
      "Epoch: 11/300 Iteration: 102 Training loss: 1.89491\n",
      "Epoch: 11/300 Iteration: 103 Training loss: 2.00132\n",
      "Epoch: 11/300 Iteration: 104 Training loss: 1.94683\n",
      "Epoch: 10/300 Iteration: 105 Validation Acc: 0.2964\n",
      "Epoch: 11/300 Iteration: 105 Training loss: 1.94447\n",
      "Epoch: 11/300 Iteration: 106 Training loss: 1.94675\n",
      "Epoch: 11/300 Iteration: 107 Training loss: 1.93635\n",
      "Epoch: 11/300 Iteration: 108 Training loss: 1.95948\n",
      "Epoch: 11/300 Iteration: 109 Training loss: 1.99161\n",
      "Epoch: 10/300 Iteration: 110 Validation Acc: 0.2876\n",
      "Epoch: 12/300 Iteration: 110 Training loss: 1.90556\n",
      "Epoch: 12/300 Iteration: 111 Training loss: 1.90064\n",
      "Epoch: 12/300 Iteration: 112 Training loss: 1.89044\n",
      "Epoch: 12/300 Iteration: 113 Training loss: 1.92182\n",
      "Epoch: 12/300 Iteration: 114 Training loss: 1.94108\n",
      "Epoch: 11/300 Iteration: 115 Validation Acc: 0.2953\n",
      "Epoch: 12/300 Iteration: 115 Training loss: 1.91310\n",
      "Epoch: 12/300 Iteration: 116 Training loss: 1.87493\n",
      "Epoch: 12/300 Iteration: 117 Training loss: 1.87813\n",
      "Epoch: 12/300 Iteration: 118 Training loss: 1.90475\n",
      "Epoch: 12/300 Iteration: 119 Training loss: 1.91534\n",
      "Epoch: 11/300 Iteration: 120 Validation Acc: 0.2930\n",
      "Epoch: 13/300 Iteration: 120 Training loss: 1.85978\n",
      "Epoch: 13/300 Iteration: 121 Training loss: 1.82615\n",
      "Epoch: 13/300 Iteration: 122 Training loss: 1.80063\n",
      "Epoch: 13/300 Iteration: 123 Training loss: 1.87593\n",
      "Epoch: 13/300 Iteration: 124 Training loss: 1.84681\n",
      "Epoch: 12/300 Iteration: 125 Validation Acc: 0.3022\n",
      "Epoch: 13/300 Iteration: 125 Training loss: 1.84322\n",
      "Epoch: 13/300 Iteration: 126 Training loss: 1.82507\n",
      "Epoch: 13/300 Iteration: 127 Training loss: 1.81530\n",
      "Epoch: 13/300 Iteration: 128 Training loss: 1.85660\n",
      "Epoch: 13/300 Iteration: 129 Training loss: 1.88107\n",
      "Epoch: 12/300 Iteration: 130 Validation Acc: 0.2997\n",
      "Epoch: 14/300 Iteration: 130 Training loss: 1.81905\n",
      "Epoch: 14/300 Iteration: 131 Training loss: 1.79972\n",
      "Epoch: 14/300 Iteration: 132 Training loss: 1.78167\n",
      "Epoch: 14/300 Iteration: 133 Training loss: 1.81204\n",
      "Epoch: 14/300 Iteration: 134 Training loss: 1.81589\n",
      "Epoch: 13/300 Iteration: 135 Validation Acc: 0.3014\n",
      "Epoch: 14/300 Iteration: 135 Training loss: 1.83195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/300 Iteration: 136 Training loss: 1.79003\n",
      "Epoch: 14/300 Iteration: 137 Training loss: 1.79919\n",
      "Epoch: 14/300 Iteration: 138 Training loss: 1.82334\n",
      "Epoch: 14/300 Iteration: 139 Training loss: 1.81643\n",
      "Epoch: 13/300 Iteration: 140 Validation Acc: 0.3072\n",
      "Epoch: 15/300 Iteration: 140 Training loss: 1.76975\n",
      "Epoch: 15/300 Iteration: 141 Training loss: 1.76714\n",
      "Epoch: 15/300 Iteration: 142 Training loss: 1.74183\n",
      "Epoch: 15/300 Iteration: 143 Training loss: 1.77991\n",
      "Epoch: 15/300 Iteration: 144 Training loss: 1.76575\n",
      "Epoch: 14/300 Iteration: 145 Validation Acc: 0.3129\n",
      "Epoch: 15/300 Iteration: 145 Training loss: 1.77654\n",
      "Epoch: 15/300 Iteration: 146 Training loss: 1.73662\n",
      "Epoch: 15/300 Iteration: 147 Training loss: 1.75981\n",
      "Epoch: 15/300 Iteration: 148 Training loss: 1.79219\n",
      "Epoch: 15/300 Iteration: 149 Training loss: 1.78617\n",
      "Epoch: 14/300 Iteration: 150 Validation Acc: 0.3039\n",
      "Epoch: 16/300 Iteration: 150 Training loss: 1.74434\n",
      "Epoch: 16/300 Iteration: 151 Training loss: 1.74382\n",
      "Epoch: 16/300 Iteration: 152 Training loss: 1.71695\n",
      "Epoch: 16/300 Iteration: 153 Training loss: 1.71981\n",
      "Epoch: 16/300 Iteration: 154 Training loss: 1.73255\n",
      "Epoch: 15/300 Iteration: 155 Validation Acc: 0.3095\n",
      "Epoch: 16/300 Iteration: 155 Training loss: 1.75641\n",
      "Epoch: 16/300 Iteration: 156 Training loss: 1.69219\n",
      "Epoch: 16/300 Iteration: 157 Training loss: 1.69667\n",
      "Epoch: 16/300 Iteration: 158 Training loss: 1.73980\n",
      "Epoch: 16/300 Iteration: 159 Training loss: 1.72426\n",
      "Epoch: 15/300 Iteration: 160 Validation Acc: 0.3177\n",
      "Epoch: 17/300 Iteration: 160 Training loss: 1.69983\n",
      "Epoch: 17/300 Iteration: 161 Training loss: 1.68676\n",
      "Epoch: 17/300 Iteration: 162 Training loss: 1.67922\n",
      "Epoch: 17/300 Iteration: 163 Training loss: 1.69013\n",
      "Epoch: 17/300 Iteration: 164 Training loss: 1.64851\n",
      "Epoch: 16/300 Iteration: 165 Validation Acc: 0.3244\n",
      "Epoch: 17/300 Iteration: 165 Training loss: 1.67851\n",
      "Epoch: 17/300 Iteration: 166 Training loss: 1.63609\n",
      "Epoch: 17/300 Iteration: 167 Training loss: 1.65714\n",
      "Epoch: 17/300 Iteration: 168 Training loss: 1.70403\n",
      "Epoch: 17/300 Iteration: 169 Training loss: 1.68838\n",
      "Epoch: 16/300 Iteration: 170 Validation Acc: 0.3294\n",
      "Epoch: 18/300 Iteration: 170 Training loss: 1.64013\n",
      "Epoch: 18/300 Iteration: 171 Training loss: 1.65243\n",
      "Epoch: 18/300 Iteration: 172 Training loss: 1.63920\n",
      "Epoch: 18/300 Iteration: 173 Training loss: 1.64761\n",
      "Epoch: 18/300 Iteration: 174 Training loss: 1.63301\n",
      "Epoch: 17/300 Iteration: 175 Validation Acc: 0.3304\n",
      "Epoch: 18/300 Iteration: 175 Training loss: 1.65526\n",
      "Epoch: 18/300 Iteration: 176 Training loss: 1.59086\n",
      "Epoch: 18/300 Iteration: 177 Training loss: 1.59386\n",
      "Epoch: 18/300 Iteration: 178 Training loss: 1.63365\n",
      "Epoch: 18/300 Iteration: 179 Training loss: 1.66516\n",
      "Epoch: 17/300 Iteration: 180 Validation Acc: 0.3287\n",
      "Epoch: 19/300 Iteration: 180 Training loss: 1.60691\n",
      "Epoch: 19/300 Iteration: 181 Training loss: 1.59014\n",
      "Epoch: 19/300 Iteration: 182 Training loss: 1.59157\n",
      "Epoch: 19/300 Iteration: 183 Training loss: 1.61631\n",
      "Epoch: 19/300 Iteration: 184 Training loss: 1.59979\n",
      "Epoch: 18/300 Iteration: 185 Validation Acc: 0.3402\n",
      "Epoch: 19/300 Iteration: 185 Training loss: 1.60745\n",
      "Epoch: 19/300 Iteration: 186 Training loss: 1.54911\n",
      "Epoch: 19/300 Iteration: 187 Training loss: 1.58686\n",
      "Epoch: 19/300 Iteration: 188 Training loss: 1.59118\n",
      "Epoch: 19/300 Iteration: 189 Training loss: 1.59719\n",
      "Epoch: 18/300 Iteration: 190 Validation Acc: 0.3254\n",
      "Epoch: 20/300 Iteration: 190 Training loss: 1.56386\n",
      "Epoch: 20/300 Iteration: 191 Training loss: 1.54811\n",
      "Epoch: 20/300 Iteration: 192 Training loss: 1.55445\n",
      "Epoch: 20/300 Iteration: 193 Training loss: 1.55770\n",
      "Epoch: 20/300 Iteration: 194 Training loss: 1.56919\n",
      "Epoch: 19/300 Iteration: 195 Validation Acc: 0.3296\n",
      "Epoch: 20/300 Iteration: 195 Training loss: 1.60453\n",
      "Epoch: 20/300 Iteration: 196 Training loss: 1.50284\n",
      "Epoch: 20/300 Iteration: 197 Training loss: 1.52688\n",
      "Epoch: 20/300 Iteration: 198 Training loss: 1.57949\n",
      "Epoch: 20/300 Iteration: 199 Training loss: 1.55749\n",
      "Epoch: 19/300 Iteration: 200 Validation Acc: 0.3244\n",
      "Epoch: 21/300 Iteration: 200 Training loss: 1.55760\n",
      "Epoch: 21/300 Iteration: 201 Training loss: 1.53660\n",
      "Epoch: 21/300 Iteration: 202 Training loss: 1.49655\n",
      "Epoch: 21/300 Iteration: 203 Training loss: 1.56359\n",
      "Epoch: 21/300 Iteration: 204 Training loss: 1.51882\n",
      "Epoch: 20/300 Iteration: 205 Validation Acc: 0.3317\n",
      "Epoch: 21/300 Iteration: 205 Training loss: 1.56809\n",
      "Epoch: 21/300 Iteration: 206 Training loss: 1.51650\n",
      "Epoch: 21/300 Iteration: 207 Training loss: 1.50258\n",
      "Epoch: 21/300 Iteration: 208 Training loss: 1.54269\n",
      "Epoch: 21/300 Iteration: 209 Training loss: 1.53057\n",
      "Epoch: 20/300 Iteration: 210 Validation Acc: 0.3354\n",
      "Epoch: 22/300 Iteration: 210 Training loss: 1.49507\n",
      "Epoch: 22/300 Iteration: 211 Training loss: 1.52010\n",
      "Epoch: 22/300 Iteration: 212 Training loss: 1.49492\n",
      "Epoch: 22/300 Iteration: 213 Training loss: 1.50345\n",
      "Epoch: 22/300 Iteration: 214 Training loss: 1.49168\n",
      "Epoch: 21/300 Iteration: 215 Validation Acc: 0.3367\n",
      "Epoch: 22/300 Iteration: 215 Training loss: 1.53264\n",
      "Epoch: 22/300 Iteration: 216 Training loss: 1.47261\n",
      "Epoch: 22/300 Iteration: 217 Training loss: 1.49586\n",
      "Epoch: 22/300 Iteration: 218 Training loss: 1.50865\n",
      "Epoch: 22/300 Iteration: 219 Training loss: 1.50591\n",
      "Epoch: 21/300 Iteration: 220 Validation Acc: 0.3427\n",
      "Epoch: 23/300 Iteration: 220 Training loss: 1.48482\n",
      "Epoch: 23/300 Iteration: 221 Training loss: 1.47989\n",
      "Epoch: 23/300 Iteration: 222 Training loss: 1.45397\n",
      "Epoch: 23/300 Iteration: 223 Training loss: 1.51381\n",
      "Epoch: 23/300 Iteration: 224 Training loss: 1.45638\n",
      "Epoch: 22/300 Iteration: 225 Validation Acc: 0.3373\n",
      "Epoch: 23/300 Iteration: 225 Training loss: 1.49666\n",
      "Epoch: 23/300 Iteration: 226 Training loss: 1.46313\n",
      "Epoch: 23/300 Iteration: 227 Training loss: 1.45349\n",
      "Epoch: 23/300 Iteration: 228 Training loss: 1.46246\n",
      "Epoch: 23/300 Iteration: 229 Training loss: 1.49051\n",
      "Epoch: 22/300 Iteration: 230 Validation Acc: 0.3436\n",
      "Epoch: 24/300 Iteration: 230 Training loss: 1.48271\n",
      "Epoch: 24/300 Iteration: 231 Training loss: 1.48167\n",
      "Epoch: 24/300 Iteration: 232 Training loss: 1.44966\n",
      "Epoch: 24/300 Iteration: 233 Training loss: 1.47120\n",
      "Epoch: 24/300 Iteration: 234 Training loss: 1.46438\n",
      "Epoch: 23/300 Iteration: 235 Validation Acc: 0.3404\n",
      "Epoch: 24/300 Iteration: 235 Training loss: 1.50357\n",
      "Epoch: 24/300 Iteration: 236 Training loss: 1.40702\n",
      "Epoch: 24/300 Iteration: 237 Training loss: 1.44134\n",
      "Epoch: 24/300 Iteration: 238 Training loss: 1.43715\n",
      "Epoch: 24/300 Iteration: 239 Training loss: 1.43911\n",
      "Epoch: 23/300 Iteration: 240 Validation Acc: 0.3504\n",
      "Epoch: 25/300 Iteration: 240 Training loss: 1.42395\n",
      "Epoch: 25/300 Iteration: 241 Training loss: 1.45003\n",
      "Epoch: 25/300 Iteration: 242 Training loss: 1.38139\n",
      "Epoch: 25/300 Iteration: 243 Training loss: 1.42396\n",
      "Epoch: 25/300 Iteration: 244 Training loss: 1.36278\n",
      "Epoch: 24/300 Iteration: 245 Validation Acc: 0.3615\n",
      "Epoch: 25/300 Iteration: 245 Training loss: 1.39599\n",
      "Epoch: 25/300 Iteration: 246 Training loss: 1.37293\n",
      "Epoch: 25/300 Iteration: 247 Training loss: 1.39482\n",
      "Epoch: 25/300 Iteration: 248 Training loss: 1.40439\n",
      "Epoch: 25/300 Iteration: 249 Training loss: 1.39543\n",
      "Epoch: 24/300 Iteration: 250 Validation Acc: 0.3653\n",
      "Epoch: 26/300 Iteration: 250 Training loss: 1.35342\n",
      "Epoch: 26/300 Iteration: 251 Training loss: 1.36760\n",
      "Epoch: 26/300 Iteration: 252 Training loss: 1.37529\n",
      "Epoch: 26/300 Iteration: 253 Training loss: 1.39062\n",
      "Epoch: 26/300 Iteration: 254 Training loss: 1.35931\n",
      "Epoch: 25/300 Iteration: 255 Validation Acc: 0.3607\n",
      "Epoch: 26/300 Iteration: 255 Training loss: 1.36674\n",
      "Epoch: 26/300 Iteration: 256 Training loss: 1.29793\n",
      "Epoch: 26/300 Iteration: 257 Training loss: 1.37919\n",
      "Epoch: 26/300 Iteration: 258 Training loss: 1.41024\n",
      "Epoch: 26/300 Iteration: 259 Training loss: 1.36542\n",
      "Epoch: 25/300 Iteration: 260 Validation Acc: 0.3630\n",
      "Epoch: 27/300 Iteration: 260 Training loss: 1.33847\n",
      "Epoch: 27/300 Iteration: 261 Training loss: 1.35147\n",
      "Epoch: 27/300 Iteration: 262 Training loss: 1.31433\n",
      "Epoch: 27/300 Iteration: 263 Training loss: 1.34931\n",
      "Epoch: 27/300 Iteration: 264 Training loss: 1.31369\n",
      "Epoch: 26/300 Iteration: 265 Validation Acc: 0.3692\n",
      "Epoch: 27/300 Iteration: 265 Training loss: 1.33693\n",
      "Epoch: 27/300 Iteration: 266 Training loss: 1.27477\n",
      "Epoch: 27/300 Iteration: 267 Training loss: 1.29462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/300 Iteration: 268 Training loss: 1.33039\n",
      "Epoch: 27/300 Iteration: 269 Training loss: 1.35074\n",
      "Epoch: 26/300 Iteration: 270 Validation Acc: 0.3788\n",
      "Epoch: 28/300 Iteration: 270 Training loss: 1.29155\n",
      "Epoch: 28/300 Iteration: 271 Training loss: 1.31484\n",
      "Epoch: 28/300 Iteration: 272 Training loss: 1.28620\n",
      "Epoch: 28/300 Iteration: 273 Training loss: 1.30287\n",
      "Epoch: 28/300 Iteration: 274 Training loss: 1.29172\n",
      "Epoch: 27/300 Iteration: 275 Validation Acc: 0.3636\n",
      "Epoch: 28/300 Iteration: 275 Training loss: 1.33223\n",
      "Epoch: 28/300 Iteration: 276 Training loss: 1.26395\n",
      "Epoch: 28/300 Iteration: 277 Training loss: 1.26465\n",
      "Epoch: 28/300 Iteration: 278 Training loss: 1.30326\n",
      "Epoch: 28/300 Iteration: 279 Training loss: 1.33546\n",
      "Epoch: 27/300 Iteration: 280 Validation Acc: 0.3784\n",
      "Epoch: 29/300 Iteration: 280 Training loss: 1.29637\n",
      "Epoch: 29/300 Iteration: 281 Training loss: 1.27323\n",
      "Epoch: 29/300 Iteration: 282 Training loss: 1.26745\n",
      "Epoch: 29/300 Iteration: 283 Training loss: 1.31309\n",
      "Epoch: 29/300 Iteration: 284 Training loss: 1.27069\n",
      "Epoch: 28/300 Iteration: 285 Validation Acc: 0.3703\n",
      "Epoch: 29/300 Iteration: 285 Training loss: 1.28040\n",
      "Epoch: 29/300 Iteration: 286 Training loss: 1.22958\n",
      "Epoch: 29/300 Iteration: 287 Training loss: 1.24949\n",
      "Epoch: 29/300 Iteration: 288 Training loss: 1.28258\n",
      "Epoch: 29/300 Iteration: 289 Training loss: 1.31238\n",
      "Epoch: 28/300 Iteration: 290 Validation Acc: 0.3767\n",
      "Epoch: 30/300 Iteration: 290 Training loss: 1.31306\n",
      "Epoch: 30/300 Iteration: 291 Training loss: 1.27599\n",
      "Epoch: 30/300 Iteration: 292 Training loss: 1.23988\n",
      "Epoch: 30/300 Iteration: 293 Training loss: 1.30021\n",
      "Epoch: 30/300 Iteration: 294 Training loss: 1.26550\n",
      "Epoch: 29/300 Iteration: 295 Validation Acc: 0.3728\n",
      "Epoch: 30/300 Iteration: 295 Training loss: 1.29644\n",
      "Epoch: 30/300 Iteration: 296 Training loss: 1.24042\n",
      "Epoch: 30/300 Iteration: 297 Training loss: 1.22957\n",
      "Epoch: 30/300 Iteration: 298 Training loss: 1.26701\n",
      "Epoch: 30/300 Iteration: 299 Training loss: 1.28212\n",
      "Epoch: 29/300 Iteration: 300 Validation Acc: 0.3763\n",
      "Epoch: 31/300 Iteration: 300 Training loss: 1.27495\n",
      "Epoch: 31/300 Iteration: 301 Training loss: 1.29698\n",
      "Epoch: 31/300 Iteration: 302 Training loss: 1.22062\n",
      "Epoch: 31/300 Iteration: 303 Training loss: 1.27826\n",
      "Epoch: 31/300 Iteration: 304 Training loss: 1.27770\n",
      "Epoch: 30/300 Iteration: 305 Validation Acc: 0.3734\n",
      "Epoch: 31/300 Iteration: 305 Training loss: 1.26425\n",
      "Epoch: 31/300 Iteration: 306 Training loss: 1.19525\n",
      "Epoch: 31/300 Iteration: 307 Training loss: 1.20183\n",
      "Epoch: 31/300 Iteration: 308 Training loss: 1.22027\n",
      "Epoch: 31/300 Iteration: 309 Training loss: 1.25747\n",
      "Epoch: 30/300 Iteration: 310 Validation Acc: 0.3843\n",
      "Epoch: 32/300 Iteration: 310 Training loss: 1.22392\n",
      "Epoch: 32/300 Iteration: 311 Training loss: 1.20685\n",
      "Epoch: 32/300 Iteration: 312 Training loss: 1.17137\n",
      "Epoch: 32/300 Iteration: 313 Training loss: 1.16125\n",
      "Epoch: 32/300 Iteration: 314 Training loss: 1.18457\n",
      "Epoch: 31/300 Iteration: 315 Validation Acc: 0.3784\n",
      "Epoch: 32/300 Iteration: 315 Training loss: 1.21413\n",
      "Epoch: 32/300 Iteration: 316 Training loss: 1.15119\n",
      "Epoch: 32/300 Iteration: 317 Training loss: 1.14709\n",
      "Epoch: 32/300 Iteration: 318 Training loss: 1.17367\n",
      "Epoch: 32/300 Iteration: 319 Training loss: 1.20742\n",
      "Epoch: 31/300 Iteration: 320 Validation Acc: 0.3870\n",
      "Epoch: 33/300 Iteration: 320 Training loss: 1.21185\n",
      "Epoch: 33/300 Iteration: 321 Training loss: 1.23315\n",
      "Epoch: 33/300 Iteration: 322 Training loss: 1.16427\n",
      "Epoch: 33/300 Iteration: 323 Training loss: 1.17963\n",
      "Epoch: 33/300 Iteration: 324 Training loss: 1.13184\n",
      "Epoch: 32/300 Iteration: 325 Validation Acc: 0.3878\n",
      "Epoch: 33/300 Iteration: 325 Training loss: 1.18845\n",
      "Epoch: 33/300 Iteration: 326 Training loss: 1.16585\n",
      "Epoch: 33/300 Iteration: 327 Training loss: 1.14232\n",
      "Epoch: 33/300 Iteration: 328 Training loss: 1.18242\n",
      "Epoch: 33/300 Iteration: 329 Training loss: 1.17070\n",
      "Epoch: 32/300 Iteration: 330 Validation Acc: 0.4001\n",
      "Epoch: 34/300 Iteration: 330 Training loss: 1.18278\n",
      "Epoch: 34/300 Iteration: 331 Training loss: 1.23551\n",
      "Epoch: 34/300 Iteration: 332 Training loss: 1.17221\n",
      "Epoch: 34/300 Iteration: 333 Training loss: 1.20466\n",
      "Epoch: 34/300 Iteration: 334 Training loss: 1.16187\n",
      "Epoch: 33/300 Iteration: 335 Validation Acc: 0.3937\n",
      "Epoch: 34/300 Iteration: 335 Training loss: 1.14342\n",
      "Epoch: 34/300 Iteration: 336 Training loss: 1.13266\n",
      "Epoch: 34/300 Iteration: 337 Training loss: 1.12592\n",
      "Epoch: 34/300 Iteration: 338 Training loss: 1.19113\n",
      "Epoch: 34/300 Iteration: 339 Training loss: 1.22137\n",
      "Epoch: 33/300 Iteration: 340 Validation Acc: 0.4126\n",
      "Epoch: 35/300 Iteration: 340 Training loss: 1.11701\n",
      "Epoch: 35/300 Iteration: 341 Training loss: 1.18490\n",
      "Epoch: 35/300 Iteration: 342 Training loss: 1.16267\n",
      "Epoch: 35/300 Iteration: 343 Training loss: 1.14218\n",
      "Epoch: 35/300 Iteration: 344 Training loss: 1.15685\n",
      "Epoch: 34/300 Iteration: 345 Validation Acc: 0.3863\n",
      "Epoch: 35/300 Iteration: 345 Training loss: 1.16607\n",
      "Epoch: 35/300 Iteration: 346 Training loss: 1.08593\n",
      "Epoch: 35/300 Iteration: 347 Training loss: 1.12812\n",
      "Epoch: 35/300 Iteration: 348 Training loss: 1.11756\n",
      "Epoch: 35/300 Iteration: 349 Training loss: 1.15010\n",
      "Epoch: 34/300 Iteration: 350 Validation Acc: 0.3899\n",
      "Epoch: 36/300 Iteration: 350 Training loss: 1.22205\n",
      "Epoch: 36/300 Iteration: 351 Training loss: 1.14603\n",
      "Epoch: 36/300 Iteration: 352 Training loss: 1.11421\n",
      "Epoch: 36/300 Iteration: 353 Training loss: 1.16434\n",
      "Epoch: 36/300 Iteration: 354 Training loss: 1.09587\n",
      "Epoch: 35/300 Iteration: 355 Validation Acc: 0.3962\n",
      "Epoch: 36/300 Iteration: 355 Training loss: 1.12478\n",
      "Epoch: 36/300 Iteration: 356 Training loss: 1.12376\n",
      "Epoch: 36/300 Iteration: 357 Training loss: 1.06717\n",
      "Epoch: 36/300 Iteration: 358 Training loss: 1.12262\n",
      "Epoch: 36/300 Iteration: 359 Training loss: 1.08770\n",
      "Epoch: 35/300 Iteration: 360 Validation Acc: 0.4043\n",
      "Epoch: 37/300 Iteration: 360 Training loss: 1.12335\n",
      "Epoch: 37/300 Iteration: 361 Training loss: 1.16626\n",
      "Epoch: 37/300 Iteration: 362 Training loss: 1.10381\n",
      "Epoch: 37/300 Iteration: 363 Training loss: 1.11090\n",
      "Epoch: 37/300 Iteration: 364 Training loss: 1.10684\n",
      "Epoch: 36/300 Iteration: 365 Validation Acc: 0.4024\n",
      "Epoch: 37/300 Iteration: 365 Training loss: 1.07183\n",
      "Epoch: 37/300 Iteration: 366 Training loss: 1.05935\n",
      "Epoch: 37/300 Iteration: 367 Training loss: 1.04633\n",
      "Epoch: 37/300 Iteration: 368 Training loss: 1.06894\n",
      "Epoch: 37/300 Iteration: 369 Training loss: 1.05925\n",
      "Epoch: 36/300 Iteration: 370 Validation Acc: 0.4112\n",
      "Epoch: 38/300 Iteration: 370 Training loss: 1.07647\n",
      "Epoch: 38/300 Iteration: 371 Training loss: 1.09697\n",
      "Epoch: 38/300 Iteration: 372 Training loss: 1.04694\n",
      "Epoch: 38/300 Iteration: 373 Training loss: 1.07528\n",
      "Epoch: 38/300 Iteration: 374 Training loss: 1.06704\n",
      "Epoch: 37/300 Iteration: 375 Validation Acc: 0.4047\n",
      "Epoch: 38/300 Iteration: 375 Training loss: 1.05281\n",
      "Epoch: 38/300 Iteration: 376 Training loss: 1.00340\n",
      "Epoch: 38/300 Iteration: 377 Training loss: 1.00713\n",
      "Epoch: 38/300 Iteration: 378 Training loss: 1.07910\n",
      "Epoch: 38/300 Iteration: 379 Training loss: 1.07570\n",
      "Epoch: 37/300 Iteration: 380 Validation Acc: 0.4193\n",
      "Epoch: 39/300 Iteration: 380 Training loss: 1.04781\n",
      "Epoch: 39/300 Iteration: 381 Training loss: 1.05618\n",
      "Epoch: 39/300 Iteration: 382 Training loss: 1.03117\n",
      "Epoch: 39/300 Iteration: 383 Training loss: 1.04916\n",
      "Epoch: 39/300 Iteration: 384 Training loss: 1.03662\n",
      "Epoch: 38/300 Iteration: 385 Validation Acc: 0.4126\n",
      "Epoch: 39/300 Iteration: 385 Training loss: 1.02302\n",
      "Epoch: 39/300 Iteration: 386 Training loss: 0.99642\n",
      "Epoch: 39/300 Iteration: 387 Training loss: 0.98343\n",
      "Epoch: 39/300 Iteration: 388 Training loss: 0.99802\n",
      "Epoch: 39/300 Iteration: 389 Training loss: 0.99854\n",
      "Epoch: 38/300 Iteration: 390 Validation Acc: 0.4273\n",
      "Epoch: 40/300 Iteration: 390 Training loss: 1.02222\n",
      "Epoch: 40/300 Iteration: 391 Training loss: 1.03849\n",
      "Epoch: 40/300 Iteration: 392 Training loss: 0.98553\n",
      "Epoch: 40/300 Iteration: 393 Training loss: 1.00175\n",
      "Epoch: 40/300 Iteration: 394 Training loss: 0.97415\n",
      "Epoch: 39/300 Iteration: 395 Validation Acc: 0.4268\n",
      "Epoch: 40/300 Iteration: 395 Training loss: 0.95467\n",
      "Epoch: 40/300 Iteration: 396 Training loss: 0.91484\n",
      "Epoch: 40/300 Iteration: 397 Training loss: 0.94128\n",
      "Epoch: 40/300 Iteration: 398 Training loss: 0.95794\n",
      "Epoch: 40/300 Iteration: 399 Training loss: 0.97009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/300 Iteration: 400 Validation Acc: 0.4358\n",
      "Epoch: 41/300 Iteration: 400 Training loss: 0.96974\n",
      "Epoch: 41/300 Iteration: 401 Training loss: 0.98393\n",
      "Epoch: 41/300 Iteration: 402 Training loss: 0.95549\n",
      "Epoch: 41/300 Iteration: 403 Training loss: 0.99099\n",
      "Epoch: 41/300 Iteration: 404 Training loss: 0.95260\n",
      "Epoch: 40/300 Iteration: 405 Validation Acc: 0.4262\n",
      "Epoch: 41/300 Iteration: 405 Training loss: 0.96145\n",
      "Epoch: 41/300 Iteration: 406 Training loss: 0.90141\n",
      "Epoch: 41/300 Iteration: 407 Training loss: 0.89572\n",
      "Epoch: 41/300 Iteration: 408 Training loss: 0.94686\n",
      "Epoch: 41/300 Iteration: 409 Training loss: 0.94745\n",
      "Epoch: 40/300 Iteration: 410 Validation Acc: 0.4321\n",
      "Epoch: 42/300 Iteration: 410 Training loss: 0.96105\n",
      "Epoch: 42/300 Iteration: 411 Training loss: 0.96117\n",
      "Epoch: 42/300 Iteration: 412 Training loss: 0.93231\n",
      "Epoch: 42/300 Iteration: 413 Training loss: 0.99171\n",
      "Epoch: 42/300 Iteration: 414 Training loss: 0.95588\n",
      "Epoch: 41/300 Iteration: 415 Validation Acc: 0.4341\n",
      "Epoch: 42/300 Iteration: 415 Training loss: 0.94068\n",
      "Epoch: 42/300 Iteration: 416 Training loss: 0.92032\n",
      "Epoch: 42/300 Iteration: 417 Training loss: 0.89984\n",
      "Epoch: 42/300 Iteration: 418 Training loss: 0.94724\n",
      "Epoch: 42/300 Iteration: 419 Training loss: 0.94459\n",
      "Epoch: 41/300 Iteration: 420 Validation Acc: 0.4308\n",
      "Epoch: 43/300 Iteration: 420 Training loss: 0.94193\n",
      "Epoch: 43/300 Iteration: 421 Training loss: 0.94308\n",
      "Epoch: 43/300 Iteration: 422 Training loss: 0.91868\n",
      "Epoch: 43/300 Iteration: 423 Training loss: 0.95296\n",
      "Epoch: 43/300 Iteration: 424 Training loss: 0.93433\n",
      "Epoch: 42/300 Iteration: 425 Validation Acc: 0.4429\n",
      "Epoch: 43/300 Iteration: 425 Training loss: 0.91824\n",
      "Epoch: 43/300 Iteration: 426 Training loss: 0.87914\n",
      "Epoch: 43/300 Iteration: 427 Training loss: 0.87393\n",
      "Epoch: 43/300 Iteration: 428 Training loss: 0.89667\n",
      "Epoch: 43/300 Iteration: 429 Training loss: 0.90613\n",
      "Epoch: 42/300 Iteration: 430 Validation Acc: 0.4293\n",
      "Epoch: 44/300 Iteration: 430 Training loss: 0.93762\n",
      "Epoch: 44/300 Iteration: 431 Training loss: 0.95522\n",
      "Epoch: 44/300 Iteration: 432 Training loss: 0.88951\n",
      "Epoch: 44/300 Iteration: 433 Training loss: 0.93891\n",
      "Epoch: 44/300 Iteration: 434 Training loss: 0.92431\n",
      "Epoch: 43/300 Iteration: 435 Validation Acc: 0.4452\n",
      "Epoch: 44/300 Iteration: 435 Training loss: 0.90526\n",
      "Epoch: 44/300 Iteration: 436 Training loss: 0.86543\n",
      "Epoch: 44/300 Iteration: 437 Training loss: 0.85546\n",
      "Epoch: 44/300 Iteration: 438 Training loss: 0.89828\n",
      "Epoch: 44/300 Iteration: 439 Training loss: 0.90599\n",
      "Epoch: 43/300 Iteration: 440 Validation Acc: 0.4437\n",
      "Epoch: 45/300 Iteration: 440 Training loss: 0.89392\n",
      "Epoch: 45/300 Iteration: 441 Training loss: 0.92662\n",
      "Epoch: 45/300 Iteration: 442 Training loss: 0.90153\n",
      "Epoch: 45/300 Iteration: 443 Training loss: 0.90750\n",
      "Epoch: 45/300 Iteration: 444 Training loss: 0.92110\n",
      "Epoch: 44/300 Iteration: 445 Validation Acc: 0.4373\n",
      "Epoch: 45/300 Iteration: 445 Training loss: 0.91224\n",
      "Epoch: 45/300 Iteration: 446 Training loss: 0.85833\n",
      "Epoch: 45/300 Iteration: 447 Training loss: 0.83838\n",
      "Epoch: 45/300 Iteration: 448 Training loss: 0.87442\n",
      "Epoch: 45/300 Iteration: 449 Training loss: 0.89095\n",
      "Epoch: 44/300 Iteration: 450 Validation Acc: 0.4352\n",
      "Epoch: 46/300 Iteration: 450 Training loss: 0.93084\n",
      "Epoch: 46/300 Iteration: 451 Training loss: 0.91991\n",
      "Epoch: 46/300 Iteration: 452 Training loss: 0.87205\n",
      "Epoch: 46/300 Iteration: 453 Training loss: 0.89702\n",
      "Epoch: 46/300 Iteration: 454 Training loss: 0.89841\n",
      "Epoch: 45/300 Iteration: 455 Validation Acc: 0.4385\n",
      "Epoch: 46/300 Iteration: 455 Training loss: 0.89725\n",
      "Epoch: 46/300 Iteration: 456 Training loss: 0.87042\n",
      "Epoch: 46/300 Iteration: 457 Training loss: 0.85319\n",
      "Epoch: 46/300 Iteration: 458 Training loss: 0.85332\n",
      "Epoch: 46/300 Iteration: 459 Training loss: 0.88935\n",
      "Epoch: 45/300 Iteration: 460 Validation Acc: 0.4465\n",
      "Epoch: 47/300 Iteration: 460 Training loss: 0.86956\n",
      "Epoch: 47/300 Iteration: 461 Training loss: 0.90700\n",
      "Epoch: 47/300 Iteration: 462 Training loss: 0.90041\n",
      "Epoch: 47/300 Iteration: 463 Training loss: 0.89053\n",
      "Epoch: 47/300 Iteration: 464 Training loss: 0.86504\n",
      "Epoch: 46/300 Iteration: 465 Validation Acc: 0.4425\n",
      "Epoch: 47/300 Iteration: 465 Training loss: 0.88015\n",
      "Epoch: 47/300 Iteration: 466 Training loss: 0.81619\n",
      "Epoch: 47/300 Iteration: 467 Training loss: 0.84223\n",
      "Epoch: 47/300 Iteration: 468 Training loss: 0.87342\n",
      "Epoch: 47/300 Iteration: 469 Training loss: 0.83298\n",
      "Epoch: 46/300 Iteration: 470 Validation Acc: 0.4431\n",
      "Epoch: 48/300 Iteration: 470 Training loss: 0.86102\n",
      "Epoch: 48/300 Iteration: 471 Training loss: 0.87277\n",
      "Epoch: 48/300 Iteration: 472 Training loss: 0.84116\n",
      "Epoch: 48/300 Iteration: 473 Training loss: 0.88512\n",
      "Epoch: 48/300 Iteration: 474 Training loss: 0.87075\n",
      "Epoch: 47/300 Iteration: 475 Validation Acc: 0.4617\n",
      "Epoch: 48/300 Iteration: 475 Training loss: 0.83813\n",
      "Epoch: 48/300 Iteration: 476 Training loss: 0.81203\n",
      "Epoch: 48/300 Iteration: 477 Training loss: 0.80199\n",
      "Epoch: 48/300 Iteration: 478 Training loss: 0.83926\n",
      "Epoch: 48/300 Iteration: 479 Training loss: 0.82838\n",
      "Epoch: 47/300 Iteration: 480 Validation Acc: 0.4523\n",
      "Epoch: 49/300 Iteration: 480 Training loss: 0.82331\n",
      "Epoch: 49/300 Iteration: 481 Training loss: 0.87363\n",
      "Epoch: 49/300 Iteration: 482 Training loss: 0.83108\n",
      "Epoch: 49/300 Iteration: 483 Training loss: 0.82636\n",
      "Epoch: 49/300 Iteration: 484 Training loss: 0.84652\n",
      "Epoch: 48/300 Iteration: 485 Validation Acc: 0.4513\n",
      "Epoch: 49/300 Iteration: 485 Training loss: 0.87191\n",
      "Epoch: 49/300 Iteration: 486 Training loss: 0.79980\n",
      "Epoch: 49/300 Iteration: 487 Training loss: 0.79770\n",
      "Epoch: 49/300 Iteration: 488 Training loss: 0.80641\n",
      "Epoch: 49/300 Iteration: 489 Training loss: 0.81452\n",
      "Epoch: 48/300 Iteration: 490 Validation Acc: 0.4498\n",
      "Epoch: 50/300 Iteration: 490 Training loss: 0.85213\n",
      "Epoch: 50/300 Iteration: 491 Training loss: 0.82557\n",
      "Epoch: 50/300 Iteration: 492 Training loss: 0.79368\n",
      "Epoch: 50/300 Iteration: 493 Training loss: 0.84807\n",
      "Epoch: 50/300 Iteration: 494 Training loss: 0.83539\n",
      "Epoch: 49/300 Iteration: 495 Validation Acc: 0.4552\n",
      "Epoch: 50/300 Iteration: 495 Training loss: 0.81809\n",
      "Epoch: 50/300 Iteration: 496 Training loss: 0.82277\n",
      "Epoch: 50/300 Iteration: 497 Training loss: 0.82959\n",
      "Epoch: 50/300 Iteration: 498 Training loss: 0.82374\n",
      "Epoch: 50/300 Iteration: 499 Training loss: 0.78887\n",
      "Epoch: 49/300 Iteration: 500 Validation Acc: 0.4613\n",
      "Epoch: 51/300 Iteration: 500 Training loss: 0.79870\n",
      "Epoch: 51/300 Iteration: 501 Training loss: 0.86449\n",
      "Epoch: 51/300 Iteration: 502 Training loss: 0.82824\n",
      "Epoch: 51/300 Iteration: 503 Training loss: 0.79205\n",
      "Epoch: 51/300 Iteration: 504 Training loss: 0.79410\n",
      "Epoch: 50/300 Iteration: 505 Validation Acc: 0.4531\n",
      "Epoch: 51/300 Iteration: 505 Training loss: 0.80430\n",
      "Epoch: 51/300 Iteration: 506 Training loss: 0.75554\n",
      "Epoch: 51/300 Iteration: 507 Training loss: 0.80044\n",
      "Epoch: 51/300 Iteration: 508 Training loss: 0.80015\n",
      "Epoch: 51/300 Iteration: 509 Training loss: 0.76048\n",
      "Epoch: 50/300 Iteration: 510 Validation Acc: 0.4711\n",
      "Epoch: 52/300 Iteration: 510 Training loss: 0.78261\n",
      "Epoch: 52/300 Iteration: 511 Training loss: 0.78425\n",
      "Epoch: 52/300 Iteration: 512 Training loss: 0.79169\n",
      "Epoch: 52/300 Iteration: 513 Training loss: 0.81017\n",
      "Epoch: 52/300 Iteration: 514 Training loss: 0.75963\n",
      "Epoch: 51/300 Iteration: 515 Validation Acc: 0.4644\n",
      "Epoch: 52/300 Iteration: 515 Training loss: 0.75293\n",
      "Epoch: 52/300 Iteration: 516 Training loss: 0.74294\n",
      "Epoch: 52/300 Iteration: 517 Training loss: 0.73874\n",
      "Epoch: 52/300 Iteration: 518 Training loss: 0.76740\n",
      "Epoch: 52/300 Iteration: 519 Training loss: 0.75716\n",
      "Epoch: 51/300 Iteration: 520 Validation Acc: 0.4715\n",
      "Epoch: 53/300 Iteration: 520 Training loss: 0.75824\n",
      "Epoch: 53/300 Iteration: 521 Training loss: 0.78642\n",
      "Epoch: 53/300 Iteration: 522 Training loss: 0.75774\n",
      "Epoch: 53/300 Iteration: 523 Training loss: 0.77939\n",
      "Epoch: 53/300 Iteration: 524 Training loss: 0.76257\n",
      "Epoch: 52/300 Iteration: 525 Validation Acc: 0.4715\n",
      "Epoch: 53/300 Iteration: 525 Training loss: 0.73684\n",
      "Epoch: 53/300 Iteration: 526 Training loss: 0.70359\n",
      "Epoch: 53/300 Iteration: 527 Training loss: 0.72652\n",
      "Epoch: 53/300 Iteration: 528 Training loss: 0.72162\n",
      "Epoch: 53/300 Iteration: 529 Training loss: 0.72764\n",
      "Epoch: 52/300 Iteration: 530 Validation Acc: 0.4748\n",
      "Epoch: 54/300 Iteration: 530 Training loss: 0.73168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/300 Iteration: 531 Training loss: 0.74520\n",
      "Epoch: 54/300 Iteration: 532 Training loss: 0.73856\n",
      "Epoch: 54/300 Iteration: 533 Training loss: 0.76259\n",
      "Epoch: 54/300 Iteration: 534 Training loss: 0.73766\n",
      "Epoch: 53/300 Iteration: 535 Validation Acc: 0.4736\n",
      "Epoch: 54/300 Iteration: 535 Training loss: 0.73072\n",
      "Epoch: 54/300 Iteration: 536 Training loss: 0.66397\n",
      "Epoch: 54/300 Iteration: 537 Training loss: 0.67042\n",
      "Epoch: 54/300 Iteration: 538 Training loss: 0.74289\n",
      "Epoch: 54/300 Iteration: 539 Training loss: 0.70019\n",
      "Epoch: 53/300 Iteration: 540 Validation Acc: 0.4815\n",
      "Epoch: 55/300 Iteration: 540 Training loss: 0.68299\n",
      "Epoch: 55/300 Iteration: 541 Training loss: 0.72627\n",
      "Epoch: 55/300 Iteration: 542 Training loss: 0.70337\n",
      "Epoch: 55/300 Iteration: 543 Training loss: 0.72307\n",
      "Epoch: 55/300 Iteration: 544 Training loss: 0.71911\n",
      "Epoch: 54/300 Iteration: 545 Validation Acc: 0.4713\n",
      "Epoch: 55/300 Iteration: 545 Training loss: 0.71555\n",
      "Epoch: 55/300 Iteration: 546 Training loss: 0.68212\n",
      "Epoch: 55/300 Iteration: 547 Training loss: 0.66184\n",
      "Epoch: 55/300 Iteration: 548 Training loss: 0.67620\n",
      "Epoch: 55/300 Iteration: 549 Training loss: 0.70734\n",
      "Epoch: 54/300 Iteration: 550 Validation Acc: 0.4799\n",
      "Epoch: 56/300 Iteration: 550 Training loss: 0.68167\n",
      "Epoch: 56/300 Iteration: 551 Training loss: 0.69749\n",
      "Epoch: 56/300 Iteration: 552 Training loss: 0.70631\n",
      "Epoch: 56/300 Iteration: 553 Training loss: 0.70100\n",
      "Epoch: 56/300 Iteration: 554 Training loss: 0.68300\n",
      "Epoch: 55/300 Iteration: 555 Validation Acc: 0.4665\n",
      "Epoch: 56/300 Iteration: 555 Training loss: 0.71496\n",
      "Epoch: 56/300 Iteration: 556 Training loss: 0.66651\n",
      "Epoch: 56/300 Iteration: 557 Training loss: 0.68237\n",
      "Epoch: 56/300 Iteration: 558 Training loss: 0.68709\n",
      "Epoch: 56/300 Iteration: 559 Training loss: 0.68231\n",
      "Epoch: 55/300 Iteration: 560 Validation Acc: 0.4721\n",
      "Epoch: 57/300 Iteration: 560 Training loss: 0.71252\n",
      "Epoch: 57/300 Iteration: 561 Training loss: 0.70540\n",
      "Epoch: 57/300 Iteration: 562 Training loss: 0.67907\n",
      "Epoch: 57/300 Iteration: 563 Training loss: 0.73975\n",
      "Epoch: 57/300 Iteration: 564 Training loss: 0.66940\n",
      "Epoch: 56/300 Iteration: 565 Validation Acc: 0.4723\n",
      "Epoch: 57/300 Iteration: 565 Training loss: 0.68386\n",
      "Epoch: 57/300 Iteration: 566 Training loss: 0.67152\n",
      "Epoch: 57/300 Iteration: 567 Training loss: 0.66169\n",
      "Epoch: 57/300 Iteration: 568 Training loss: 0.69588\n",
      "Epoch: 57/300 Iteration: 569 Training loss: 0.68165\n",
      "Epoch: 56/300 Iteration: 570 Validation Acc: 0.4774\n",
      "Epoch: 58/300 Iteration: 570 Training loss: 0.69607\n",
      "Epoch: 58/300 Iteration: 571 Training loss: 0.73024\n",
      "Epoch: 58/300 Iteration: 572 Training loss: 0.68960\n",
      "Epoch: 58/300 Iteration: 573 Training loss: 0.70564\n",
      "Epoch: 58/300 Iteration: 574 Training loss: 0.70770\n",
      "Epoch: 57/300 Iteration: 575 Validation Acc: 0.4819\n",
      "Epoch: 58/300 Iteration: 575 Training loss: 0.65895\n",
      "Epoch: 58/300 Iteration: 576 Training loss: 0.63306\n",
      "Epoch: 58/300 Iteration: 577 Training loss: 0.67024\n",
      "Epoch: 58/300 Iteration: 578 Training loss: 0.67819\n",
      "Epoch: 58/300 Iteration: 579 Training loss: 0.70433\n",
      "Epoch: 57/300 Iteration: 580 Validation Acc: 0.4799\n",
      "Epoch: 59/300 Iteration: 580 Training loss: 0.67671\n",
      "Epoch: 59/300 Iteration: 581 Training loss: 0.69570\n",
      "Epoch: 59/300 Iteration: 582 Training loss: 0.69041\n",
      "Epoch: 59/300 Iteration: 583 Training loss: 0.70232\n",
      "Epoch: 59/300 Iteration: 584 Training loss: 0.74327\n",
      "Epoch: 58/300 Iteration: 585 Validation Acc: 0.4826\n",
      "Epoch: 59/300 Iteration: 585 Training loss: 0.69573\n",
      "Epoch: 59/300 Iteration: 586 Training loss: 0.59499\n",
      "Epoch: 59/300 Iteration: 587 Training loss: 0.62948\n",
      "Epoch: 59/300 Iteration: 588 Training loss: 0.67981\n",
      "Epoch: 59/300 Iteration: 589 Training loss: 0.70259\n",
      "Epoch: 58/300 Iteration: 590 Validation Acc: 0.4732\n",
      "Epoch: 60/300 Iteration: 590 Training loss: 0.68561\n",
      "Epoch: 60/300 Iteration: 591 Training loss: 0.68141\n",
      "Epoch: 60/300 Iteration: 592 Training loss: 0.65916\n",
      "Epoch: 60/300 Iteration: 593 Training loss: 0.67912\n",
      "Epoch: 60/300 Iteration: 594 Training loss: 0.71401\n",
      "Epoch: 59/300 Iteration: 595 Validation Acc: 0.4742\n",
      "Epoch: 60/300 Iteration: 595 Training loss: 0.71804\n",
      "Epoch: 60/300 Iteration: 596 Training loss: 0.61946\n",
      "Epoch: 60/300 Iteration: 597 Training loss: 0.59142\n",
      "Epoch: 60/300 Iteration: 598 Training loss: 0.63766\n",
      "Epoch: 60/300 Iteration: 599 Training loss: 0.68707\n",
      "Epoch: 59/300 Iteration: 600 Validation Acc: 0.4590\n",
      "Epoch: 61/300 Iteration: 600 Training loss: 0.72018\n",
      "Epoch: 61/300 Iteration: 601 Training loss: 0.69190\n",
      "Epoch: 61/300 Iteration: 602 Training loss: 0.63402\n",
      "Epoch: 61/300 Iteration: 603 Training loss: 0.67037\n",
      "Epoch: 61/300 Iteration: 604 Training loss: 0.67931\n",
      "Epoch: 60/300 Iteration: 605 Validation Acc: 0.4769\n",
      "Epoch: 61/300 Iteration: 605 Training loss: 0.70270\n",
      "Epoch: 61/300 Iteration: 606 Training loss: 0.65740\n",
      "Epoch: 61/300 Iteration: 607 Training loss: 0.62159\n",
      "Epoch: 61/300 Iteration: 608 Training loss: 0.59379\n",
      "Epoch: 61/300 Iteration: 609 Training loss: 0.63671\n",
      "Epoch: 60/300 Iteration: 610 Validation Acc: 0.4700\n",
      "Epoch: 62/300 Iteration: 610 Training loss: 0.68533\n",
      "Epoch: 62/300 Iteration: 611 Training loss: 0.72099\n",
      "Epoch: 62/300 Iteration: 612 Training loss: 0.66920\n",
      "Epoch: 62/300 Iteration: 613 Training loss: 0.63720\n",
      "Epoch: 62/300 Iteration: 614 Training loss: 0.64662\n",
      "Epoch: 61/300 Iteration: 615 Validation Acc: 0.4694\n",
      "Epoch: 62/300 Iteration: 615 Training loss: 0.67908\n",
      "Epoch: 62/300 Iteration: 616 Training loss: 0.64414\n",
      "Epoch: 62/300 Iteration: 617 Training loss: 0.65851\n",
      "Epoch: 62/300 Iteration: 618 Training loss: 0.63657\n",
      "Epoch: 62/300 Iteration: 619 Training loss: 0.60136\n",
      "Epoch: 61/300 Iteration: 620 Validation Acc: 0.4686\n",
      "Epoch: 63/300 Iteration: 620 Training loss: 0.67337\n",
      "Epoch: 63/300 Iteration: 621 Training loss: 0.66938\n",
      "Epoch: 63/300 Iteration: 622 Training loss: 0.67783\n",
      "Epoch: 63/300 Iteration: 623 Training loss: 0.67615\n",
      "Epoch: 63/300 Iteration: 624 Training loss: 0.61824\n",
      "Epoch: 62/300 Iteration: 625 Validation Acc: 0.4815\n",
      "Epoch: 63/300 Iteration: 625 Training loss: 0.63424\n",
      "Epoch: 63/300 Iteration: 626 Training loss: 0.62813\n",
      "Epoch: 63/300 Iteration: 627 Training loss: 0.63999\n",
      "Epoch: 63/300 Iteration: 628 Training loss: 0.64316\n",
      "Epoch: 63/300 Iteration: 629 Training loss: 0.61464\n",
      "Epoch: 62/300 Iteration: 630 Validation Acc: 0.4786\n",
      "Epoch: 64/300 Iteration: 630 Training loss: 0.62464\n",
      "Epoch: 64/300 Iteration: 631 Training loss: 0.68960\n",
      "Epoch: 64/300 Iteration: 632 Training loss: 0.63229\n",
      "Epoch: 64/300 Iteration: 633 Training loss: 0.66875\n",
      "Epoch: 64/300 Iteration: 634 Training loss: 0.67119\n",
      "Epoch: 63/300 Iteration: 635 Validation Acc: 0.4882\n",
      "Epoch: 64/300 Iteration: 635 Training loss: 0.62495\n",
      "Epoch: 64/300 Iteration: 636 Training loss: 0.58284\n",
      "Epoch: 64/300 Iteration: 637 Training loss: 0.61847\n",
      "Epoch: 64/300 Iteration: 638 Training loss: 0.62299\n",
      "Epoch: 64/300 Iteration: 639 Training loss: 0.61186\n",
      "Epoch: 63/300 Iteration: 640 Validation Acc: 0.4822\n",
      "Epoch: 65/300 Iteration: 640 Training loss: 0.61388\n",
      "Epoch: 65/300 Iteration: 641 Training loss: 0.63962\n",
      "Epoch: 65/300 Iteration: 642 Training loss: 0.60905\n",
      "Epoch: 65/300 Iteration: 643 Training loss: 0.63130\n",
      "Epoch: 65/300 Iteration: 644 Training loss: 0.65483\n",
      "Epoch: 64/300 Iteration: 645 Validation Acc: 0.4838\n",
      "Epoch: 65/300 Iteration: 645 Training loss: 0.62325\n",
      "Epoch: 65/300 Iteration: 646 Training loss: 0.55484\n",
      "Epoch: 65/300 Iteration: 647 Training loss: 0.61445\n",
      "Epoch: 65/300 Iteration: 648 Training loss: 0.60550\n",
      "Epoch: 65/300 Iteration: 649 Training loss: 0.57656\n",
      "Epoch: 64/300 Iteration: 650 Validation Acc: 0.4792\n",
      "Epoch: 66/300 Iteration: 650 Training loss: 0.60786\n",
      "Epoch: 66/300 Iteration: 651 Training loss: 0.66406\n",
      "Epoch: 66/300 Iteration: 652 Training loss: 0.62490\n",
      "Epoch: 66/300 Iteration: 653 Training loss: 0.60364\n",
      "Epoch: 66/300 Iteration: 654 Training loss: 0.61836\n",
      "Epoch: 65/300 Iteration: 655 Validation Acc: 0.4690\n",
      "Epoch: 66/300 Iteration: 655 Training loss: 0.65440\n",
      "Epoch: 66/300 Iteration: 656 Training loss: 0.58406\n",
      "Epoch: 66/300 Iteration: 657 Training loss: 0.58873\n",
      "Epoch: 66/300 Iteration: 658 Training loss: 0.63168\n",
      "Epoch: 66/300 Iteration: 659 Training loss: 0.60498\n",
      "Epoch: 65/300 Iteration: 660 Validation Acc: 0.4853\n",
      "Epoch: 67/300 Iteration: 660 Training loss: 0.57183\n",
      "Epoch: 67/300 Iteration: 661 Training loss: 0.62497\n",
      "Epoch: 67/300 Iteration: 662 Training loss: 0.65635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/300 Iteration: 663 Training loss: 0.64800\n",
      "Epoch: 67/300 Iteration: 664 Training loss: 0.60747\n",
      "Epoch: 66/300 Iteration: 665 Validation Acc: 0.4707\n",
      "Epoch: 67/300 Iteration: 665 Training loss: 0.64926\n",
      "Epoch: 67/300 Iteration: 666 Training loss: 0.64148\n",
      "Epoch: 67/300 Iteration: 667 Training loss: 0.63030\n",
      "Epoch: 67/300 Iteration: 668 Training loss: 0.56986\n",
      "Epoch: 67/300 Iteration: 669 Training loss: 0.60622\n",
      "Epoch: 66/300 Iteration: 670 Validation Acc: 0.4734\n",
      "Epoch: 68/300 Iteration: 670 Training loss: 0.63945\n",
      "Epoch: 68/300 Iteration: 671 Training loss: 0.64590\n",
      "Epoch: 68/300 Iteration: 672 Training loss: 0.59531\n",
      "Epoch: 68/300 Iteration: 673 Training loss: 0.63950\n",
      "Epoch: 68/300 Iteration: 674 Training loss: 0.62842\n",
      "Epoch: 67/300 Iteration: 675 Validation Acc: 0.4778\n",
      "Epoch: 68/300 Iteration: 675 Training loss: 0.62268\n",
      "Epoch: 68/300 Iteration: 676 Training loss: 0.64131\n",
      "Epoch: 68/300 Iteration: 677 Training loss: 0.70031\n",
      "Epoch: 68/300 Iteration: 678 Training loss: 0.65649\n",
      "Epoch: 68/300 Iteration: 679 Training loss: 0.60862\n",
      "Epoch: 67/300 Iteration: 680 Validation Acc: 0.4989\n",
      "Epoch: 69/300 Iteration: 680 Training loss: 0.56178\n",
      "Epoch: 69/300 Iteration: 681 Training loss: 0.58290\n",
      "Epoch: 69/300 Iteration: 682 Training loss: 0.59768\n",
      "Epoch: 69/300 Iteration: 683 Training loss: 0.66477\n",
      "Epoch: 69/300 Iteration: 684 Training loss: 0.57774\n",
      "Epoch: 68/300 Iteration: 685 Validation Acc: 0.4893\n",
      "Epoch: 69/300 Iteration: 685 Training loss: 0.57904\n",
      "Epoch: 69/300 Iteration: 686 Training loss: 0.51510\n",
      "Epoch: 69/300 Iteration: 687 Training loss: 0.55828\n",
      "Epoch: 69/300 Iteration: 688 Training loss: 0.60416\n",
      "Epoch: 69/300 Iteration: 689 Training loss: 0.59799\n",
      "Epoch: 68/300 Iteration: 690 Validation Acc: 0.4968\n",
      "Epoch: 70/300 Iteration: 690 Training loss: 0.58031\n",
      "Epoch: 70/300 Iteration: 691 Training loss: 0.59255\n",
      "Epoch: 70/300 Iteration: 692 Training loss: 0.55995\n",
      "Epoch: 70/300 Iteration: 693 Training loss: 0.61073\n",
      "Epoch: 70/300 Iteration: 694 Training loss: 0.57971\n",
      "Epoch: 69/300 Iteration: 695 Validation Acc: 0.4943\n",
      "Epoch: 70/300 Iteration: 695 Training loss: 0.54977\n",
      "Epoch: 70/300 Iteration: 696 Training loss: 0.49809\n",
      "Epoch: 70/300 Iteration: 697 Training loss: 0.49608\n",
      "Epoch: 70/300 Iteration: 698 Training loss: 0.52933\n",
      "Epoch: 70/300 Iteration: 699 Training loss: 0.57740\n",
      "Epoch: 69/300 Iteration: 700 Validation Acc: 0.4899\n",
      "Epoch: 71/300 Iteration: 700 Training loss: 0.57286\n",
      "Epoch: 71/300 Iteration: 701 Training loss: 0.54567\n",
      "Epoch: 71/300 Iteration: 702 Training loss: 0.51084\n",
      "Epoch: 71/300 Iteration: 703 Training loss: 0.53372\n",
      "Epoch: 71/300 Iteration: 704 Training loss: 0.56395\n",
      "Epoch: 70/300 Iteration: 705 Validation Acc: 0.4893\n",
      "Epoch: 71/300 Iteration: 705 Training loss: 0.57423\n",
      "Epoch: 71/300 Iteration: 706 Training loss: 0.50632\n",
      "Epoch: 71/300 Iteration: 707 Training loss: 0.48783\n",
      "Epoch: 71/300 Iteration: 708 Training loss: 0.51077\n",
      "Epoch: 71/300 Iteration: 709 Training loss: 0.53595\n",
      "Epoch: 70/300 Iteration: 710 Validation Acc: 0.4886\n",
      "Epoch: 72/300 Iteration: 710 Training loss: 0.55584\n",
      "Epoch: 72/300 Iteration: 711 Training loss: 0.55750\n",
      "Epoch: 72/300 Iteration: 712 Training loss: 0.51033\n",
      "Epoch: 72/300 Iteration: 713 Training loss: 0.52505\n",
      "Epoch: 72/300 Iteration: 714 Training loss: 0.54118\n",
      "Epoch: 71/300 Iteration: 715 Validation Acc: 0.4909\n",
      "Epoch: 72/300 Iteration: 715 Training loss: 0.54695\n",
      "Epoch: 72/300 Iteration: 716 Training loss: 0.50924\n",
      "Epoch: 72/300 Iteration: 717 Training loss: 0.48196\n",
      "Epoch: 72/300 Iteration: 718 Training loss: 0.49228\n",
      "Epoch: 72/300 Iteration: 719 Training loss: 0.52840\n",
      "Epoch: 71/300 Iteration: 720 Validation Acc: 0.4949\n",
      "Epoch: 73/300 Iteration: 720 Training loss: 0.54943\n",
      "Epoch: 73/300 Iteration: 721 Training loss: 0.54723\n",
      "Epoch: 73/300 Iteration: 722 Training loss: 0.50275\n",
      "Epoch: 73/300 Iteration: 723 Training loss: 0.50481\n",
      "Epoch: 73/300 Iteration: 724 Training loss: 0.52445\n",
      "Epoch: 72/300 Iteration: 725 Validation Acc: 0.4880\n",
      "Epoch: 73/300 Iteration: 725 Training loss: 0.55787\n",
      "Epoch: 73/300 Iteration: 726 Training loss: 0.50110\n",
      "Epoch: 73/300 Iteration: 727 Training loss: 0.48398\n",
      "Epoch: 73/300 Iteration: 728 Training loss: 0.47209\n",
      "Epoch: 73/300 Iteration: 729 Training loss: 0.50827\n",
      "Epoch: 72/300 Iteration: 730 Validation Acc: 0.4897\n",
      "Epoch: 74/300 Iteration: 730 Training loss: 0.54557\n",
      "Epoch: 74/300 Iteration: 731 Training loss: 0.54684\n",
      "Epoch: 74/300 Iteration: 732 Training loss: 0.51822\n",
      "Epoch: 74/300 Iteration: 733 Training loss: 0.51824\n",
      "Epoch: 74/300 Iteration: 734 Training loss: 0.50777\n",
      "Epoch: 73/300 Iteration: 735 Validation Acc: 0.4920\n",
      "Epoch: 74/300 Iteration: 735 Training loss: 0.53428\n",
      "Epoch: 74/300 Iteration: 736 Training loss: 0.52364\n",
      "Epoch: 74/300 Iteration: 737 Training loss: 0.52036\n",
      "Epoch: 74/300 Iteration: 738 Training loss: 0.49200\n",
      "Epoch: 74/300 Iteration: 739 Training loss: 0.49017\n",
      "Epoch: 73/300 Iteration: 740 Validation Acc: 0.4989\n",
      "Epoch: 75/300 Iteration: 740 Training loss: 0.49348\n",
      "Epoch: 75/300 Iteration: 741 Training loss: 0.54923\n",
      "Epoch: 75/300 Iteration: 742 Training loss: 0.50913\n",
      "Epoch: 75/300 Iteration: 743 Training loss: 0.52084\n",
      "Epoch: 75/300 Iteration: 744 Training loss: 0.51413\n",
      "Epoch: 74/300 Iteration: 745 Validation Acc: 0.4968\n",
      "Epoch: 75/300 Iteration: 745 Training loss: 0.52529\n",
      "Epoch: 75/300 Iteration: 746 Training loss: 0.52131\n",
      "Epoch: 75/300 Iteration: 747 Training loss: 0.53084\n",
      "Epoch: 75/300 Iteration: 748 Training loss: 0.53067\n",
      "Epoch: 75/300 Iteration: 749 Training loss: 0.53275\n",
      "Epoch: 74/300 Iteration: 750 Validation Acc: 0.4920\n",
      "Epoch: 76/300 Iteration: 750 Training loss: 0.53793\n",
      "Epoch: 76/300 Iteration: 751 Training loss: 0.58925\n",
      "Epoch: 76/300 Iteration: 752 Training loss: 0.48617\n",
      "Epoch: 76/300 Iteration: 753 Training loss: 0.47518\n",
      "Epoch: 76/300 Iteration: 754 Training loss: 0.51730\n",
      "Epoch: 75/300 Iteration: 755 Validation Acc: 0.4963\n",
      "Epoch: 76/300 Iteration: 755 Training loss: 0.54380\n",
      "Epoch: 76/300 Iteration: 756 Training loss: 0.47865\n",
      "Epoch: 76/300 Iteration: 757 Training loss: 0.48590\n",
      "Epoch: 76/300 Iteration: 758 Training loss: 0.49933\n",
      "Epoch: 76/300 Iteration: 759 Training loss: 0.51637\n",
      "Epoch: 75/300 Iteration: 760 Validation Acc: 0.5022\n",
      "Epoch: 77/300 Iteration: 760 Training loss: 0.51861\n",
      "Epoch: 77/300 Iteration: 761 Training loss: 0.47489\n",
      "Epoch: 77/300 Iteration: 762 Training loss: 0.45255\n",
      "Epoch: 77/300 Iteration: 763 Training loss: 0.49989\n",
      "Epoch: 77/300 Iteration: 764 Training loss: 0.48947\n",
      "Epoch: 76/300 Iteration: 765 Validation Acc: 0.5085\n",
      "Epoch: 77/300 Iteration: 765 Training loss: 0.48573\n",
      "Epoch: 77/300 Iteration: 766 Training loss: 0.46683\n",
      "Epoch: 77/300 Iteration: 767 Training loss: 0.45740\n",
      "Epoch: 77/300 Iteration: 768 Training loss: 0.43965\n",
      "Epoch: 77/300 Iteration: 769 Training loss: 0.45653\n",
      "Epoch: 76/300 Iteration: 770 Validation Acc: 0.5020\n",
      "Epoch: 78/300 Iteration: 770 Training loss: 0.47488\n",
      "Epoch: 78/300 Iteration: 771 Training loss: 0.48509\n",
      "Epoch: 78/300 Iteration: 772 Training loss: 0.45574\n",
      "Epoch: 78/300 Iteration: 773 Training loss: 0.45605\n",
      "Epoch: 78/300 Iteration: 774 Training loss: 0.46271\n",
      "Epoch: 77/300 Iteration: 775 Validation Acc: 0.5032\n",
      "Epoch: 78/300 Iteration: 775 Training loss: 0.47005\n",
      "Epoch: 78/300 Iteration: 776 Training loss: 0.46792\n",
      "Epoch: 78/300 Iteration: 777 Training loss: 0.47499\n",
      "Epoch: 78/300 Iteration: 778 Training loss: 0.44413\n",
      "Epoch: 78/300 Iteration: 779 Training loss: 0.43288\n",
      "Epoch: 77/300 Iteration: 780 Validation Acc: 0.5009\n",
      "Epoch: 79/300 Iteration: 780 Training loss: 0.48023\n",
      "Epoch: 79/300 Iteration: 781 Training loss: 0.49934\n",
      "Epoch: 79/300 Iteration: 782 Training loss: 0.45263\n",
      "Epoch: 79/300 Iteration: 783 Training loss: 0.45431\n",
      "Epoch: 79/300 Iteration: 784 Training loss: 0.45889\n",
      "Epoch: 78/300 Iteration: 785 Validation Acc: 0.5032\n",
      "Epoch: 79/300 Iteration: 785 Training loss: 0.46867\n",
      "Epoch: 79/300 Iteration: 786 Training loss: 0.48344\n",
      "Epoch: 79/300 Iteration: 787 Training loss: 0.50201\n",
      "Epoch: 79/300 Iteration: 788 Training loss: 0.47841\n",
      "Epoch: 79/300 Iteration: 789 Training loss: 0.43323\n",
      "Epoch: 78/300 Iteration: 790 Validation Acc: 0.5074\n",
      "Epoch: 80/300 Iteration: 790 Training loss: 0.45735\n",
      "Epoch: 80/300 Iteration: 791 Training loss: 0.54058\n",
      "Epoch: 80/300 Iteration: 792 Training loss: 0.48719\n",
      "Epoch: 80/300 Iteration: 793 Training loss: 0.44532\n",
      "Epoch: 80/300 Iteration: 794 Training loss: 0.45974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/300 Iteration: 795 Validation Acc: 0.4915\n",
      "Epoch: 80/300 Iteration: 795 Training loss: 0.49160\n",
      "Epoch: 80/300 Iteration: 796 Training loss: 0.48777\n",
      "Epoch: 80/300 Iteration: 797 Training loss: 0.51898\n",
      "Epoch: 80/300 Iteration: 798 Training loss: 0.50776\n",
      "Epoch: 80/300 Iteration: 799 Training loss: 0.46998\n",
      "Epoch: 79/300 Iteration: 800 Validation Acc: 0.5224\n",
      "Epoch: 81/300 Iteration: 800 Training loss: 0.43639\n",
      "Epoch: 81/300 Iteration: 801 Training loss: 0.49023\n",
      "Epoch: 81/300 Iteration: 802 Training loss: 0.56220\n",
      "Epoch: 81/300 Iteration: 803 Training loss: 0.48826\n",
      "Epoch: 81/300 Iteration: 804 Training loss: 0.41243\n",
      "Epoch: 80/300 Iteration: 805 Validation Acc: 0.4932\n",
      "Epoch: 81/300 Iteration: 805 Training loss: 0.46577\n",
      "Epoch: 81/300 Iteration: 806 Training loss: 0.51157\n",
      "Epoch: 81/300 Iteration: 807 Training loss: 0.53547\n",
      "Epoch: 81/300 Iteration: 808 Training loss: 0.51916\n",
      "Epoch: 81/300 Iteration: 809 Training loss: 0.50360\n",
      "Epoch: 80/300 Iteration: 810 Validation Acc: 0.5176\n",
      "Epoch: 82/300 Iteration: 810 Training loss: 0.48435\n",
      "Epoch: 82/300 Iteration: 811 Training loss: 0.47480\n",
      "Epoch: 82/300 Iteration: 812 Training loss: 0.46605\n",
      "Epoch: 82/300 Iteration: 813 Training loss: 0.55486\n",
      "Epoch: 82/300 Iteration: 814 Training loss: 0.48292\n",
      "Epoch: 81/300 Iteration: 815 Validation Acc: 0.5206\n",
      "Epoch: 82/300 Iteration: 815 Training loss: 0.40243\n",
      "Epoch: 82/300 Iteration: 816 Training loss: 0.40675\n",
      "Epoch: 82/300 Iteration: 817 Training loss: 0.50913\n",
      "Epoch: 82/300 Iteration: 818 Training loss: 0.50410\n",
      "Epoch: 82/300 Iteration: 819 Training loss: 0.48369\n",
      "Epoch: 81/300 Iteration: 820 Validation Acc: 0.5114\n",
      "Epoch: 83/300 Iteration: 820 Training loss: 0.47814\n",
      "Epoch: 83/300 Iteration: 821 Training loss: 0.47878\n",
      "Epoch: 83/300 Iteration: 822 Training loss: 0.45469\n",
      "Epoch: 83/300 Iteration: 823 Training loss: 0.44135\n",
      "Epoch: 83/300 Iteration: 824 Training loss: 0.47013\n",
      "Epoch: 82/300 Iteration: 825 Validation Acc: 0.5099\n",
      "Epoch: 83/300 Iteration: 825 Training loss: 0.45696\n",
      "Epoch: 83/300 Iteration: 826 Training loss: 0.39496\n",
      "Epoch: 83/300 Iteration: 827 Training loss: 0.41588\n",
      "Epoch: 83/300 Iteration: 828 Training loss: 0.44388\n",
      "Epoch: 83/300 Iteration: 829 Training loss: 0.43538\n",
      "Epoch: 82/300 Iteration: 830 Validation Acc: 0.5101\n",
      "Epoch: 84/300 Iteration: 830 Training loss: 0.45551\n",
      "Epoch: 84/300 Iteration: 831 Training loss: 0.45822\n",
      "Epoch: 84/300 Iteration: 832 Training loss: 0.41275\n",
      "Epoch: 84/300 Iteration: 833 Training loss: 0.41351\n",
      "Epoch: 84/300 Iteration: 834 Training loss: 0.42937\n",
      "Epoch: 83/300 Iteration: 835 Validation Acc: 0.5170\n",
      "Epoch: 84/300 Iteration: 835 Training loss: 0.41314\n",
      "Epoch: 84/300 Iteration: 836 Training loss: 0.41610\n",
      "Epoch: 84/300 Iteration: 837 Training loss: 0.40638\n",
      "Epoch: 84/300 Iteration: 838 Training loss: 0.41056\n",
      "Epoch: 84/300 Iteration: 839 Training loss: 0.39190\n",
      "Epoch: 83/300 Iteration: 840 Validation Acc: 0.5162\n",
      "Epoch: 85/300 Iteration: 840 Training loss: 0.42853\n",
      "Epoch: 85/300 Iteration: 841 Training loss: 0.45068\n",
      "Epoch: 85/300 Iteration: 842 Training loss: 0.41147\n",
      "Epoch: 85/300 Iteration: 843 Training loss: 0.38294\n",
      "Epoch: 85/300 Iteration: 844 Training loss: 0.40920\n",
      "Epoch: 84/300 Iteration: 845 Validation Acc: 0.5168\n",
      "Epoch: 85/300 Iteration: 845 Training loss: 0.40700\n",
      "Epoch: 85/300 Iteration: 846 Training loss: 0.38153\n",
      "Epoch: 85/300 Iteration: 847 Training loss: 0.38889\n",
      "Epoch: 85/300 Iteration: 848 Training loss: 0.40109\n",
      "Epoch: 85/300 Iteration: 849 Training loss: 0.38988\n",
      "Epoch: 84/300 Iteration: 850 Validation Acc: 0.5252\n",
      "Epoch: 86/300 Iteration: 850 Training loss: 0.39190\n",
      "Epoch: 86/300 Iteration: 851 Training loss: 0.41287\n",
      "Epoch: 86/300 Iteration: 852 Training loss: 0.40162\n",
      "Epoch: 86/300 Iteration: 853 Training loss: 0.39704\n",
      "Epoch: 86/300 Iteration: 854 Training loss: 0.39316\n",
      "Epoch: 85/300 Iteration: 855 Validation Acc: 0.5147\n",
      "Epoch: 86/300 Iteration: 855 Training loss: 0.40452\n",
      "Epoch: 86/300 Iteration: 856 Training loss: 0.38522\n",
      "Epoch: 86/300 Iteration: 857 Training loss: 0.38510\n",
      "Epoch: 86/300 Iteration: 858 Training loss: 0.38671\n",
      "Epoch: 86/300 Iteration: 859 Training loss: 0.40236\n",
      "Epoch: 85/300 Iteration: 860 Validation Acc: 0.5193\n",
      "Epoch: 87/300 Iteration: 860 Training loss: 0.42349\n",
      "Epoch: 87/300 Iteration: 861 Training loss: 0.41200\n",
      "Epoch: 87/300 Iteration: 862 Training loss: 0.38900\n",
      "Epoch: 87/300 Iteration: 863 Training loss: 0.40309\n",
      "Epoch: 87/300 Iteration: 864 Training loss: 0.38262\n",
      "Epoch: 86/300 Iteration: 865 Validation Acc: 0.5181\n",
      "Epoch: 87/300 Iteration: 865 Training loss: 0.37236\n",
      "Epoch: 87/300 Iteration: 866 Training loss: 0.42286\n",
      "Epoch: 87/300 Iteration: 867 Training loss: 0.38923\n",
      "Epoch: 87/300 Iteration: 868 Training loss: 0.38302\n",
      "Epoch: 87/300 Iteration: 869 Training loss: 0.38300\n",
      "Epoch: 86/300 Iteration: 870 Validation Acc: 0.5197\n",
      "Epoch: 88/300 Iteration: 870 Training loss: 0.41965\n",
      "Epoch: 88/300 Iteration: 871 Training loss: 0.45954\n",
      "Epoch: 88/300 Iteration: 872 Training loss: 0.44093\n",
      "Epoch: 88/300 Iteration: 873 Training loss: 0.43735\n",
      "Epoch: 88/300 Iteration: 874 Training loss: 0.43432\n",
      "Epoch: 87/300 Iteration: 875 Validation Acc: 0.5222\n",
      "Epoch: 88/300 Iteration: 875 Training loss: 0.37958\n",
      "Epoch: 88/300 Iteration: 876 Training loss: 0.34157\n",
      "Epoch: 88/300 Iteration: 877 Training loss: 0.45705\n",
      "Epoch: 88/300 Iteration: 878 Training loss: 0.44946\n",
      "Epoch: 88/300 Iteration: 879 Training loss: 0.36875\n",
      "Epoch: 87/300 Iteration: 880 Validation Acc: 0.5277\n",
      "Epoch: 89/300 Iteration: 880 Training loss: 0.38152\n",
      "Epoch: 89/300 Iteration: 881 Training loss: 0.41224\n",
      "Epoch: 89/300 Iteration: 882 Training loss: 0.44915\n",
      "Epoch: 89/300 Iteration: 883 Training loss: 0.45847\n",
      "Epoch: 89/300 Iteration: 884 Training loss: 0.43906\n",
      "Epoch: 88/300 Iteration: 885 Validation Acc: 0.5143\n",
      "Epoch: 89/300 Iteration: 885 Training loss: 0.42460\n",
      "Epoch: 89/300 Iteration: 886 Training loss: 0.38778\n",
      "Epoch: 89/300 Iteration: 887 Training loss: 0.38252\n",
      "Epoch: 89/300 Iteration: 888 Training loss: 0.43451\n",
      "Epoch: 89/300 Iteration: 889 Training loss: 0.45769\n",
      "Epoch: 88/300 Iteration: 890 Validation Acc: 0.5366\n",
      "Epoch: 90/300 Iteration: 890 Training loss: 0.38621\n",
      "Epoch: 90/300 Iteration: 891 Training loss: 0.38434\n",
      "Epoch: 90/300 Iteration: 892 Training loss: 0.41586\n",
      "Epoch: 90/300 Iteration: 893 Training loss: 0.44862\n",
      "Epoch: 90/300 Iteration: 894 Training loss: 0.41803\n",
      "Epoch: 89/300 Iteration: 895 Validation Acc: 0.5135\n",
      "Epoch: 90/300 Iteration: 895 Training loss: 0.41625\n",
      "Epoch: 90/300 Iteration: 896 Training loss: 0.42241\n",
      "Epoch: 90/300 Iteration: 897 Training loss: 0.44622\n",
      "Epoch: 90/300 Iteration: 898 Training loss: 0.41774\n",
      "Epoch: 90/300 Iteration: 899 Training loss: 0.40879\n",
      "Epoch: 89/300 Iteration: 900 Validation Acc: 0.5266\n",
      "Epoch: 91/300 Iteration: 900 Training loss: 0.41665\n",
      "Epoch: 91/300 Iteration: 901 Training loss: 0.40680\n",
      "Epoch: 91/300 Iteration: 902 Training loss: 0.38343\n",
      "Epoch: 91/300 Iteration: 903 Training loss: 0.41060\n",
      "Epoch: 91/300 Iteration: 904 Training loss: 0.37839\n",
      "Epoch: 90/300 Iteration: 905 Validation Acc: 0.5266\n",
      "Epoch: 91/300 Iteration: 905 Training loss: 0.35896\n",
      "Epoch: 91/300 Iteration: 906 Training loss: 0.38489\n",
      "Epoch: 91/300 Iteration: 907 Training loss: 0.36127\n",
      "Epoch: 91/300 Iteration: 908 Training loss: 0.36393\n",
      "Epoch: 91/300 Iteration: 909 Training loss: 0.36369\n",
      "Epoch: 90/300 Iteration: 910 Validation Acc: 0.5341\n",
      "Epoch: 92/300 Iteration: 910 Training loss: 0.38752\n",
      "Epoch: 92/300 Iteration: 911 Training loss: 0.39185\n",
      "Epoch: 92/300 Iteration: 912 Training loss: 0.37598\n",
      "Epoch: 92/300 Iteration: 913 Training loss: 0.38637\n",
      "Epoch: 92/300 Iteration: 914 Training loss: 0.37485\n",
      "Epoch: 91/300 Iteration: 915 Validation Acc: 0.5421\n",
      "Epoch: 92/300 Iteration: 915 Training loss: 0.35152\n",
      "Epoch: 92/300 Iteration: 916 Training loss: 0.34132\n",
      "Epoch: 92/300 Iteration: 917 Training loss: 0.42958\n",
      "Epoch: 92/300 Iteration: 918 Training loss: 0.36139\n",
      "Epoch: 92/300 Iteration: 919 Training loss: 0.33255\n",
      "Epoch: 91/300 Iteration: 920 Validation Acc: 0.5274\n",
      "Epoch: 93/300 Iteration: 920 Training loss: 0.38364\n",
      "Epoch: 93/300 Iteration: 921 Training loss: 0.40087\n",
      "Epoch: 93/300 Iteration: 922 Training loss: 0.37707\n",
      "Epoch: 93/300 Iteration: 923 Training loss: 0.42389\n",
      "Epoch: 93/300 Iteration: 924 Training loss: 0.41636\n",
      "Epoch: 92/300 Iteration: 925 Validation Acc: 0.5343\n",
      "Epoch: 93/300 Iteration: 925 Training loss: 0.38856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/300 Iteration: 926 Training loss: 0.35889\n",
      "Epoch: 93/300 Iteration: 927 Training loss: 0.36038\n",
      "Epoch: 93/300 Iteration: 928 Training loss: 0.38719\n",
      "Epoch: 93/300 Iteration: 929 Training loss: 0.40837\n",
      "Epoch: 92/300 Iteration: 930 Validation Acc: 0.5387\n",
      "Epoch: 94/300 Iteration: 930 Training loss: 0.34794\n",
      "Epoch: 94/300 Iteration: 931 Training loss: 0.35985\n",
      "Epoch: 94/300 Iteration: 932 Training loss: 0.37224\n",
      "Epoch: 94/300 Iteration: 933 Training loss: 0.39364\n",
      "Epoch: 94/300 Iteration: 934 Training loss: 0.39340\n",
      "Epoch: 93/300 Iteration: 935 Validation Acc: 0.5302\n",
      "Epoch: 94/300 Iteration: 935 Training loss: 0.38785\n",
      "Epoch: 94/300 Iteration: 936 Training loss: 0.36642\n",
      "Epoch: 94/300 Iteration: 937 Training loss: 0.38047\n",
      "Epoch: 94/300 Iteration: 938 Training loss: 0.37329\n",
      "Epoch: 94/300 Iteration: 939 Training loss: 0.37540\n",
      "Epoch: 93/300 Iteration: 940 Validation Acc: 0.5348\n",
      "Epoch: 95/300 Iteration: 940 Training loss: 0.38944\n",
      "Epoch: 95/300 Iteration: 941 Training loss: 0.37700\n",
      "Epoch: 95/300 Iteration: 942 Training loss: 0.34368\n",
      "Epoch: 95/300 Iteration: 943 Training loss: 0.34600\n",
      "Epoch: 95/300 Iteration: 944 Training loss: 0.38528\n",
      "Epoch: 94/300 Iteration: 945 Validation Acc: 0.5345\n",
      "Epoch: 95/300 Iteration: 945 Training loss: 0.37803\n",
      "Epoch: 95/300 Iteration: 946 Training loss: 0.33838\n",
      "Epoch: 95/300 Iteration: 947 Training loss: 0.35988\n",
      "Epoch: 95/300 Iteration: 948 Training loss: 0.34961\n",
      "Epoch: 95/300 Iteration: 949 Training loss: 0.35991\n",
      "Epoch: 94/300 Iteration: 950 Validation Acc: 0.5358\n",
      "Epoch: 96/300 Iteration: 950 Training loss: 0.36321\n",
      "Epoch: 96/300 Iteration: 951 Training loss: 0.35445\n",
      "Epoch: 96/300 Iteration: 952 Training loss: 0.34344\n",
      "Epoch: 96/300 Iteration: 953 Training loss: 0.37347\n",
      "Epoch: 96/300 Iteration: 954 Training loss: 0.37089\n",
      "Epoch: 95/300 Iteration: 955 Validation Acc: 0.5385\n",
      "Epoch: 96/300 Iteration: 955 Training loss: 0.35350\n",
      "Epoch: 96/300 Iteration: 956 Training loss: 0.31338\n",
      "Epoch: 96/300 Iteration: 957 Training loss: 0.32307\n",
      "Epoch: 96/300 Iteration: 958 Training loss: 0.35093\n",
      "Epoch: 96/300 Iteration: 959 Training loss: 0.35323\n",
      "Epoch: 95/300 Iteration: 960 Validation Acc: 0.5408\n",
      "Epoch: 97/300 Iteration: 960 Training loss: 0.33963\n",
      "Epoch: 97/300 Iteration: 961 Training loss: 0.34732\n",
      "Epoch: 97/300 Iteration: 962 Training loss: 0.33014\n",
      "Epoch: 97/300 Iteration: 963 Training loss: 0.32679\n",
      "Epoch: 97/300 Iteration: 964 Training loss: 0.36559\n",
      "Epoch: 96/300 Iteration: 965 Validation Acc: 0.5404\n",
      "Epoch: 97/300 Iteration: 965 Training loss: 0.34837\n",
      "Epoch: 97/300 Iteration: 966 Training loss: 0.31486\n",
      "Epoch: 97/300 Iteration: 967 Training loss: 0.30993\n",
      "Epoch: 97/300 Iteration: 968 Training loss: 0.31809\n",
      "Epoch: 97/300 Iteration: 969 Training loss: 0.34613\n",
      "Epoch: 96/300 Iteration: 970 Validation Acc: 0.5335\n",
      "Epoch: 98/300 Iteration: 970 Training loss: 0.37854\n",
      "Epoch: 98/300 Iteration: 971 Training loss: 0.33423\n",
      "Epoch: 98/300 Iteration: 972 Training loss: 0.28524\n",
      "Epoch: 98/300 Iteration: 973 Training loss: 0.30732\n",
      "Epoch: 98/300 Iteration: 974 Training loss: 0.36990\n",
      "Epoch: 97/300 Iteration: 975 Validation Acc: 0.5293\n",
      "Epoch: 98/300 Iteration: 975 Training loss: 0.35813\n",
      "Epoch: 98/300 Iteration: 976 Training loss: 0.29667\n",
      "Epoch: 98/300 Iteration: 977 Training loss: 0.29637\n",
      "Epoch: 98/300 Iteration: 978 Training loss: 0.30562\n",
      "Epoch: 98/300 Iteration: 979 Training loss: 0.32249\n",
      "Epoch: 97/300 Iteration: 980 Validation Acc: 0.5398\n",
      "Epoch: 99/300 Iteration: 980 Training loss: 0.35070\n",
      "Epoch: 99/300 Iteration: 981 Training loss: 0.33908\n",
      "Epoch: 99/300 Iteration: 982 Training loss: 0.31239\n",
      "Epoch: 99/300 Iteration: 983 Training loss: 0.29089\n",
      "Epoch: 99/300 Iteration: 984 Training loss: 0.31302\n",
      "Epoch: 98/300 Iteration: 985 Validation Acc: 0.5322\n",
      "Epoch: 99/300 Iteration: 985 Training loss: 0.34474\n",
      "Epoch: 99/300 Iteration: 986 Training loss: 0.33378\n",
      "Epoch: 99/300 Iteration: 987 Training loss: 0.30646\n",
      "Epoch: 99/300 Iteration: 988 Training loss: 0.28635\n",
      "Epoch: 99/300 Iteration: 989 Training loss: 0.30198\n",
      "Epoch: 98/300 Iteration: 990 Validation Acc: 0.5318\n",
      "Epoch: 100/300 Iteration: 990 Training loss: 0.35170\n",
      "Epoch: 100/300 Iteration: 991 Training loss: 0.34955\n",
      "Epoch: 100/300 Iteration: 992 Training loss: 0.30440\n",
      "Epoch: 100/300 Iteration: 993 Training loss: 0.30678\n",
      "Epoch: 100/300 Iteration: 994 Training loss: 0.29916\n",
      "Epoch: 99/300 Iteration: 995 Validation Acc: 0.5448\n",
      "Epoch: 100/300 Iteration: 995 Training loss: 0.29936\n",
      "Epoch: 100/300 Iteration: 996 Training loss: 0.30808\n",
      "Epoch: 100/300 Iteration: 997 Training loss: 0.32386\n",
      "Epoch: 100/300 Iteration: 998 Training loss: 0.29896\n",
      "Epoch: 100/300 Iteration: 999 Training loss: 0.26888\n",
      "Epoch: 99/300 Iteration: 1000 Validation Acc: 0.5441\n",
      "Epoch: 101/300 Iteration: 1000 Training loss: 0.29321\n",
      "Epoch: 101/300 Iteration: 1001 Training loss: 0.32661\n",
      "Epoch: 101/300 Iteration: 1002 Training loss: 0.32964\n",
      "Epoch: 101/300 Iteration: 1003 Training loss: 0.30217\n",
      "Epoch: 101/300 Iteration: 1004 Training loss: 0.28485\n",
      "Epoch: 100/300 Iteration: 1005 Validation Acc: 0.5500\n",
      "Epoch: 101/300 Iteration: 1005 Training loss: 0.28297\n",
      "Epoch: 101/300 Iteration: 1006 Training loss: 0.27800\n",
      "Epoch: 101/300 Iteration: 1007 Training loss: 0.29950\n",
      "Epoch: 101/300 Iteration: 1008 Training loss: 0.31502\n",
      "Epoch: 101/300 Iteration: 1009 Training loss: 0.28284\n",
      "Epoch: 100/300 Iteration: 1010 Validation Acc: 0.5563\n",
      "Epoch: 102/300 Iteration: 1010 Training loss: 0.26235\n",
      "Epoch: 102/300 Iteration: 1011 Training loss: 0.28290\n",
      "Epoch: 102/300 Iteration: 1012 Training loss: 0.31803\n",
      "Epoch: 102/300 Iteration: 1013 Training loss: 0.30972\n",
      "Epoch: 102/300 Iteration: 1014 Training loss: 0.28531\n",
      "Epoch: 101/300 Iteration: 1015 Validation Acc: 0.5500\n",
      "Epoch: 102/300 Iteration: 1015 Training loss: 0.27560\n",
      "Epoch: 102/300 Iteration: 1016 Training loss: 0.26436\n",
      "Epoch: 102/300 Iteration: 1017 Training loss: 0.27245\n",
      "Epoch: 102/300 Iteration: 1018 Training loss: 0.30338\n",
      "Epoch: 102/300 Iteration: 1019 Training loss: 0.28886\n",
      "Epoch: 101/300 Iteration: 1020 Validation Acc: 0.5448\n",
      "Epoch: 103/300 Iteration: 1020 Training loss: 0.28509\n",
      "Epoch: 103/300 Iteration: 1021 Training loss: 0.26303\n",
      "Epoch: 103/300 Iteration: 1022 Training loss: 0.27469\n",
      "Epoch: 103/300 Iteration: 1023 Training loss: 0.30693\n",
      "Epoch: 103/300 Iteration: 1024 Training loss: 0.29731\n",
      "Epoch: 102/300 Iteration: 1025 Validation Acc: 0.5433\n",
      "Epoch: 103/300 Iteration: 1025 Training loss: 0.29126\n",
      "Epoch: 103/300 Iteration: 1026 Training loss: 0.28631\n",
      "Epoch: 103/300 Iteration: 1027 Training loss: 0.28298\n",
      "Epoch: 103/300 Iteration: 1028 Training loss: 0.26966\n",
      "Epoch: 103/300 Iteration: 1029 Training loss: 0.29473\n",
      "Epoch: 102/300 Iteration: 1030 Validation Acc: 0.5416\n",
      "Epoch: 104/300 Iteration: 1030 Training loss: 0.30466\n",
      "Epoch: 104/300 Iteration: 1031 Training loss: 0.28615\n",
      "Epoch: 104/300 Iteration: 1032 Training loss: 0.28213\n",
      "Epoch: 104/300 Iteration: 1033 Training loss: 0.28071\n",
      "Epoch: 104/300 Iteration: 1034 Training loss: 0.28650\n",
      "Epoch: 103/300 Iteration: 1035 Validation Acc: 0.5427\n",
      "Epoch: 104/300 Iteration: 1035 Training loss: 0.28812\n",
      "Epoch: 104/300 Iteration: 1036 Training loss: 0.27216\n",
      "Epoch: 104/300 Iteration: 1037 Training loss: 0.29723\n",
      "Epoch: 104/300 Iteration: 1038 Training loss: 0.29451\n",
      "Epoch: 104/300 Iteration: 1039 Training loss: 0.26397\n",
      "Epoch: 103/300 Iteration: 1040 Validation Acc: 0.5466\n",
      "Epoch: 105/300 Iteration: 1040 Training loss: 0.28619\n",
      "Epoch: 105/300 Iteration: 1041 Training loss: 0.29125\n",
      "Epoch: 105/300 Iteration: 1042 Training loss: 0.27453\n",
      "Epoch: 105/300 Iteration: 1043 Training loss: 0.29201\n",
      "Epoch: 105/300 Iteration: 1044 Training loss: 0.28379\n",
      "Epoch: 104/300 Iteration: 1045 Validation Acc: 0.5489\n",
      "Epoch: 105/300 Iteration: 1045 Training loss: 0.26774\n",
      "Epoch: 105/300 Iteration: 1046 Training loss: 0.26627\n",
      "Epoch: 105/300 Iteration: 1047 Training loss: 0.27147\n",
      "Epoch: 105/300 Iteration: 1048 Training loss: 0.28368\n",
      "Epoch: 105/300 Iteration: 1049 Training loss: 0.28153\n",
      "Epoch: 104/300 Iteration: 1050 Validation Acc: 0.5569\n",
      "Epoch: 106/300 Iteration: 1050 Training loss: 0.26443\n",
      "Epoch: 106/300 Iteration: 1051 Training loss: 0.27312\n",
      "Epoch: 106/300 Iteration: 1052 Training loss: 0.29826\n",
      "Epoch: 106/300 Iteration: 1053 Training loss: 0.28144\n",
      "Epoch: 106/300 Iteration: 1054 Training loss: 0.26792\n",
      "Epoch: 105/300 Iteration: 1055 Validation Acc: 0.5502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106/300 Iteration: 1055 Training loss: 0.26350\n",
      "Epoch: 106/300 Iteration: 1056 Training loss: 0.25998\n",
      "Epoch: 106/300 Iteration: 1057 Training loss: 0.26440\n",
      "Epoch: 106/300 Iteration: 1058 Training loss: 0.27473\n",
      "Epoch: 106/300 Iteration: 1059 Training loss: 0.28615\n",
      "Epoch: 105/300 Iteration: 1060 Validation Acc: 0.5494\n",
      "Epoch: 107/300 Iteration: 1060 Training loss: 0.28984\n",
      "Epoch: 107/300 Iteration: 1061 Training loss: 0.24876\n",
      "Epoch: 107/300 Iteration: 1062 Training loss: 0.26173\n",
      "Epoch: 107/300 Iteration: 1063 Training loss: 0.30662\n",
      "Epoch: 107/300 Iteration: 1064 Training loss: 0.29063\n",
      "Epoch: 106/300 Iteration: 1065 Validation Acc: 0.5460\n",
      "Epoch: 107/300 Iteration: 1065 Training loss: 0.26742\n",
      "Epoch: 107/300 Iteration: 1066 Training loss: 0.24608\n",
      "Epoch: 107/300 Iteration: 1067 Training loss: 0.25852\n",
      "Epoch: 107/300 Iteration: 1068 Training loss: 0.26573\n",
      "Epoch: 107/300 Iteration: 1069 Training loss: 0.28172\n",
      "Epoch: 106/300 Iteration: 1070 Validation Acc: 0.5466\n",
      "Epoch: 108/300 Iteration: 1070 Training loss: 0.30298\n",
      "Epoch: 108/300 Iteration: 1071 Training loss: 0.26514\n",
      "Epoch: 108/300 Iteration: 1072 Training loss: 0.23290\n",
      "Epoch: 108/300 Iteration: 1073 Training loss: 0.26503\n",
      "Epoch: 108/300 Iteration: 1074 Training loss: 0.31901\n",
      "Epoch: 107/300 Iteration: 1075 Validation Acc: 0.5375\n",
      "Epoch: 108/300 Iteration: 1075 Training loss: 0.29254\n",
      "Epoch: 108/300 Iteration: 1076 Training loss: 0.26348\n",
      "Epoch: 108/300 Iteration: 1077 Training loss: 0.25961\n",
      "Epoch: 108/300 Iteration: 1078 Training loss: 0.25612\n",
      "Epoch: 108/300 Iteration: 1079 Training loss: 0.25066\n",
      "Epoch: 107/300 Iteration: 1080 Validation Acc: 0.5477\n",
      "Epoch: 109/300 Iteration: 1080 Training loss: 0.28914\n",
      "Epoch: 109/300 Iteration: 1081 Training loss: 0.30940\n",
      "Epoch: 109/300 Iteration: 1082 Training loss: 0.24228\n",
      "Epoch: 109/300 Iteration: 1083 Training loss: 0.21828\n",
      "Epoch: 109/300 Iteration: 1084 Training loss: 0.25978\n",
      "Epoch: 108/300 Iteration: 1085 Validation Acc: 0.5352\n",
      "Epoch: 109/300 Iteration: 1085 Training loss: 0.29134\n",
      "Epoch: 109/300 Iteration: 1086 Training loss: 0.27205\n",
      "Epoch: 109/300 Iteration: 1087 Training loss: 0.25104\n",
      "Epoch: 109/300 Iteration: 1088 Training loss: 0.23759\n",
      "Epoch: 109/300 Iteration: 1089 Training loss: 0.23104\n",
      "Epoch: 108/300 Iteration: 1090 Validation Acc: 0.5531\n",
      "Epoch: 110/300 Iteration: 1090 Training loss: 0.25884\n",
      "Epoch: 110/300 Iteration: 1091 Training loss: 0.28092\n",
      "Epoch: 110/300 Iteration: 1092 Training loss: 0.26564\n",
      "Epoch: 110/300 Iteration: 1093 Training loss: 0.23340\n",
      "Epoch: 110/300 Iteration: 1094 Training loss: 0.22058\n",
      "Epoch: 109/300 Iteration: 1095 Validation Acc: 0.5481\n",
      "Epoch: 110/300 Iteration: 1095 Training loss: 0.24400\n",
      "Epoch: 110/300 Iteration: 1096 Training loss: 0.28031\n",
      "Epoch: 110/300 Iteration: 1097 Training loss: 0.26171\n",
      "Epoch: 110/300 Iteration: 1098 Training loss: 0.23417\n",
      "Epoch: 110/300 Iteration: 1099 Training loss: 0.21756\n",
      "Epoch: 109/300 Iteration: 1100 Validation Acc: 0.5592\n",
      "Epoch: 111/300 Iteration: 1100 Training loss: 0.22916\n",
      "Epoch: 111/300 Iteration: 1101 Training loss: 0.26568\n",
      "Epoch: 111/300 Iteration: 1102 Training loss: 0.25855\n",
      "Epoch: 111/300 Iteration: 1103 Training loss: 0.24160\n",
      "Epoch: 111/300 Iteration: 1104 Training loss: 0.22846\n",
      "Epoch: 110/300 Iteration: 1105 Validation Acc: 0.5571\n",
      "Epoch: 111/300 Iteration: 1105 Training loss: 0.22035\n",
      "Epoch: 111/300 Iteration: 1106 Training loss: 0.23584\n",
      "Epoch: 111/300 Iteration: 1107 Training loss: 0.26162\n",
      "Epoch: 111/300 Iteration: 1108 Training loss: 0.24858\n",
      "Epoch: 111/300 Iteration: 1109 Training loss: 0.21693\n",
      "Epoch: 110/300 Iteration: 1110 Validation Acc: 0.5623\n",
      "Epoch: 112/300 Iteration: 1110 Training loss: 0.21702\n",
      "Epoch: 112/300 Iteration: 1111 Training loss: 0.23846\n",
      "Epoch: 112/300 Iteration: 1112 Training loss: 0.25590\n",
      "Epoch: 112/300 Iteration: 1113 Training loss: 0.24577\n",
      "Epoch: 112/300 Iteration: 1114 Training loss: 0.22523\n",
      "Epoch: 111/300 Iteration: 1115 Validation Acc: 0.5544\n",
      "Epoch: 112/300 Iteration: 1115 Training loss: 0.22635\n",
      "Epoch: 112/300 Iteration: 1116 Training loss: 0.22025\n",
      "Epoch: 112/300 Iteration: 1117 Training loss: 0.22909\n",
      "Epoch: 112/300 Iteration: 1118 Training loss: 0.24137\n",
      "Epoch: 112/300 Iteration: 1119 Training loss: 0.23727\n",
      "Epoch: 111/300 Iteration: 1120 Validation Acc: 0.5577\n",
      "Epoch: 113/300 Iteration: 1120 Training loss: 0.23322\n",
      "Epoch: 113/300 Iteration: 1121 Training loss: 0.22011\n",
      "Epoch: 113/300 Iteration: 1122 Training loss: 0.23034\n",
      "Epoch: 113/300 Iteration: 1123 Training loss: 0.26538\n",
      "Epoch: 113/300 Iteration: 1124 Training loss: 0.21916\n",
      "Epoch: 112/300 Iteration: 1125 Validation Acc: 0.5529\n",
      "Epoch: 113/300 Iteration: 1125 Training loss: 0.22137\n",
      "Epoch: 113/300 Iteration: 1126 Training loss: 0.22637\n",
      "Epoch: 113/300 Iteration: 1127 Training loss: 0.22694\n",
      "Epoch: 113/300 Iteration: 1128 Training loss: 0.23164\n",
      "Epoch: 113/300 Iteration: 1129 Training loss: 0.23760\n",
      "Epoch: 112/300 Iteration: 1130 Validation Acc: 0.5531\n",
      "Epoch: 114/300 Iteration: 1130 Training loss: 0.24483\n",
      "Epoch: 114/300 Iteration: 1131 Training loss: 0.22926\n",
      "Epoch: 114/300 Iteration: 1132 Training loss: 0.22426\n",
      "Epoch: 114/300 Iteration: 1133 Training loss: 0.23751\n",
      "Epoch: 114/300 Iteration: 1134 Training loss: 0.22883\n",
      "Epoch: 113/300 Iteration: 1135 Validation Acc: 0.5575\n",
      "Epoch: 114/300 Iteration: 1135 Training loss: 0.21325\n",
      "Epoch: 114/300 Iteration: 1136 Training loss: 0.21453\n",
      "Epoch: 114/300 Iteration: 1137 Training loss: 0.23120\n",
      "Epoch: 114/300 Iteration: 1138 Training loss: 0.22018\n",
      "Epoch: 114/300 Iteration: 1139 Training loss: 0.21145\n",
      "Epoch: 113/300 Iteration: 1140 Validation Acc: 0.5540\n",
      "Epoch: 115/300 Iteration: 1140 Training loss: 0.23977\n",
      "Epoch: 115/300 Iteration: 1141 Training loss: 0.23255\n",
      "Epoch: 115/300 Iteration: 1142 Training loss: 0.21039\n",
      "Epoch: 115/300 Iteration: 1143 Training loss: 0.24056\n",
      "Epoch: 115/300 Iteration: 1144 Training loss: 0.24076\n",
      "Epoch: 114/300 Iteration: 1145 Validation Acc: 0.5594\n",
      "Epoch: 115/300 Iteration: 1145 Training loss: 0.20317\n",
      "Epoch: 115/300 Iteration: 1146 Training loss: 0.21050\n",
      "Epoch: 115/300 Iteration: 1147 Training loss: 0.22916\n",
      "Epoch: 115/300 Iteration: 1148 Training loss: 0.22783\n",
      "Epoch: 115/300 Iteration: 1149 Training loss: 0.21296\n",
      "Epoch: 114/300 Iteration: 1150 Validation Acc: 0.5489\n",
      "Epoch: 116/300 Iteration: 1150 Training loss: 0.22759\n",
      "Epoch: 116/300 Iteration: 1151 Training loss: 0.24027\n",
      "Epoch: 116/300 Iteration: 1152 Training loss: 0.21436\n",
      "Epoch: 116/300 Iteration: 1153 Training loss: 0.21724\n",
      "Epoch: 116/300 Iteration: 1154 Training loss: 0.23548\n",
      "Epoch: 115/300 Iteration: 1155 Validation Acc: 0.5577\n",
      "Epoch: 116/300 Iteration: 1155 Training loss: 0.20883\n",
      "Epoch: 116/300 Iteration: 1156 Training loss: 0.19949\n",
      "Epoch: 116/300 Iteration: 1157 Training loss: 0.23483\n",
      "Epoch: 116/300 Iteration: 1158 Training loss: 0.22775\n",
      "Epoch: 116/300 Iteration: 1159 Training loss: 0.19559\n",
      "Epoch: 115/300 Iteration: 1160 Validation Acc: 0.5546\n",
      "Epoch: 117/300 Iteration: 1160 Training loss: 0.22226\n",
      "Epoch: 117/300 Iteration: 1161 Training loss: 0.25780\n",
      "Epoch: 117/300 Iteration: 1162 Training loss: 0.23452\n",
      "Epoch: 117/300 Iteration: 1163 Training loss: 0.22287\n",
      "Epoch: 117/300 Iteration: 1164 Training loss: 0.21857\n",
      "Epoch: 116/300 Iteration: 1165 Validation Acc: 0.5567\n",
      "Epoch: 117/300 Iteration: 1165 Training loss: 0.21300\n",
      "Epoch: 117/300 Iteration: 1166 Training loss: 0.21104\n",
      "Epoch: 117/300 Iteration: 1167 Training loss: 0.24593\n",
      "Epoch: 117/300 Iteration: 1168 Training loss: 0.23645\n",
      "Epoch: 117/300 Iteration: 1169 Training loss: 0.20157\n",
      "Epoch: 116/300 Iteration: 1170 Validation Acc: 0.5596\n",
      "Epoch: 118/300 Iteration: 1170 Training loss: 0.20965\n",
      "Epoch: 118/300 Iteration: 1171 Training loss: 0.26674\n",
      "Epoch: 118/300 Iteration: 1172 Training loss: 0.25421\n",
      "Epoch: 118/300 Iteration: 1173 Training loss: 0.23950\n",
      "Epoch: 118/300 Iteration: 1174 Training loss: 0.23237\n",
      "Epoch: 117/300 Iteration: 1175 Validation Acc: 0.5529\n",
      "Epoch: 118/300 Iteration: 1175 Training loss: 0.22780\n",
      "Epoch: 118/300 Iteration: 1176 Training loss: 0.22487\n",
      "Epoch: 118/300 Iteration: 1177 Training loss: 0.24467\n",
      "Epoch: 118/300 Iteration: 1178 Training loss: 0.24790\n",
      "Epoch: 118/300 Iteration: 1179 Training loss: 0.22719\n",
      "Epoch: 117/300 Iteration: 1180 Validation Acc: 0.5571\n",
      "Epoch: 119/300 Iteration: 1180 Training loss: 0.21531\n",
      "Epoch: 119/300 Iteration: 1181 Training loss: 0.25563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119/300 Iteration: 1182 Training loss: 0.27878\n",
      "Epoch: 119/300 Iteration: 1183 Training loss: 0.26321\n",
      "Epoch: 119/300 Iteration: 1184 Training loss: 0.26840\n",
      "Epoch: 118/300 Iteration: 1185 Validation Acc: 0.5377\n",
      "Epoch: 119/300 Iteration: 1185 Training loss: 0.26642\n",
      "Epoch: 119/300 Iteration: 1186 Training loss: 0.24293\n",
      "Epoch: 119/300 Iteration: 1187 Training loss: 0.26804\n",
      "Epoch: 119/300 Iteration: 1188 Training loss: 0.30935\n",
      "Epoch: 119/300 Iteration: 1189 Training loss: 0.25465\n",
      "Epoch: 118/300 Iteration: 1190 Validation Acc: 0.5550\n",
      "Epoch: 120/300 Iteration: 1190 Training loss: 0.23541\n",
      "Epoch: 120/300 Iteration: 1191 Training loss: 0.26451\n",
      "Epoch: 120/300 Iteration: 1192 Training loss: 0.32250\n",
      "Epoch: 120/300 Iteration: 1193 Training loss: 0.31155\n",
      "Epoch: 120/300 Iteration: 1194 Training loss: 0.31745\n",
      "Epoch: 119/300 Iteration: 1195 Validation Acc: 0.5162\n",
      "Epoch: 120/300 Iteration: 1195 Training loss: 0.32684\n",
      "Epoch: 120/300 Iteration: 1196 Training loss: 0.35651\n",
      "Epoch: 120/300 Iteration: 1197 Training loss: 0.26826\n",
      "Epoch: 120/300 Iteration: 1198 Training loss: 0.25983\n",
      "Epoch: 120/300 Iteration: 1199 Training loss: 0.33939\n",
      "Epoch: 119/300 Iteration: 1200 Validation Acc: 0.5425\n",
      "Epoch: 121/300 Iteration: 1200 Training loss: 0.32226\n",
      "Epoch: 121/300 Iteration: 1201 Training loss: 0.24930\n",
      "Epoch: 121/300 Iteration: 1202 Training loss: 0.29116\n",
      "Epoch: 121/300 Iteration: 1203 Training loss: 0.29290\n",
      "Epoch: 121/300 Iteration: 1204 Training loss: 0.28112\n",
      "Epoch: 120/300 Iteration: 1205 Validation Acc: 0.5343\n",
      "Epoch: 121/300 Iteration: 1205 Training loss: 0.26505\n",
      "Epoch: 121/300 Iteration: 1206 Training loss: 0.34561\n",
      "Epoch: 121/300 Iteration: 1207 Training loss: 0.35853\n",
      "Epoch: 121/300 Iteration: 1208 Training loss: 0.29357\n",
      "Epoch: 121/300 Iteration: 1209 Training loss: 0.26764\n",
      "Epoch: 120/300 Iteration: 1210 Validation Acc: 0.5387\n",
      "Epoch: 122/300 Iteration: 1210 Training loss: 0.30240\n",
      "Epoch: 122/300 Iteration: 1211 Training loss: 0.30295\n",
      "Epoch: 122/300 Iteration: 1212 Training loss: 0.32387\n",
      "Epoch: 122/300 Iteration: 1213 Training loss: 0.34542\n",
      "Epoch: 122/300 Iteration: 1214 Training loss: 0.28794\n",
      "Epoch: 121/300 Iteration: 1215 Validation Acc: 0.5389\n",
      "Epoch: 122/300 Iteration: 1215 Training loss: 0.26264\n",
      "Epoch: 122/300 Iteration: 1216 Training loss: 0.26835\n",
      "Epoch: 122/300 Iteration: 1217 Training loss: 0.33392\n",
      "Epoch: 122/300 Iteration: 1218 Training loss: 0.36811\n",
      "Epoch: 122/300 Iteration: 1219 Training loss: 0.29151\n",
      "Epoch: 121/300 Iteration: 1220 Validation Acc: 0.5377\n",
      "Epoch: 123/300 Iteration: 1220 Training loss: 0.28025\n",
      "Epoch: 123/300 Iteration: 1221 Training loss: 0.30528\n",
      "Epoch: 123/300 Iteration: 1222 Training loss: 0.29556\n",
      "Epoch: 123/300 Iteration: 1223 Training loss: 0.33852\n",
      "Epoch: 123/300 Iteration: 1224 Training loss: 0.37884\n",
      "Epoch: 122/300 Iteration: 1225 Validation Acc: 0.5222\n",
      "Epoch: 123/300 Iteration: 1225 Training loss: 0.31677\n",
      "Epoch: 123/300 Iteration: 1226 Training loss: 0.27916\n",
      "Epoch: 123/300 Iteration: 1227 Training loss: 0.26053\n",
      "Epoch: 123/300 Iteration: 1228 Training loss: 0.36967\n",
      "Epoch: 123/300 Iteration: 1229 Training loss: 0.38455\n",
      "Epoch: 122/300 Iteration: 1230 Validation Acc: 0.5348\n",
      "Epoch: 124/300 Iteration: 1230 Training loss: 0.31043\n",
      "Epoch: 124/300 Iteration: 1231 Training loss: 0.31934\n",
      "Epoch: 124/300 Iteration: 1232 Training loss: 0.34103\n",
      "Epoch: 124/300 Iteration: 1233 Training loss: 0.33007\n",
      "Epoch: 124/300 Iteration: 1234 Training loss: 0.35164\n",
      "Epoch: 123/300 Iteration: 1235 Validation Acc: 0.5187\n",
      "Epoch: 124/300 Iteration: 1235 Training loss: 0.33351\n",
      "Epoch: 124/300 Iteration: 1236 Training loss: 0.38066\n",
      "Epoch: 124/300 Iteration: 1237 Training loss: 0.33124\n",
      "Epoch: 124/300 Iteration: 1238 Training loss: 0.33492\n",
      "Epoch: 124/300 Iteration: 1239 Training loss: 0.40632\n",
      "Epoch: 123/300 Iteration: 1240 Validation Acc: 0.5237\n",
      "Epoch: 125/300 Iteration: 1240 Training loss: 0.40708\n",
      "Epoch: 125/300 Iteration: 1241 Training loss: 0.30622\n",
      "Epoch: 125/300 Iteration: 1242 Training loss: 0.27283\n",
      "Epoch: 125/300 Iteration: 1243 Training loss: 0.39062\n",
      "Epoch: 125/300 Iteration: 1244 Training loss: 0.36036\n",
      "Epoch: 124/300 Iteration: 1245 Validation Acc: 0.5185\n",
      "Epoch: 125/300 Iteration: 1245 Training loss: 0.35983\n",
      "Epoch: 125/300 Iteration: 1246 Training loss: 0.37889\n",
      "Epoch: 125/300 Iteration: 1247 Training loss: 0.36081\n",
      "Epoch: 125/300 Iteration: 1248 Training loss: 0.35885\n",
      "Epoch: 125/300 Iteration: 1249 Training loss: 0.33188\n",
      "Epoch: 124/300 Iteration: 1250 Validation Acc: 0.5366\n",
      "Epoch: 126/300 Iteration: 1250 Training loss: 0.35723\n",
      "Epoch: 126/300 Iteration: 1251 Training loss: 0.40220\n",
      "Epoch: 126/300 Iteration: 1252 Training loss: 0.34130\n",
      "Epoch: 126/300 Iteration: 1253 Training loss: 0.26587\n",
      "Epoch: 126/300 Iteration: 1254 Training loss: 0.31107\n",
      "Epoch: 125/300 Iteration: 1255 Validation Acc: 0.5208\n",
      "Epoch: 126/300 Iteration: 1255 Training loss: 0.34645\n",
      "Epoch: 126/300 Iteration: 1256 Training loss: 0.36255\n",
      "Epoch: 126/300 Iteration: 1257 Training loss: 0.27856\n",
      "Epoch: 126/300 Iteration: 1258 Training loss: 0.26797\n",
      "Epoch: 126/300 Iteration: 1259 Training loss: 0.31974\n",
      "Epoch: 125/300 Iteration: 1260 Validation Acc: 0.5220\n",
      "Epoch: 127/300 Iteration: 1260 Training loss: 0.37260\n",
      "Epoch: 127/300 Iteration: 1261 Training loss: 0.30153\n",
      "Epoch: 127/300 Iteration: 1262 Training loss: 0.30839\n",
      "Epoch: 127/300 Iteration: 1263 Training loss: 0.34346\n",
      "Epoch: 127/300 Iteration: 1264 Training loss: 0.31119\n",
      "Epoch: 126/300 Iteration: 1265 Validation Acc: 0.5414\n",
      "Epoch: 127/300 Iteration: 1265 Training loss: 0.27044\n",
      "Epoch: 127/300 Iteration: 1266 Training loss: 0.27655\n",
      "Epoch: 127/300 Iteration: 1267 Training loss: 0.32760\n",
      "Epoch: 127/300 Iteration: 1268 Training loss: 0.30021\n",
      "Epoch: 127/300 Iteration: 1269 Training loss: 0.25312\n",
      "Epoch: 126/300 Iteration: 1270 Validation Acc: 0.5454\n",
      "Epoch: 128/300 Iteration: 1270 Training loss: 0.27072\n",
      "Epoch: 128/300 Iteration: 1271 Training loss: 0.29957\n",
      "Epoch: 128/300 Iteration: 1272 Training loss: 0.25398\n",
      "Epoch: 128/300 Iteration: 1273 Training loss: 0.26265\n",
      "Epoch: 128/300 Iteration: 1274 Training loss: 0.30336\n",
      "Epoch: 127/300 Iteration: 1275 Validation Acc: 0.5471\n",
      "Epoch: 128/300 Iteration: 1275 Training loss: 0.25141\n",
      "Epoch: 128/300 Iteration: 1276 Training loss: 0.23975\n",
      "Epoch: 128/300 Iteration: 1277 Training loss: 0.25693\n",
      "Epoch: 128/300 Iteration: 1278 Training loss: 0.29736\n",
      "Epoch: 128/300 Iteration: 1279 Training loss: 0.26715\n",
      "Epoch: 127/300 Iteration: 1280 Validation Acc: 0.5537\n",
      "Epoch: 129/300 Iteration: 1280 Training loss: 0.24964\n",
      "Epoch: 129/300 Iteration: 1281 Training loss: 0.24079\n",
      "Epoch: 129/300 Iteration: 1282 Training loss: 0.22927\n",
      "Epoch: 129/300 Iteration: 1283 Training loss: 0.24443\n",
      "Epoch: 129/300 Iteration: 1284 Training loss: 0.25790\n",
      "Epoch: 128/300 Iteration: 1285 Validation Acc: 0.5506\n",
      "Epoch: 129/300 Iteration: 1285 Training loss: 0.23736\n",
      "Epoch: 129/300 Iteration: 1286 Training loss: 0.20721\n",
      "Epoch: 129/300 Iteration: 1287 Training loss: 0.21830\n",
      "Epoch: 129/300 Iteration: 1288 Training loss: 0.23927\n",
      "Epoch: 129/300 Iteration: 1289 Training loss: 0.21684\n",
      "Epoch: 128/300 Iteration: 1290 Validation Acc: 0.5565\n",
      "Epoch: 130/300 Iteration: 1290 Training loss: 0.26333\n",
      "Epoch: 130/300 Iteration: 1291 Training loss: 0.25131\n",
      "Epoch: 130/300 Iteration: 1292 Training loss: 0.22536\n",
      "Epoch: 130/300 Iteration: 1293 Training loss: 0.21713\n",
      "Epoch: 130/300 Iteration: 1294 Training loss: 0.23114\n",
      "Epoch: 129/300 Iteration: 1295 Validation Acc: 0.5544\n",
      "Epoch: 130/300 Iteration: 1295 Training loss: 0.23721\n",
      "Epoch: 130/300 Iteration: 1296 Training loss: 0.20708\n",
      "Epoch: 130/300 Iteration: 1297 Training loss: 0.21001\n",
      "Epoch: 130/300 Iteration: 1298 Training loss: 0.20226\n",
      "Epoch: 130/300 Iteration: 1299 Training loss: 0.17635\n",
      "Epoch: 129/300 Iteration: 1300 Validation Acc: 0.5698\n",
      "Epoch: 131/300 Iteration: 1300 Training loss: 0.20041\n",
      "Epoch: 131/300 Iteration: 1301 Training loss: 0.23597\n",
      "Epoch: 131/300 Iteration: 1302 Training loss: 0.20621\n",
      "Epoch: 131/300 Iteration: 1303 Training loss: 0.18569\n",
      "Epoch: 131/300 Iteration: 1304 Training loss: 0.19132\n",
      "Epoch: 130/300 Iteration: 1305 Validation Acc: 0.5633\n",
      "Epoch: 131/300 Iteration: 1305 Training loss: 0.19305\n",
      "Epoch: 131/300 Iteration: 1306 Training loss: 0.18564\n",
      "Epoch: 131/300 Iteration: 1307 Training loss: 0.19383\n",
      "Epoch: 131/300 Iteration: 1308 Training loss: 0.19325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131/300 Iteration: 1309 Training loss: 0.17463\n",
      "Epoch: 130/300 Iteration: 1310 Validation Acc: 0.5675\n",
      "Epoch: 132/300 Iteration: 1310 Training loss: 0.18785\n",
      "Epoch: 132/300 Iteration: 1311 Training loss: 0.19039\n",
      "Epoch: 132/300 Iteration: 1312 Training loss: 0.18393\n",
      "Epoch: 132/300 Iteration: 1313 Training loss: 0.18067\n",
      "Epoch: 132/300 Iteration: 1314 Training loss: 0.17347\n",
      "Epoch: 131/300 Iteration: 1315 Validation Acc: 0.5732\n",
      "Epoch: 132/300 Iteration: 1315 Training loss: 0.16485\n",
      "Epoch: 132/300 Iteration: 1316 Training loss: 0.16501\n",
      "Epoch: 132/300 Iteration: 1317 Training loss: 0.16909\n",
      "Epoch: 132/300 Iteration: 1318 Training loss: 0.17051\n",
      "Epoch: 132/300 Iteration: 1319 Training loss: 0.15750\n",
      "Epoch: 131/300 Iteration: 1320 Validation Acc: 0.5750\n",
      "Epoch: 133/300 Iteration: 1320 Training loss: 0.15560\n",
      "Epoch: 133/300 Iteration: 1321 Training loss: 0.15827\n",
      "Epoch: 133/300 Iteration: 1322 Training loss: 0.17063\n",
      "Epoch: 133/300 Iteration: 1323 Training loss: 0.17175\n",
      "Epoch: 133/300 Iteration: 1324 Training loss: 0.15950\n",
      "Epoch: 132/300 Iteration: 1325 Validation Acc: 0.5807\n",
      "Epoch: 133/300 Iteration: 1325 Training loss: 0.12985\n",
      "Epoch: 133/300 Iteration: 1326 Training loss: 0.12458\n",
      "Epoch: 133/300 Iteration: 1327 Training loss: 0.15468\n",
      "Epoch: 133/300 Iteration: 1328 Training loss: 0.17687\n",
      "Epoch: 133/300 Iteration: 1329 Training loss: 0.15129\n",
      "Epoch: 132/300 Iteration: 1330 Validation Acc: 0.5786\n",
      "Epoch: 134/300 Iteration: 1330 Training loss: 0.13621\n",
      "Epoch: 134/300 Iteration: 1331 Training loss: 0.13233\n",
      "Epoch: 134/300 Iteration: 1332 Training loss: 0.14578\n",
      "Epoch: 134/300 Iteration: 1333 Training loss: 0.16046\n",
      "Epoch: 134/300 Iteration: 1334 Training loss: 0.15161\n",
      "Epoch: 133/300 Iteration: 1335 Validation Acc: 0.5817\n",
      "Epoch: 134/300 Iteration: 1335 Training loss: 0.12939\n",
      "Epoch: 134/300 Iteration: 1336 Training loss: 0.11330\n",
      "Epoch: 134/300 Iteration: 1337 Training loss: 0.12920\n",
      "Epoch: 134/300 Iteration: 1338 Training loss: 0.15615\n",
      "Epoch: 134/300 Iteration: 1339 Training loss: 0.15009\n",
      "Epoch: 133/300 Iteration: 1340 Validation Acc: 0.5794\n",
      "Epoch: 135/300 Iteration: 1340 Training loss: 0.13889\n",
      "Epoch: 135/300 Iteration: 1341 Training loss: 0.11992\n",
      "Epoch: 135/300 Iteration: 1342 Training loss: 0.12316\n",
      "Epoch: 135/300 Iteration: 1343 Training loss: 0.14497\n",
      "Epoch: 135/300 Iteration: 1344 Training loss: 0.15514\n",
      "Epoch: 134/300 Iteration: 1345 Validation Acc: 0.5777\n",
      "Epoch: 135/300 Iteration: 1345 Training loss: 0.13075\n",
      "Epoch: 135/300 Iteration: 1346 Training loss: 0.10487\n",
      "Epoch: 135/300 Iteration: 1347 Training loss: 0.11439\n",
      "Epoch: 135/300 Iteration: 1348 Training loss: 0.13486\n",
      "Epoch: 135/300 Iteration: 1349 Training loss: 0.13346\n",
      "Epoch: 134/300 Iteration: 1350 Validation Acc: 0.5767\n",
      "Epoch: 136/300 Iteration: 1350 Training loss: 0.14520\n",
      "Epoch: 136/300 Iteration: 1351 Training loss: 0.12501\n",
      "Epoch: 136/300 Iteration: 1352 Training loss: 0.11110\n",
      "Epoch: 136/300 Iteration: 1353 Training loss: 0.12093\n",
      "Epoch: 136/300 Iteration: 1354 Training loss: 0.14757\n",
      "Epoch: 135/300 Iteration: 1355 Validation Acc: 0.5798\n",
      "Epoch: 136/300 Iteration: 1355 Training loss: 0.13144\n",
      "Epoch: 136/300 Iteration: 1356 Training loss: 0.10546\n",
      "Epoch: 136/300 Iteration: 1357 Training loss: 0.11090\n",
      "Epoch: 136/300 Iteration: 1358 Training loss: 0.12945\n",
      "Epoch: 136/300 Iteration: 1359 Training loss: 0.12330\n",
      "Epoch: 135/300 Iteration: 1360 Validation Acc: 0.5792\n",
      "Epoch: 137/300 Iteration: 1360 Training loss: 0.13623\n",
      "Epoch: 137/300 Iteration: 1361 Training loss: 0.12685\n",
      "Epoch: 137/300 Iteration: 1362 Training loss: 0.11489\n",
      "Epoch: 137/300 Iteration: 1363 Training loss: 0.11695\n",
      "Epoch: 137/300 Iteration: 1364 Training loss: 0.13898\n",
      "Epoch: 136/300 Iteration: 1365 Validation Acc: 0.5800\n",
      "Epoch: 137/300 Iteration: 1365 Training loss: 0.12635\n",
      "Epoch: 137/300 Iteration: 1366 Training loss: 0.10471\n",
      "Epoch: 137/300 Iteration: 1367 Training loss: 0.10937\n",
      "Epoch: 137/300 Iteration: 1368 Training loss: 0.12977\n",
      "Epoch: 137/300 Iteration: 1369 Training loss: 0.12183\n",
      "Epoch: 136/300 Iteration: 1370 Validation Acc: 0.5803\n",
      "Epoch: 138/300 Iteration: 1370 Training loss: 0.13033\n",
      "Epoch: 138/300 Iteration: 1371 Training loss: 0.12199\n",
      "Epoch: 138/300 Iteration: 1372 Training loss: 0.11981\n",
      "Epoch: 138/300 Iteration: 1373 Training loss: 0.12263\n",
      "Epoch: 138/300 Iteration: 1374 Training loss: 0.13542\n",
      "Epoch: 137/300 Iteration: 1375 Validation Acc: 0.5775\n",
      "Epoch: 138/300 Iteration: 1375 Training loss: 0.12361\n",
      "Epoch: 138/300 Iteration: 1376 Training loss: 0.10395\n",
      "Epoch: 138/300 Iteration: 1377 Training loss: 0.11036\n",
      "Epoch: 138/300 Iteration: 1378 Training loss: 0.13166\n",
      "Epoch: 138/300 Iteration: 1379 Training loss: 0.12827\n",
      "Epoch: 137/300 Iteration: 1380 Validation Acc: 0.5811\n",
      "Epoch: 139/300 Iteration: 1380 Training loss: 0.12787\n",
      "Epoch: 139/300 Iteration: 1381 Training loss: 0.11570\n",
      "Epoch: 139/300 Iteration: 1382 Training loss: 0.11793\n",
      "Epoch: 139/300 Iteration: 1383 Training loss: 0.13037\n",
      "Epoch: 139/300 Iteration: 1384 Training loss: 0.13987\n",
      "Epoch: 138/300 Iteration: 1385 Validation Acc: 0.5750\n",
      "Epoch: 139/300 Iteration: 1385 Training loss: 0.12498\n",
      "Epoch: 139/300 Iteration: 1386 Training loss: 0.10085\n",
      "Epoch: 139/300 Iteration: 1387 Training loss: 0.10857\n",
      "Epoch: 139/300 Iteration: 1388 Training loss: 0.13490\n",
      "Epoch: 139/300 Iteration: 1389 Training loss: 0.13601\n",
      "Epoch: 138/300 Iteration: 1390 Validation Acc: 0.5798\n",
      "Epoch: 140/300 Iteration: 1390 Training loss: 0.13174\n",
      "Epoch: 140/300 Iteration: 1391 Training loss: 0.11443\n",
      "Epoch: 140/300 Iteration: 1392 Training loss: 0.11535\n",
      "Epoch: 140/300 Iteration: 1393 Training loss: 0.13590\n",
      "Epoch: 140/300 Iteration: 1394 Training loss: 0.14864\n",
      "Epoch: 139/300 Iteration: 1395 Validation Acc: 0.5715\n",
      "Epoch: 140/300 Iteration: 1395 Training loss: 0.13219\n",
      "Epoch: 140/300 Iteration: 1396 Training loss: 0.10016\n",
      "Epoch: 140/300 Iteration: 1397 Training loss: 0.10395\n",
      "Epoch: 140/300 Iteration: 1398 Training loss: 0.13406\n",
      "Epoch: 140/300 Iteration: 1399 Training loss: 0.15267\n",
      "Epoch: 139/300 Iteration: 1400 Validation Acc: 0.5755\n",
      "Epoch: 141/300 Iteration: 1400 Training loss: 0.14111\n",
      "Epoch: 141/300 Iteration: 1401 Training loss: 0.11448\n",
      "Epoch: 141/300 Iteration: 1402 Training loss: 0.11374\n",
      "Epoch: 141/300 Iteration: 1403 Training loss: 0.13717\n",
      "Epoch: 141/300 Iteration: 1404 Training loss: 0.15994\n",
      "Epoch: 140/300 Iteration: 1405 Validation Acc: 0.5623\n",
      "Epoch: 141/300 Iteration: 1405 Training loss: 0.15207\n",
      "Epoch: 141/300 Iteration: 1406 Training loss: 0.10852\n",
      "Epoch: 141/300 Iteration: 1407 Training loss: 0.10373\n",
      "Epoch: 141/300 Iteration: 1408 Training loss: 0.12715\n",
      "Epoch: 141/300 Iteration: 1409 Training loss: 0.16602\n",
      "Epoch: 140/300 Iteration: 1410 Validation Acc: 0.5667\n",
      "Epoch: 142/300 Iteration: 1410 Training loss: 0.16650\n",
      "Epoch: 142/300 Iteration: 1411 Training loss: 0.12452\n",
      "Epoch: 142/300 Iteration: 1412 Training loss: 0.11665\n",
      "Epoch: 142/300 Iteration: 1413 Training loss: 0.13855\n",
      "Epoch: 142/300 Iteration: 1414 Training loss: 0.17741\n",
      "Epoch: 141/300 Iteration: 1415 Validation Acc: 0.5560\n",
      "Epoch: 142/300 Iteration: 1415 Training loss: 0.17201\n",
      "Epoch: 142/300 Iteration: 1416 Training loss: 0.11780\n",
      "Epoch: 142/300 Iteration: 1417 Training loss: 0.10752\n",
      "Epoch: 142/300 Iteration: 1418 Training loss: 0.12504\n",
      "Epoch: 142/300 Iteration: 1419 Training loss: 0.17089\n",
      "Epoch: 141/300 Iteration: 1420 Validation Acc: 0.5575\n",
      "Epoch: 143/300 Iteration: 1420 Training loss: 0.18882\n",
      "Epoch: 143/300 Iteration: 1421 Training loss: 0.13691\n",
      "Epoch: 143/300 Iteration: 1422 Training loss: 0.12592\n",
      "Epoch: 143/300 Iteration: 1423 Training loss: 0.14416\n",
      "Epoch: 143/300 Iteration: 1424 Training loss: 0.18023\n",
      "Epoch: 142/300 Iteration: 1425 Validation Acc: 0.5458\n",
      "Epoch: 143/300 Iteration: 1425 Training loss: 0.20674\n",
      "Epoch: 143/300 Iteration: 1426 Training loss: 0.13780\n",
      "Epoch: 143/300 Iteration: 1427 Training loss: 0.11645\n",
      "Epoch: 143/300 Iteration: 1428 Training loss: 0.12999\n",
      "Epoch: 143/300 Iteration: 1429 Training loss: 0.17699\n",
      "Epoch: 142/300 Iteration: 1430 Validation Acc: 0.5393\n",
      "Epoch: 144/300 Iteration: 1430 Training loss: 0.23231\n",
      "Epoch: 144/300 Iteration: 1431 Training loss: 0.16707\n",
      "Epoch: 144/300 Iteration: 1432 Training loss: 0.14074\n",
      "Epoch: 144/300 Iteration: 1433 Training loss: 0.15752\n",
      "Epoch: 144/300 Iteration: 1434 Training loss: 0.18671\n",
      "Epoch: 143/300 Iteration: 1435 Validation Acc: 0.5320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144/300 Iteration: 1435 Training loss: 0.23666\n",
      "Epoch: 144/300 Iteration: 1436 Training loss: 0.17577\n",
      "Epoch: 144/300 Iteration: 1437 Training loss: 0.13476\n",
      "Epoch: 144/300 Iteration: 1438 Training loss: 0.14368\n",
      "Epoch: 144/300 Iteration: 1439 Training loss: 0.18153\n",
      "Epoch: 143/300 Iteration: 1440 Validation Acc: 0.5260\n",
      "Epoch: 145/300 Iteration: 1440 Training loss: 0.24946\n",
      "Epoch: 145/300 Iteration: 1441 Training loss: 0.21400\n",
      "Epoch: 145/300 Iteration: 1442 Training loss: 0.16381\n",
      "Epoch: 145/300 Iteration: 1443 Training loss: 0.17750\n",
      "Epoch: 145/300 Iteration: 1444 Training loss: 0.20173\n",
      "Epoch: 144/300 Iteration: 1445 Validation Acc: 0.5316\n",
      "Epoch: 145/300 Iteration: 1445 Training loss: 0.23260\n",
      "Epoch: 145/300 Iteration: 1446 Training loss: 0.26303\n",
      "Epoch: 145/300 Iteration: 1447 Training loss: 0.18251\n",
      "Epoch: 145/300 Iteration: 1448 Training loss: 0.15749\n",
      "Epoch: 145/300 Iteration: 1449 Training loss: 0.21205\n",
      "Epoch: 144/300 Iteration: 1450 Validation Acc: 0.5199\n",
      "Epoch: 146/300 Iteration: 1450 Training loss: 0.26032\n",
      "Epoch: 146/300 Iteration: 1451 Training loss: 0.28641\n",
      "Epoch: 146/300 Iteration: 1452 Training loss: 0.21563\n",
      "Epoch: 146/300 Iteration: 1453 Training loss: 0.20047\n",
      "Epoch: 146/300 Iteration: 1454 Training loss: 0.25787\n",
      "Epoch: 145/300 Iteration: 1455 Validation Acc: 0.5337\n",
      "Epoch: 146/300 Iteration: 1455 Training loss: 0.26602\n",
      "Epoch: 146/300 Iteration: 1456 Training loss: 0.22499\n",
      "Epoch: 146/300 Iteration: 1457 Training loss: 0.25216\n",
      "Epoch: 146/300 Iteration: 1458 Training loss: 0.20849\n",
      "Epoch: 146/300 Iteration: 1459 Training loss: 0.18976\n",
      "Epoch: 145/300 Iteration: 1460 Validation Acc: 0.5183\n",
      "Epoch: 147/300 Iteration: 1460 Training loss: 0.24629\n",
      "Epoch: 147/300 Iteration: 1461 Training loss: 0.32341\n",
      "Epoch: 147/300 Iteration: 1462 Training loss: 0.26192\n",
      "Epoch: 147/300 Iteration: 1463 Training loss: 0.18471\n",
      "Epoch: 147/300 Iteration: 1464 Training loss: 0.20711\n",
      "Epoch: 146/300 Iteration: 1465 Validation Acc: 0.5174\n",
      "Epoch: 147/300 Iteration: 1465 Training loss: 0.30965\n",
      "Epoch: 147/300 Iteration: 1466 Training loss: 0.28514\n",
      "Epoch: 147/300 Iteration: 1467 Training loss: 0.26441\n",
      "Epoch: 147/300 Iteration: 1468 Training loss: 0.22682\n",
      "Epoch: 147/300 Iteration: 1469 Training loss: 0.19869\n",
      "Epoch: 146/300 Iteration: 1470 Validation Acc: 0.5158\n",
      "Epoch: 148/300 Iteration: 1470 Training loss: 0.27244\n",
      "Epoch: 148/300 Iteration: 1471 Training loss: 0.32762\n",
      "Epoch: 148/300 Iteration: 1472 Training loss: 0.27949\n",
      "Epoch: 148/300 Iteration: 1473 Training loss: 0.22552\n",
      "Epoch: 148/300 Iteration: 1474 Training loss: 0.19167\n",
      "Epoch: 147/300 Iteration: 1475 Validation Acc: 0.5210\n",
      "Epoch: 148/300 Iteration: 1475 Training loss: 0.24084\n",
      "Epoch: 148/300 Iteration: 1476 Training loss: 0.38533\n",
      "Epoch: 148/300 Iteration: 1477 Training loss: 0.27083\n",
      "Epoch: 148/300 Iteration: 1478 Training loss: 0.25515\n",
      "Epoch: 148/300 Iteration: 1479 Training loss: 0.24281\n",
      "Epoch: 147/300 Iteration: 1480 Validation Acc: 0.5191\n",
      "Epoch: 149/300 Iteration: 1480 Training loss: 0.26852\n",
      "Epoch: 149/300 Iteration: 1481 Training loss: 0.35380\n",
      "Epoch: 149/300 Iteration: 1482 Training loss: 0.40356\n",
      "Epoch: 149/300 Iteration: 1483 Training loss: 0.27056\n",
      "Epoch: 149/300 Iteration: 1484 Training loss: 0.21826\n",
      "Epoch: 148/300 Iteration: 1485 Validation Acc: 0.5212\n",
      "Epoch: 149/300 Iteration: 1485 Training loss: 0.25177\n",
      "Epoch: 149/300 Iteration: 1486 Training loss: 0.37811\n",
      "Epoch: 149/300 Iteration: 1487 Training loss: 0.34968\n",
      "Epoch: 149/300 Iteration: 1488 Training loss: 0.31227\n",
      "Epoch: 149/300 Iteration: 1489 Training loss: 0.24965\n",
      "Epoch: 148/300 Iteration: 1490 Validation Acc: 0.5168\n",
      "Epoch: 150/300 Iteration: 1490 Training loss: 0.29104\n",
      "Epoch: 150/300 Iteration: 1491 Training loss: 0.36057\n",
      "Epoch: 150/300 Iteration: 1492 Training loss: 0.36590\n",
      "Epoch: 150/300 Iteration: 1493 Training loss: 0.32897\n",
      "Epoch: 150/300 Iteration: 1494 Training loss: 0.27311\n",
      "Epoch: 149/300 Iteration: 1495 Validation Acc: 0.5381\n",
      "Epoch: 150/300 Iteration: 1495 Training loss: 0.23204\n",
      "Epoch: 150/300 Iteration: 1496 Training loss: 0.29230\n",
      "Epoch: 150/300 Iteration: 1497 Training loss: 0.37866\n",
      "Epoch: 150/300 Iteration: 1498 Training loss: 0.34046\n",
      "Epoch: 150/300 Iteration: 1499 Training loss: 0.23562\n",
      "Epoch: 149/300 Iteration: 1500 Validation Acc: 0.5339\n",
      "Epoch: 151/300 Iteration: 1500 Training loss: 0.25216\n",
      "Epoch: 151/300 Iteration: 1501 Training loss: 0.30093\n",
      "Epoch: 151/300 Iteration: 1502 Training loss: 0.35869\n",
      "Epoch: 151/300 Iteration: 1503 Training loss: 0.38016\n",
      "Epoch: 151/300 Iteration: 1504 Training loss: 0.31085\n",
      "Epoch: 150/300 Iteration: 1505 Validation Acc: 0.5393\n",
      "Epoch: 151/300 Iteration: 1505 Training loss: 0.25969\n",
      "Epoch: 151/300 Iteration: 1506 Training loss: 0.23364\n",
      "Epoch: 151/300 Iteration: 1507 Training loss: 0.28892\n",
      "Epoch: 151/300 Iteration: 1508 Training loss: 0.45136\n",
      "Epoch: 151/300 Iteration: 1509 Training loss: 0.32562\n",
      "Epoch: 150/300 Iteration: 1510 Validation Acc: 0.5421\n",
      "Epoch: 152/300 Iteration: 1510 Training loss: 0.24841\n",
      "Epoch: 152/300 Iteration: 1511 Training loss: 0.24678\n",
      "Epoch: 152/300 Iteration: 1512 Training loss: 0.29085\n",
      "Epoch: 152/300 Iteration: 1513 Training loss: 0.36871\n",
      "Epoch: 152/300 Iteration: 1514 Training loss: 0.34835\n",
      "Epoch: 151/300 Iteration: 1515 Validation Acc: 0.5329\n",
      "Epoch: 152/300 Iteration: 1515 Training loss: 0.30502\n",
      "Epoch: 152/300 Iteration: 1516 Training loss: 0.26910\n",
      "Epoch: 152/300 Iteration: 1517 Training loss: 0.26905\n",
      "Epoch: 152/300 Iteration: 1518 Training loss: 0.28786\n",
      "Epoch: 152/300 Iteration: 1519 Training loss: 0.29506\n",
      "Epoch: 151/300 Iteration: 1520 Validation Acc: 0.5279\n",
      "Epoch: 153/300 Iteration: 1520 Training loss: 0.31428\n",
      "Epoch: 153/300 Iteration: 1521 Training loss: 0.28879\n",
      "Epoch: 153/300 Iteration: 1522 Training loss: 0.23300\n",
      "Epoch: 153/300 Iteration: 1523 Training loss: 0.24321\n",
      "Epoch: 153/300 Iteration: 1524 Training loss: 0.23952\n",
      "Epoch: 152/300 Iteration: 1525 Validation Acc: 0.5387\n",
      "Epoch: 153/300 Iteration: 1525 Training loss: 0.29742\n",
      "Epoch: 153/300 Iteration: 1526 Training loss: 0.26474\n",
      "Epoch: 153/300 Iteration: 1527 Training loss: 0.18119\n",
      "Epoch: 153/300 Iteration: 1528 Training loss: 0.17247\n",
      "Epoch: 153/300 Iteration: 1529 Training loss: 0.21627\n",
      "Epoch: 152/300 Iteration: 1530 Validation Acc: 0.5400\n",
      "Epoch: 154/300 Iteration: 1530 Training loss: 0.26821\n",
      "Epoch: 154/300 Iteration: 1531 Training loss: 0.25807\n",
      "Epoch: 154/300 Iteration: 1532 Training loss: 0.20434\n",
      "Epoch: 154/300 Iteration: 1533 Training loss: 0.18731\n",
      "Epoch: 154/300 Iteration: 1534 Training loss: 0.23036\n",
      "Epoch: 153/300 Iteration: 1535 Validation Acc: 0.5611\n",
      "Epoch: 154/300 Iteration: 1535 Training loss: 0.19296\n",
      "Epoch: 154/300 Iteration: 1536 Training loss: 0.18862\n",
      "Epoch: 154/300 Iteration: 1537 Training loss: 0.23592\n",
      "Epoch: 154/300 Iteration: 1538 Training loss: 0.22017\n",
      "Epoch: 154/300 Iteration: 1539 Training loss: 0.16051\n",
      "Epoch: 153/300 Iteration: 1540 Validation Acc: 0.5692\n",
      "Epoch: 155/300 Iteration: 1540 Training loss: 0.16784\n",
      "Epoch: 155/300 Iteration: 1541 Training loss: 0.21811\n",
      "Epoch: 155/300 Iteration: 1542 Training loss: 0.23955\n",
      "Epoch: 155/300 Iteration: 1543 Training loss: 0.18831\n",
      "Epoch: 155/300 Iteration: 1544 Training loss: 0.15645\n",
      "Epoch: 154/300 Iteration: 1545 Validation Acc: 0.5608\n",
      "Epoch: 155/300 Iteration: 1545 Training loss: 0.17077\n",
      "Epoch: 155/300 Iteration: 1546 Training loss: 0.21547\n",
      "Epoch: 155/300 Iteration: 1547 Training loss: 0.16799\n",
      "Epoch: 155/300 Iteration: 1548 Training loss: 0.16353\n",
      "Epoch: 155/300 Iteration: 1549 Training loss: 0.15220\n",
      "Epoch: 154/300 Iteration: 1550 Validation Acc: 0.5686\n",
      "Epoch: 156/300 Iteration: 1550 Training loss: 0.16153\n",
      "Epoch: 156/300 Iteration: 1551 Training loss: 0.17199\n",
      "Epoch: 156/300 Iteration: 1552 Training loss: 0.20243\n",
      "Epoch: 156/300 Iteration: 1553 Training loss: 0.18327\n",
      "Epoch: 156/300 Iteration: 1554 Training loss: 0.14920\n",
      "Epoch: 155/300 Iteration: 1555 Validation Acc: 0.5796\n",
      "Epoch: 156/300 Iteration: 1555 Training loss: 0.12307\n",
      "Epoch: 156/300 Iteration: 1556 Training loss: 0.13759\n",
      "Epoch: 156/300 Iteration: 1557 Training loss: 0.18405\n",
      "Epoch: 156/300 Iteration: 1558 Training loss: 0.20667\n",
      "Epoch: 156/300 Iteration: 1559 Training loss: 0.15082\n",
      "Epoch: 155/300 Iteration: 1560 Validation Acc: 0.5773\n",
      "Epoch: 157/300 Iteration: 1560 Training loss: 0.12710\n",
      "Epoch: 157/300 Iteration: 1561 Training loss: 0.11938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157/300 Iteration: 1562 Training loss: 0.14794\n",
      "Epoch: 157/300 Iteration: 1563 Training loss: 0.19786\n",
      "Epoch: 157/300 Iteration: 1564 Training loss: 0.16439\n",
      "Epoch: 156/300 Iteration: 1565 Validation Acc: 0.5803\n",
      "Epoch: 157/300 Iteration: 1565 Training loss: 0.11318\n",
      "Epoch: 157/300 Iteration: 1566 Training loss: 0.09361\n",
      "Epoch: 157/300 Iteration: 1567 Training loss: 0.12769\n",
      "Epoch: 157/300 Iteration: 1568 Training loss: 0.18041\n",
      "Epoch: 157/300 Iteration: 1569 Training loss: 0.16379\n",
      "Epoch: 156/300 Iteration: 1570 Validation Acc: 0.5848\n",
      "Epoch: 158/300 Iteration: 1570 Training loss: 0.12724\n",
      "Epoch: 158/300 Iteration: 1571 Training loss: 0.10123\n",
      "Epoch: 158/300 Iteration: 1572 Training loss: 0.10738\n",
      "Epoch: 158/300 Iteration: 1573 Training loss: 0.14804\n",
      "Epoch: 158/300 Iteration: 1574 Training loss: 0.18713\n",
      "Epoch: 157/300 Iteration: 1575 Validation Acc: 0.5771\n",
      "Epoch: 158/300 Iteration: 1575 Training loss: 0.13877\n",
      "Epoch: 158/300 Iteration: 1576 Training loss: 0.08894\n",
      "Epoch: 158/300 Iteration: 1577 Training loss: 0.08938\n",
      "Epoch: 158/300 Iteration: 1578 Training loss: 0.10878\n",
      "Epoch: 158/300 Iteration: 1579 Training loss: 0.15243\n",
      "Epoch: 157/300 Iteration: 1580 Validation Acc: 0.5727\n",
      "Epoch: 159/300 Iteration: 1580 Training loss: 0.15794\n",
      "Epoch: 159/300 Iteration: 1581 Training loss: 0.10250\n",
      "Epoch: 159/300 Iteration: 1582 Training loss: 0.08612\n",
      "Epoch: 159/300 Iteration: 1583 Training loss: 0.08954\n",
      "Epoch: 159/300 Iteration: 1584 Training loss: 0.12111\n",
      "Epoch: 158/300 Iteration: 1585 Validation Acc: 0.5727\n",
      "Epoch: 159/300 Iteration: 1585 Training loss: 0.13670\n",
      "Epoch: 159/300 Iteration: 1586 Training loss: 0.10746\n",
      "Epoch: 159/300 Iteration: 1587 Training loss: 0.09102\n",
      "Epoch: 159/300 Iteration: 1588 Training loss: 0.08274\n",
      "Epoch: 159/300 Iteration: 1589 Training loss: 0.08389\n",
      "Epoch: 158/300 Iteration: 1590 Validation Acc: 0.5846\n",
      "Epoch: 160/300 Iteration: 1590 Training loss: 0.10731\n",
      "Epoch: 160/300 Iteration: 1591 Training loss: 0.11356\n",
      "Epoch: 160/300 Iteration: 1592 Training loss: 0.09362\n",
      "Epoch: 160/300 Iteration: 1593 Training loss: 0.07776\n",
      "Epoch: 160/300 Iteration: 1594 Training loss: 0.08055\n",
      "Epoch: 159/300 Iteration: 1595 Validation Acc: 0.5846\n",
      "Epoch: 160/300 Iteration: 1595 Training loss: 0.07890\n",
      "Epoch: 160/300 Iteration: 1596 Training loss: 0.07940\n",
      "Epoch: 160/300 Iteration: 1597 Training loss: 0.08957\n",
      "Epoch: 160/300 Iteration: 1598 Training loss: 0.08200\n",
      "Epoch: 160/300 Iteration: 1599 Training loss: 0.07416\n",
      "Epoch: 159/300 Iteration: 1600 Validation Acc: 0.5874\n",
      "Epoch: 161/300 Iteration: 1600 Training loss: 0.07816\n",
      "Epoch: 161/300 Iteration: 1601 Training loss: 0.07679\n",
      "Epoch: 161/300 Iteration: 1602 Training loss: 0.07476\n",
      "Epoch: 161/300 Iteration: 1603 Training loss: 0.07623\n",
      "Epoch: 161/300 Iteration: 1604 Training loss: 0.07991\n",
      "Epoch: 160/300 Iteration: 1605 Validation Acc: 0.5871\n",
      "Epoch: 161/300 Iteration: 1605 Training loss: 0.07197\n",
      "Epoch: 161/300 Iteration: 1606 Training loss: 0.06565\n",
      "Epoch: 161/300 Iteration: 1607 Training loss: 0.07112\n",
      "Epoch: 161/300 Iteration: 1608 Training loss: 0.07390\n",
      "Epoch: 161/300 Iteration: 1609 Training loss: 0.06844\n",
      "Epoch: 160/300 Iteration: 1610 Validation Acc: 0.5876\n",
      "Epoch: 162/300 Iteration: 1610 Training loss: 0.07428\n",
      "Epoch: 162/300 Iteration: 1611 Training loss: 0.07210\n",
      "Epoch: 162/300 Iteration: 1612 Training loss: 0.06848\n",
      "Epoch: 162/300 Iteration: 1613 Training loss: 0.06867\n",
      "Epoch: 162/300 Iteration: 1614 Training loss: 0.07402\n",
      "Epoch: 161/300 Iteration: 1615 Validation Acc: 0.5888\n",
      "Epoch: 162/300 Iteration: 1615 Training loss: 0.06756\n",
      "Epoch: 162/300 Iteration: 1616 Training loss: 0.06170\n",
      "Epoch: 162/300 Iteration: 1617 Training loss: 0.06796\n",
      "Epoch: 162/300 Iteration: 1618 Training loss: 0.06846\n",
      "Epoch: 162/300 Iteration: 1619 Training loss: 0.06324\n",
      "Epoch: 161/300 Iteration: 1620 Validation Acc: 0.5899\n",
      "Epoch: 163/300 Iteration: 1620 Training loss: 0.07019\n",
      "Epoch: 163/300 Iteration: 1621 Training loss: 0.06851\n",
      "Epoch: 163/300 Iteration: 1622 Training loss: 0.06445\n",
      "Epoch: 163/300 Iteration: 1623 Training loss: 0.06330\n",
      "Epoch: 163/300 Iteration: 1624 Training loss: 0.06732\n",
      "Epoch: 162/300 Iteration: 1625 Validation Acc: 0.5867\n",
      "Epoch: 163/300 Iteration: 1625 Training loss: 0.06254\n",
      "Epoch: 163/300 Iteration: 1626 Training loss: 0.05875\n",
      "Epoch: 163/300 Iteration: 1627 Training loss: 0.06613\n",
      "Epoch: 163/300 Iteration: 1628 Training loss: 0.06648\n",
      "Epoch: 163/300 Iteration: 1629 Training loss: 0.05997\n",
      "Epoch: 162/300 Iteration: 1630 Validation Acc: 0.5911\n",
      "Epoch: 164/300 Iteration: 1630 Training loss: 0.06488\n",
      "Epoch: 164/300 Iteration: 1631 Training loss: 0.06592\n",
      "Epoch: 164/300 Iteration: 1632 Training loss: 0.06452\n",
      "Epoch: 164/300 Iteration: 1633 Training loss: 0.06377\n",
      "Epoch: 164/300 Iteration: 1634 Training loss: 0.06533\n",
      "Epoch: 163/300 Iteration: 1635 Validation Acc: 0.5899\n",
      "Epoch: 164/300 Iteration: 1635 Training loss: 0.05972\n",
      "Epoch: 164/300 Iteration: 1636 Training loss: 0.05616\n",
      "Epoch: 164/300 Iteration: 1637 Training loss: 0.06528\n",
      "Epoch: 164/300 Iteration: 1638 Training loss: 0.06705\n",
      "Epoch: 164/300 Iteration: 1639 Training loss: 0.06016\n",
      "Epoch: 163/300 Iteration: 1640 Validation Acc: 0.5909\n",
      "Epoch: 165/300 Iteration: 1640 Training loss: 0.06343\n",
      "Epoch: 165/300 Iteration: 1641 Training loss: 0.06233\n",
      "Epoch: 165/300 Iteration: 1642 Training loss: 0.06308\n",
      "Epoch: 165/300 Iteration: 1643 Training loss: 0.06485\n",
      "Epoch: 165/300 Iteration: 1644 Training loss: 0.06474\n",
      "Epoch: 164/300 Iteration: 1645 Validation Acc: 0.5917\n",
      "Epoch: 165/300 Iteration: 1645 Training loss: 0.05736\n",
      "Epoch: 165/300 Iteration: 1646 Training loss: 0.05374\n",
      "Epoch: 165/300 Iteration: 1647 Training loss: 0.06346\n",
      "Epoch: 165/300 Iteration: 1648 Training loss: 0.06726\n",
      "Epoch: 165/300 Iteration: 1649 Training loss: 0.06082\n",
      "Epoch: 164/300 Iteration: 1650 Validation Acc: 0.5926\n",
      "Epoch: 166/300 Iteration: 1650 Training loss: 0.06197\n",
      "Epoch: 166/300 Iteration: 1651 Training loss: 0.05935\n",
      "Epoch: 166/300 Iteration: 1652 Training loss: 0.06165\n",
      "Epoch: 166/300 Iteration: 1653 Training loss: 0.06545\n",
      "Epoch: 166/300 Iteration: 1654 Training loss: 0.06488\n",
      "Epoch: 165/300 Iteration: 1655 Validation Acc: 0.5911\n",
      "Epoch: 166/300 Iteration: 1655 Training loss: 0.05625\n",
      "Epoch: 166/300 Iteration: 1656 Training loss: 0.05111\n",
      "Epoch: 166/300 Iteration: 1657 Training loss: 0.06148\n",
      "Epoch: 166/300 Iteration: 1658 Training loss: 0.06728\n",
      "Epoch: 166/300 Iteration: 1659 Training loss: 0.06295\n",
      "Epoch: 165/300 Iteration: 1660 Validation Acc: 0.5915\n",
      "Epoch: 167/300 Iteration: 1660 Training loss: 0.06223\n",
      "Epoch: 167/300 Iteration: 1661 Training loss: 0.05686\n",
      "Epoch: 167/300 Iteration: 1662 Training loss: 0.05870\n",
      "Epoch: 167/300 Iteration: 1663 Training loss: 0.06517\n",
      "Epoch: 167/300 Iteration: 1664 Training loss: 0.06631\n",
      "Epoch: 166/300 Iteration: 1665 Validation Acc: 0.5915\n",
      "Epoch: 167/300 Iteration: 1665 Training loss: 0.05671\n",
      "Epoch: 167/300 Iteration: 1666 Training loss: 0.04915\n",
      "Epoch: 167/300 Iteration: 1667 Training loss: 0.05951\n",
      "Epoch: 167/300 Iteration: 1668 Training loss: 0.06730\n",
      "Epoch: 167/300 Iteration: 1669 Training loss: 0.06580\n",
      "Epoch: 166/300 Iteration: 1670 Validation Acc: 0.5909\n",
      "Epoch: 168/300 Iteration: 1670 Training loss: 0.06386\n",
      "Epoch: 168/300 Iteration: 1671 Training loss: 0.05538\n",
      "Epoch: 168/300 Iteration: 1672 Training loss: 0.05608\n",
      "Epoch: 168/300 Iteration: 1673 Training loss: 0.06357\n",
      "Epoch: 168/300 Iteration: 1674 Training loss: 0.06807\n",
      "Epoch: 167/300 Iteration: 1675 Validation Acc: 0.5917\n",
      "Epoch: 168/300 Iteration: 1675 Training loss: 0.05870\n",
      "Epoch: 168/300 Iteration: 1676 Training loss: 0.04808\n",
      "Epoch: 168/300 Iteration: 1677 Training loss: 0.05643\n",
      "Epoch: 168/300 Iteration: 1678 Training loss: 0.06467\n",
      "Epoch: 168/300 Iteration: 1679 Training loss: 0.06645\n",
      "Epoch: 167/300 Iteration: 1680 Validation Acc: 0.5890\n",
      "Epoch: 169/300 Iteration: 1680 Training loss: 0.06614\n",
      "Epoch: 169/300 Iteration: 1681 Training loss: 0.05547\n",
      "Epoch: 169/300 Iteration: 1682 Training loss: 0.05347\n",
      "Epoch: 169/300 Iteration: 1683 Training loss: 0.05950\n",
      "Epoch: 169/300 Iteration: 1684 Training loss: 0.06853\n",
      "Epoch: 168/300 Iteration: 1685 Validation Acc: 0.5911\n",
      "Epoch: 169/300 Iteration: 1685 Training loss: 0.06210\n",
      "Epoch: 169/300 Iteration: 1686 Training loss: 0.04874\n",
      "Epoch: 169/300 Iteration: 1687 Training loss: 0.05356\n",
      "Epoch: 169/300 Iteration: 1688 Training loss: 0.06064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 169/300 Iteration: 1689 Training loss: 0.06419\n",
      "Epoch: 168/300 Iteration: 1690 Validation Acc: 0.5888\n",
      "Epoch: 170/300 Iteration: 1690 Training loss: 0.06863\n",
      "Epoch: 170/300 Iteration: 1691 Training loss: 0.05764\n",
      "Epoch: 170/300 Iteration: 1692 Training loss: 0.05232\n",
      "Epoch: 170/300 Iteration: 1693 Training loss: 0.05385\n",
      "Epoch: 170/300 Iteration: 1694 Training loss: 0.06481\n",
      "Epoch: 169/300 Iteration: 1695 Validation Acc: 0.5894\n",
      "Epoch: 170/300 Iteration: 1695 Training loss: 0.06413\n",
      "Epoch: 170/300 Iteration: 1696 Training loss: 0.05152\n",
      "Epoch: 170/300 Iteration: 1697 Training loss: 0.05210\n",
      "Epoch: 170/300 Iteration: 1698 Training loss: 0.05629\n",
      "Epoch: 170/300 Iteration: 1699 Training loss: 0.05894\n",
      "Epoch: 169/300 Iteration: 1700 Validation Acc: 0.5886\n",
      "Epoch: 171/300 Iteration: 1700 Training loss: 0.06738\n",
      "Epoch: 171/300 Iteration: 1701 Training loss: 0.05990\n",
      "Epoch: 171/300 Iteration: 1702 Training loss: 0.05354\n",
      "Epoch: 171/300 Iteration: 1703 Training loss: 0.05047\n",
      "Epoch: 171/300 Iteration: 1704 Training loss: 0.05943\n",
      "Epoch: 170/300 Iteration: 1705 Validation Acc: 0.5882\n",
      "Epoch: 171/300 Iteration: 1705 Training loss: 0.06264\n",
      "Epoch: 171/300 Iteration: 1706 Training loss: 0.05550\n",
      "Epoch: 171/300 Iteration: 1707 Training loss: 0.05388\n",
      "Epoch: 171/300 Iteration: 1708 Training loss: 0.05368\n",
      "Epoch: 171/300 Iteration: 1709 Training loss: 0.05381\n",
      "Epoch: 170/300 Iteration: 1710 Validation Acc: 0.5888\n",
      "Epoch: 172/300 Iteration: 1710 Training loss: 0.06427\n",
      "Epoch: 172/300 Iteration: 1711 Training loss: 0.06117\n",
      "Epoch: 172/300 Iteration: 1712 Training loss: 0.05686\n",
      "Epoch: 172/300 Iteration: 1713 Training loss: 0.05025\n",
      "Epoch: 172/300 Iteration: 1714 Training loss: 0.05517\n",
      "Epoch: 171/300 Iteration: 1715 Validation Acc: 0.5907\n",
      "Epoch: 172/300 Iteration: 1715 Training loss: 0.05712\n",
      "Epoch: 172/300 Iteration: 1716 Training loss: 0.05625\n",
      "Epoch: 172/300 Iteration: 1717 Training loss: 0.05767\n",
      "Epoch: 172/300 Iteration: 1718 Training loss: 0.05368\n",
      "Epoch: 172/300 Iteration: 1719 Training loss: 0.04969\n",
      "Epoch: 171/300 Iteration: 1720 Validation Acc: 0.5922\n",
      "Epoch: 173/300 Iteration: 1720 Training loss: 0.05943\n",
      "Epoch: 173/300 Iteration: 1721 Training loss: 0.05984\n",
      "Epoch: 173/300 Iteration: 1722 Training loss: 0.06053\n",
      "Epoch: 173/300 Iteration: 1723 Training loss: 0.05286\n",
      "Epoch: 173/300 Iteration: 1724 Training loss: 0.05331\n",
      "Epoch: 172/300 Iteration: 1725 Validation Acc: 0.5922\n",
      "Epoch: 173/300 Iteration: 1725 Training loss: 0.05103\n",
      "Epoch: 173/300 Iteration: 1726 Training loss: 0.05246\n",
      "Epoch: 173/300 Iteration: 1727 Training loss: 0.06151\n",
      "Epoch: 173/300 Iteration: 1728 Training loss: 0.05716\n",
      "Epoch: 173/300 Iteration: 1729 Training loss: 0.04722\n",
      "Epoch: 172/300 Iteration: 1730 Validation Acc: 0.5934\n",
      "Epoch: 174/300 Iteration: 1730 Training loss: 0.05425\n",
      "Epoch: 174/300 Iteration: 1731 Training loss: 0.05502\n",
      "Epoch: 174/300 Iteration: 1732 Training loss: 0.06056\n",
      "Epoch: 174/300 Iteration: 1733 Training loss: 0.05672\n",
      "Epoch: 174/300 Iteration: 1734 Training loss: 0.05480\n",
      "Epoch: 173/300 Iteration: 1735 Validation Acc: 0.5936\n",
      "Epoch: 174/300 Iteration: 1735 Training loss: 0.04668\n",
      "Epoch: 174/300 Iteration: 1736 Training loss: 0.04519\n",
      "Epoch: 174/300 Iteration: 1737 Training loss: 0.05932\n",
      "Epoch: 174/300 Iteration: 1738 Training loss: 0.06111\n",
      "Epoch: 174/300 Iteration: 1739 Training loss: 0.04793\n",
      "Epoch: 173/300 Iteration: 1740 Validation Acc: 0.5953\n",
      "Epoch: 175/300 Iteration: 1740 Training loss: 0.05135\n",
      "Epoch: 175/300 Iteration: 1741 Training loss: 0.04973\n",
      "Epoch: 175/300 Iteration: 1742 Training loss: 0.05565\n",
      "Epoch: 175/300 Iteration: 1743 Training loss: 0.05820\n",
      "Epoch: 175/300 Iteration: 1744 Training loss: 0.05796\n",
      "Epoch: 174/300 Iteration: 1745 Validation Acc: 0.5947\n",
      "Epoch: 175/300 Iteration: 1745 Training loss: 0.04650\n",
      "Epoch: 175/300 Iteration: 1746 Training loss: 0.04041\n",
      "Epoch: 175/300 Iteration: 1747 Training loss: 0.05166\n",
      "Epoch: 175/300 Iteration: 1748 Training loss: 0.05872\n",
      "Epoch: 175/300 Iteration: 1749 Training loss: 0.05165\n",
      "Epoch: 174/300 Iteration: 1750 Validation Acc: 0.5940\n",
      "Epoch: 176/300 Iteration: 1750 Training loss: 0.05244\n",
      "Epoch: 176/300 Iteration: 1751 Training loss: 0.04680\n",
      "Epoch: 176/300 Iteration: 1752 Training loss: 0.04951\n",
      "Epoch: 176/300 Iteration: 1753 Training loss: 0.05411\n",
      "Epoch: 176/300 Iteration: 1754 Training loss: 0.05962\n",
      "Epoch: 175/300 Iteration: 1755 Validation Acc: 0.5928\n",
      "Epoch: 176/300 Iteration: 1755 Training loss: 0.04898\n",
      "Epoch: 176/300 Iteration: 1756 Training loss: 0.04039\n",
      "Epoch: 176/300 Iteration: 1757 Training loss: 0.04604\n",
      "Epoch: 176/300 Iteration: 1758 Training loss: 0.05187\n",
      "Epoch: 176/300 Iteration: 1759 Training loss: 0.05083\n",
      "Epoch: 175/300 Iteration: 1760 Validation Acc: 0.5934\n",
      "Epoch: 177/300 Iteration: 1760 Training loss: 0.05571\n",
      "Epoch: 177/300 Iteration: 1761 Training loss: 0.04758\n",
      "Epoch: 177/300 Iteration: 1762 Training loss: 0.04583\n",
      "Epoch: 177/300 Iteration: 1763 Training loss: 0.04818\n",
      "Epoch: 177/300 Iteration: 1764 Training loss: 0.05555\n",
      "Epoch: 176/300 Iteration: 1765 Validation Acc: 0.5915\n",
      "Epoch: 177/300 Iteration: 1765 Training loss: 0.04960\n",
      "Epoch: 177/300 Iteration: 1766 Training loss: 0.04288\n",
      "Epoch: 177/300 Iteration: 1767 Training loss: 0.04523\n",
      "Epoch: 177/300 Iteration: 1768 Training loss: 0.04748\n",
      "Epoch: 177/300 Iteration: 1769 Training loss: 0.04517\n",
      "Epoch: 176/300 Iteration: 1770 Validation Acc: 0.5936\n",
      "Epoch: 178/300 Iteration: 1770 Training loss: 0.05430\n",
      "Epoch: 178/300 Iteration: 1771 Training loss: 0.05084\n",
      "Epoch: 178/300 Iteration: 1772 Training loss: 0.04605\n",
      "Epoch: 178/300 Iteration: 1773 Training loss: 0.04422\n",
      "Epoch: 178/300 Iteration: 1774 Training loss: 0.04939\n",
      "Epoch: 177/300 Iteration: 1775 Validation Acc: 0.5922\n",
      "Epoch: 178/300 Iteration: 1775 Training loss: 0.04574\n",
      "Epoch: 178/300 Iteration: 1776 Training loss: 0.04275\n",
      "Epoch: 178/300 Iteration: 1777 Training loss: 0.04678\n",
      "Epoch: 178/300 Iteration: 1778 Training loss: 0.04757\n",
      "Epoch: 178/300 Iteration: 1779 Training loss: 0.04274\n",
      "Epoch: 177/300 Iteration: 1780 Validation Acc: 0.5951\n",
      "Epoch: 179/300 Iteration: 1780 Training loss: 0.04886\n",
      "Epoch: 179/300 Iteration: 1781 Training loss: 0.04824\n",
      "Epoch: 179/300 Iteration: 1782 Training loss: 0.04720\n",
      "Epoch: 179/300 Iteration: 1783 Training loss: 0.04463\n",
      "Epoch: 179/300 Iteration: 1784 Training loss: 0.04697\n",
      "Epoch: 178/300 Iteration: 1785 Validation Acc: 0.5938\n",
      "Epoch: 179/300 Iteration: 1785 Training loss: 0.04234\n",
      "Epoch: 179/300 Iteration: 1786 Training loss: 0.03865\n",
      "Epoch: 179/300 Iteration: 1787 Training loss: 0.04506\n",
      "Epoch: 179/300 Iteration: 1788 Training loss: 0.04804\n",
      "Epoch: 179/300 Iteration: 1789 Training loss: 0.04357\n",
      "Epoch: 178/300 Iteration: 1790 Validation Acc: 0.5932\n",
      "Epoch: 180/300 Iteration: 1790 Training loss: 0.04671\n",
      "Epoch: 180/300 Iteration: 1791 Training loss: 0.04337\n",
      "Epoch: 180/300 Iteration: 1792 Training loss: 0.04436\n",
      "Epoch: 180/300 Iteration: 1793 Training loss: 0.04449\n",
      "Epoch: 180/300 Iteration: 1794 Training loss: 0.04727\n",
      "Epoch: 179/300 Iteration: 1795 Validation Acc: 0.5947\n",
      "Epoch: 180/300 Iteration: 1795 Training loss: 0.04212\n",
      "Epoch: 180/300 Iteration: 1796 Training loss: 0.03629\n",
      "Epoch: 180/300 Iteration: 1797 Training loss: 0.04183\n",
      "Epoch: 180/300 Iteration: 1798 Training loss: 0.04586\n",
      "Epoch: 180/300 Iteration: 1799 Training loss: 0.04305\n",
      "Epoch: 179/300 Iteration: 1800 Validation Acc: 0.5924\n",
      "Epoch: 181/300 Iteration: 1800 Training loss: 0.04682\n",
      "Epoch: 181/300 Iteration: 1801 Training loss: 0.04233\n",
      "Epoch: 181/300 Iteration: 1802 Training loss: 0.04233\n",
      "Epoch: 181/300 Iteration: 1803 Training loss: 0.04206\n",
      "Epoch: 181/300 Iteration: 1804 Training loss: 0.04614\n",
      "Epoch: 180/300 Iteration: 1805 Validation Acc: 0.5944\n",
      "Epoch: 181/300 Iteration: 1805 Training loss: 0.04205\n",
      "Epoch: 181/300 Iteration: 1806 Training loss: 0.03603\n",
      "Epoch: 181/300 Iteration: 1807 Training loss: 0.04087\n",
      "Epoch: 181/300 Iteration: 1808 Training loss: 0.04408\n",
      "Epoch: 181/300 Iteration: 1809 Training loss: 0.04125\n",
      "Epoch: 180/300 Iteration: 1810 Validation Acc: 0.5938\n",
      "Epoch: 182/300 Iteration: 1810 Training loss: 0.04550\n",
      "Epoch: 182/300 Iteration: 1811 Training loss: 0.04177\n",
      "Epoch: 182/300 Iteration: 1812 Training loss: 0.04174\n",
      "Epoch: 182/300 Iteration: 1813 Training loss: 0.04095\n",
      "Epoch: 182/300 Iteration: 1814 Training loss: 0.04476\n",
      "Epoch: 181/300 Iteration: 1815 Validation Acc: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 182/300 Iteration: 1815 Training loss: 0.04065\n",
      "Epoch: 182/300 Iteration: 1816 Training loss: 0.03530\n",
      "Epoch: 182/300 Iteration: 1817 Training loss: 0.04032\n",
      "Epoch: 182/300 Iteration: 1818 Training loss: 0.04347\n",
      "Epoch: 182/300 Iteration: 1819 Training loss: 0.04011\n",
      "Epoch: 181/300 Iteration: 1820 Validation Acc: 0.5938\n",
      "Epoch: 183/300 Iteration: 1820 Training loss: 0.04419\n",
      "Epoch: 183/300 Iteration: 1821 Training loss: 0.04059\n",
      "Epoch: 183/300 Iteration: 1822 Training loss: 0.04106\n",
      "Epoch: 183/300 Iteration: 1823 Training loss: 0.04054\n",
      "Epoch: 183/300 Iteration: 1824 Training loss: 0.04424\n",
      "Epoch: 182/300 Iteration: 1825 Validation Acc: 0.5938\n",
      "Epoch: 183/300 Iteration: 1825 Training loss: 0.03954\n",
      "Epoch: 183/300 Iteration: 1826 Training loss: 0.03432\n",
      "Epoch: 183/300 Iteration: 1827 Training loss: 0.03929\n",
      "Epoch: 183/300 Iteration: 1828 Training loss: 0.04276\n",
      "Epoch: 183/300 Iteration: 1829 Training loss: 0.03945\n",
      "Epoch: 182/300 Iteration: 1830 Validation Acc: 0.5944\n",
      "Epoch: 184/300 Iteration: 1830 Training loss: 0.04347\n",
      "Epoch: 184/300 Iteration: 1831 Training loss: 0.03983\n",
      "Epoch: 184/300 Iteration: 1832 Training loss: 0.04025\n",
      "Epoch: 184/300 Iteration: 1833 Training loss: 0.03962\n",
      "Epoch: 184/300 Iteration: 1834 Training loss: 0.04351\n",
      "Epoch: 183/300 Iteration: 1835 Validation Acc: 0.5944\n",
      "Epoch: 184/300 Iteration: 1835 Training loss: 0.03901\n",
      "Epoch: 184/300 Iteration: 1836 Training loss: 0.03381\n",
      "Epoch: 184/300 Iteration: 1837 Training loss: 0.03849\n",
      "Epoch: 184/300 Iteration: 1838 Training loss: 0.04189\n",
      "Epoch: 184/300 Iteration: 1839 Training loss: 0.03883\n",
      "Epoch: 183/300 Iteration: 1840 Validation Acc: 0.5947\n",
      "Epoch: 185/300 Iteration: 1840 Training loss: 0.04288\n",
      "Epoch: 185/300 Iteration: 1841 Training loss: 0.03938\n",
      "Epoch: 185/300 Iteration: 1842 Training loss: 0.03971\n",
      "Epoch: 185/300 Iteration: 1843 Training loss: 0.03889\n",
      "Epoch: 185/300 Iteration: 1844 Training loss: 0.04263\n",
      "Epoch: 184/300 Iteration: 1845 Validation Acc: 0.5944\n",
      "Epoch: 185/300 Iteration: 1845 Training loss: 0.03843\n",
      "Epoch: 185/300 Iteration: 1846 Training loss: 0.03330\n",
      "Epoch: 185/300 Iteration: 1847 Training loss: 0.03789\n",
      "Epoch: 185/300 Iteration: 1848 Training loss: 0.04137\n",
      "Epoch: 185/300 Iteration: 1849 Training loss: 0.03836\n",
      "Epoch: 184/300 Iteration: 1850 Validation Acc: 0.5947\n",
      "Epoch: 186/300 Iteration: 1850 Training loss: 0.04224\n",
      "Epoch: 186/300 Iteration: 1851 Training loss: 0.03876\n",
      "Epoch: 186/300 Iteration: 1852 Training loss: 0.03912\n",
      "Epoch: 186/300 Iteration: 1853 Training loss: 0.03833\n",
      "Epoch: 186/300 Iteration: 1854 Training loss: 0.04200\n",
      "Epoch: 185/300 Iteration: 1855 Validation Acc: 0.5942\n",
      "Epoch: 186/300 Iteration: 1855 Training loss: 0.03794\n",
      "Epoch: 186/300 Iteration: 1856 Training loss: 0.03271\n",
      "Epoch: 186/300 Iteration: 1857 Training loss: 0.03728\n",
      "Epoch: 186/300 Iteration: 1858 Training loss: 0.04075\n",
      "Epoch: 186/300 Iteration: 1859 Training loss: 0.03804\n",
      "Epoch: 185/300 Iteration: 1860 Validation Acc: 0.5947\n",
      "Epoch: 187/300 Iteration: 1860 Training loss: 0.04160\n",
      "Epoch: 187/300 Iteration: 1861 Training loss: 0.03799\n",
      "Epoch: 187/300 Iteration: 1862 Training loss: 0.03842\n",
      "Epoch: 187/300 Iteration: 1863 Training loss: 0.03767\n",
      "Epoch: 187/300 Iteration: 1864 Training loss: 0.04138\n",
      "Epoch: 186/300 Iteration: 1865 Validation Acc: 0.5942\n",
      "Epoch: 187/300 Iteration: 1865 Training loss: 0.03742\n",
      "Epoch: 187/300 Iteration: 1866 Training loss: 0.03226\n",
      "Epoch: 187/300 Iteration: 1867 Training loss: 0.03680\n",
      "Epoch: 187/300 Iteration: 1868 Training loss: 0.04015\n",
      "Epoch: 187/300 Iteration: 1869 Training loss: 0.03757\n",
      "Epoch: 186/300 Iteration: 1870 Validation Acc: 0.5947\n",
      "Epoch: 188/300 Iteration: 1870 Training loss: 0.04105\n",
      "Epoch: 188/300 Iteration: 1871 Training loss: 0.03735\n",
      "Epoch: 188/300 Iteration: 1872 Training loss: 0.03793\n",
      "Epoch: 188/300 Iteration: 1873 Training loss: 0.03712\n",
      "Epoch: 188/300 Iteration: 1874 Training loss: 0.04089\n",
      "Epoch: 187/300 Iteration: 1875 Validation Acc: 0.5951\n",
      "Epoch: 188/300 Iteration: 1875 Training loss: 0.03698\n",
      "Epoch: 188/300 Iteration: 1876 Training loss: 0.03175\n",
      "Epoch: 188/300 Iteration: 1877 Training loss: 0.03625\n",
      "Epoch: 188/300 Iteration: 1878 Training loss: 0.03973\n",
      "Epoch: 188/300 Iteration: 1879 Training loss: 0.03717\n",
      "Epoch: 187/300 Iteration: 1880 Validation Acc: 0.5949\n",
      "Epoch: 189/300 Iteration: 1880 Training loss: 0.04049\n",
      "Epoch: 189/300 Iteration: 1881 Training loss: 0.03659\n",
      "Epoch: 189/300 Iteration: 1882 Training loss: 0.03745\n",
      "Epoch: 189/300 Iteration: 1883 Training loss: 0.03649\n",
      "Epoch: 189/300 Iteration: 1884 Training loss: 0.04036\n",
      "Epoch: 188/300 Iteration: 1885 Validation Acc: 0.5949\n",
      "Epoch: 189/300 Iteration: 1885 Training loss: 0.03647\n",
      "Epoch: 189/300 Iteration: 1886 Training loss: 0.03132\n",
      "Epoch: 189/300 Iteration: 1887 Training loss: 0.03567\n",
      "Epoch: 189/300 Iteration: 1888 Training loss: 0.03929\n",
      "Epoch: 189/300 Iteration: 1889 Training loss: 0.03667\n",
      "Epoch: 188/300 Iteration: 1890 Validation Acc: 0.5955\n",
      "Epoch: 190/300 Iteration: 1890 Training loss: 0.04006\n",
      "Epoch: 190/300 Iteration: 1891 Training loss: 0.03615\n",
      "Epoch: 190/300 Iteration: 1892 Training loss: 0.03685\n",
      "Epoch: 190/300 Iteration: 1893 Training loss: 0.03595\n",
      "Epoch: 190/300 Iteration: 1894 Training loss: 0.03977\n",
      "Epoch: 189/300 Iteration: 1895 Validation Acc: 0.5949\n",
      "Epoch: 190/300 Iteration: 1895 Training loss: 0.03597\n",
      "Epoch: 190/300 Iteration: 1896 Training loss: 0.03094\n",
      "Epoch: 190/300 Iteration: 1897 Training loss: 0.03511\n",
      "Epoch: 190/300 Iteration: 1898 Training loss: 0.03881\n",
      "Epoch: 190/300 Iteration: 1899 Training loss: 0.03590\n",
      "Epoch: 189/300 Iteration: 1900 Validation Acc: 0.5953\n",
      "Epoch: 191/300 Iteration: 1900 Training loss: 0.03950\n",
      "Epoch: 191/300 Iteration: 1901 Training loss: 0.03572\n",
      "Epoch: 191/300 Iteration: 1902 Training loss: 0.03633\n",
      "Epoch: 191/300 Iteration: 1903 Training loss: 0.03540\n",
      "Epoch: 191/300 Iteration: 1904 Training loss: 0.03928\n",
      "Epoch: 190/300 Iteration: 1905 Validation Acc: 0.5949\n",
      "Epoch: 191/300 Iteration: 1905 Training loss: 0.03553\n",
      "Epoch: 191/300 Iteration: 1906 Training loss: 0.03035\n",
      "Epoch: 191/300 Iteration: 1907 Training loss: 0.03453\n",
      "Epoch: 191/300 Iteration: 1908 Training loss: 0.03823\n",
      "Epoch: 191/300 Iteration: 1909 Training loss: 0.03555\n",
      "Epoch: 190/300 Iteration: 1910 Validation Acc: 0.5951\n",
      "Epoch: 192/300 Iteration: 1910 Training loss: 0.03897\n",
      "Epoch: 192/300 Iteration: 1911 Training loss: 0.03522\n",
      "Epoch: 192/300 Iteration: 1912 Training loss: 0.03575\n",
      "Epoch: 192/300 Iteration: 1913 Training loss: 0.03483\n",
      "Epoch: 192/300 Iteration: 1914 Training loss: 0.03865\n",
      "Epoch: 191/300 Iteration: 1915 Validation Acc: 0.5940\n",
      "Epoch: 192/300 Iteration: 1915 Training loss: 0.03508\n",
      "Epoch: 192/300 Iteration: 1916 Training loss: 0.02986\n",
      "Epoch: 192/300 Iteration: 1917 Training loss: 0.03395\n",
      "Epoch: 192/300 Iteration: 1918 Training loss: 0.03775\n",
      "Epoch: 192/300 Iteration: 1919 Training loss: 0.03520\n",
      "Epoch: 191/300 Iteration: 1920 Validation Acc: 0.5955\n",
      "Epoch: 193/300 Iteration: 1920 Training loss: 0.03857\n",
      "Epoch: 193/300 Iteration: 1921 Training loss: 0.03480\n",
      "Epoch: 193/300 Iteration: 1922 Training loss: 0.03539\n",
      "Epoch: 193/300 Iteration: 1923 Training loss: 0.03441\n",
      "Epoch: 193/300 Iteration: 1924 Training loss: 0.03819\n",
      "Epoch: 192/300 Iteration: 1925 Validation Acc: 0.5947\n",
      "Epoch: 193/300 Iteration: 1925 Training loss: 0.03468\n",
      "Epoch: 193/300 Iteration: 1926 Training loss: 0.02961\n",
      "Epoch: 193/300 Iteration: 1927 Training loss: 0.03365\n",
      "Epoch: 193/300 Iteration: 1928 Training loss: 0.03736\n",
      "Epoch: 193/300 Iteration: 1929 Training loss: 0.03481\n",
      "Epoch: 192/300 Iteration: 1930 Validation Acc: 0.5947\n",
      "Epoch: 194/300 Iteration: 1930 Training loss: 0.03808\n",
      "Epoch: 194/300 Iteration: 1931 Training loss: 0.03427\n",
      "Epoch: 194/300 Iteration: 1932 Training loss: 0.03505\n",
      "Epoch: 194/300 Iteration: 1933 Training loss: 0.03402\n",
      "Epoch: 194/300 Iteration: 1934 Training loss: 0.03787\n",
      "Epoch: 193/300 Iteration: 1935 Validation Acc: 0.5936\n",
      "Epoch: 194/300 Iteration: 1935 Training loss: 0.03419\n",
      "Epoch: 194/300 Iteration: 1936 Training loss: 0.02912\n",
      "Epoch: 194/300 Iteration: 1937 Training loss: 0.03314\n",
      "Epoch: 194/300 Iteration: 1938 Training loss: 0.03717\n",
      "Epoch: 194/300 Iteration: 1939 Training loss: 0.03447\n",
      "Epoch: 193/300 Iteration: 1940 Validation Acc: 0.5953\n",
      "Epoch: 195/300 Iteration: 1940 Training loss: 0.03769\n",
      "Epoch: 195/300 Iteration: 1941 Training loss: 0.03373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195/300 Iteration: 1942 Training loss: 0.03461\n",
      "Epoch: 195/300 Iteration: 1943 Training loss: 0.03368\n",
      "Epoch: 195/300 Iteration: 1944 Training loss: 0.03749\n",
      "Epoch: 194/300 Iteration: 1945 Validation Acc: 0.5947\n",
      "Epoch: 195/300 Iteration: 1945 Training loss: 0.03394\n",
      "Epoch: 195/300 Iteration: 1946 Training loss: 0.02883\n",
      "Epoch: 195/300 Iteration: 1947 Training loss: 0.03262\n",
      "Epoch: 195/300 Iteration: 1948 Training loss: 0.03669\n",
      "Epoch: 195/300 Iteration: 1949 Training loss: 0.03421\n",
      "Epoch: 194/300 Iteration: 1950 Validation Acc: 0.5957\n",
      "Epoch: 196/300 Iteration: 1950 Training loss: 0.03726\n",
      "Epoch: 196/300 Iteration: 1951 Training loss: 0.03338\n",
      "Epoch: 196/300 Iteration: 1952 Training loss: 0.03415\n",
      "Epoch: 196/300 Iteration: 1953 Training loss: 0.03322\n",
      "Epoch: 196/300 Iteration: 1954 Training loss: 0.03692\n",
      "Epoch: 195/300 Iteration: 1955 Validation Acc: 0.5951\n",
      "Epoch: 196/300 Iteration: 1955 Training loss: 0.03354\n",
      "Epoch: 196/300 Iteration: 1956 Training loss: 0.02844\n",
      "Epoch: 196/300 Iteration: 1957 Training loss: 0.03232\n",
      "Epoch: 196/300 Iteration: 1958 Training loss: 0.03617\n",
      "Epoch: 196/300 Iteration: 1959 Training loss: 0.03382\n",
      "Epoch: 195/300 Iteration: 1960 Validation Acc: 0.5953\n",
      "Epoch: 197/300 Iteration: 1960 Training loss: 0.03683\n",
      "Epoch: 197/300 Iteration: 1961 Training loss: 0.03283\n",
      "Epoch: 197/300 Iteration: 1962 Training loss: 0.03364\n",
      "Epoch: 197/300 Iteration: 1963 Training loss: 0.03271\n",
      "Epoch: 197/300 Iteration: 1964 Training loss: 0.03642\n",
      "Epoch: 196/300 Iteration: 1965 Validation Acc: 0.5953\n",
      "Epoch: 197/300 Iteration: 1965 Training loss: 0.03304\n",
      "Epoch: 197/300 Iteration: 1966 Training loss: 0.02794\n",
      "Epoch: 197/300 Iteration: 1967 Training loss: 0.03181\n",
      "Epoch: 197/300 Iteration: 1968 Training loss: 0.03577\n",
      "Epoch: 197/300 Iteration: 1969 Training loss: 0.03343\n",
      "Epoch: 196/300 Iteration: 1970 Validation Acc: 0.5951\n",
      "Epoch: 198/300 Iteration: 1970 Training loss: 0.03647\n",
      "Epoch: 198/300 Iteration: 1971 Training loss: 0.03221\n",
      "Epoch: 198/300 Iteration: 1972 Training loss: 0.03326\n",
      "Epoch: 198/300 Iteration: 1973 Training loss: 0.03214\n",
      "Epoch: 198/300 Iteration: 1974 Training loss: 0.03594\n",
      "Epoch: 197/300 Iteration: 1975 Validation Acc: 0.5944\n",
      "Epoch: 198/300 Iteration: 1975 Training loss: 0.03274\n",
      "Epoch: 198/300 Iteration: 1976 Training loss: 0.02759\n",
      "Epoch: 198/300 Iteration: 1977 Training loss: 0.03145\n",
      "Epoch: 198/300 Iteration: 1978 Training loss: 0.03549\n",
      "Epoch: 198/300 Iteration: 1979 Training loss: 0.03295\n",
      "Epoch: 197/300 Iteration: 1980 Validation Acc: 0.5953\n",
      "Epoch: 199/300 Iteration: 1980 Training loss: 0.03611\n",
      "Epoch: 199/300 Iteration: 1981 Training loss: 0.03180\n",
      "Epoch: 199/300 Iteration: 1982 Training loss: 0.03288\n",
      "Epoch: 199/300 Iteration: 1983 Training loss: 0.03173\n",
      "Epoch: 199/300 Iteration: 1984 Training loss: 0.03558\n",
      "Epoch: 198/300 Iteration: 1985 Validation Acc: 0.5947\n",
      "Epoch: 199/300 Iteration: 1985 Training loss: 0.03253\n",
      "Epoch: 199/300 Iteration: 1986 Training loss: 0.02739\n",
      "Epoch: 199/300 Iteration: 1987 Training loss: 0.03118\n",
      "Epoch: 199/300 Iteration: 1988 Training loss: 0.03509\n",
      "Epoch: 199/300 Iteration: 1989 Training loss: 0.03264\n",
      "Epoch: 198/300 Iteration: 1990 Validation Acc: 0.5942\n",
      "Epoch: 200/300 Iteration: 1990 Training loss: 0.03573\n",
      "Epoch: 200/300 Iteration: 1991 Training loss: 0.03142\n",
      "Epoch: 200/300 Iteration: 1992 Training loss: 0.03261\n",
      "Epoch: 200/300 Iteration: 1993 Training loss: 0.03144\n",
      "Epoch: 200/300 Iteration: 1994 Training loss: 0.03525\n",
      "Epoch: 199/300 Iteration: 1995 Validation Acc: 0.5949\n",
      "Epoch: 200/300 Iteration: 1995 Training loss: 0.03202\n",
      "Epoch: 200/300 Iteration: 1996 Training loss: 0.02705\n",
      "Epoch: 200/300 Iteration: 1997 Training loss: 0.03081\n",
      "Epoch: 200/300 Iteration: 1998 Training loss: 0.03481\n",
      "Epoch: 200/300 Iteration: 1999 Training loss: 0.03229\n",
      "Epoch: 199/300 Iteration: 2000 Validation Acc: 0.5949\n",
      "Epoch: 201/300 Iteration: 2000 Training loss: 0.03532\n",
      "Epoch: 201/300 Iteration: 2001 Training loss: 0.03098\n",
      "Epoch: 201/300 Iteration: 2002 Training loss: 0.03214\n",
      "Epoch: 201/300 Iteration: 2003 Training loss: 0.03112\n",
      "Epoch: 201/300 Iteration: 2004 Training loss: 0.03491\n",
      "Epoch: 200/300 Iteration: 2005 Validation Acc: 0.5949\n",
      "Epoch: 201/300 Iteration: 2005 Training loss: 0.03162\n",
      "Epoch: 201/300 Iteration: 2006 Training loss: 0.02662\n",
      "Epoch: 201/300 Iteration: 2007 Training loss: 0.03029\n",
      "Epoch: 201/300 Iteration: 2008 Training loss: 0.03440\n",
      "Epoch: 201/300 Iteration: 2009 Training loss: 0.03191\n",
      "Epoch: 200/300 Iteration: 2010 Validation Acc: 0.5940\n",
      "Epoch: 202/300 Iteration: 2010 Training loss: 0.03495\n",
      "Epoch: 202/300 Iteration: 2011 Training loss: 0.03060\n",
      "Epoch: 202/300 Iteration: 2012 Training loss: 0.03169\n",
      "Epoch: 202/300 Iteration: 2013 Training loss: 0.03068\n",
      "Epoch: 202/300 Iteration: 2014 Training loss: 0.03452\n",
      "Epoch: 201/300 Iteration: 2015 Validation Acc: 0.5947\n",
      "Epoch: 202/300 Iteration: 2015 Training loss: 0.03113\n",
      "Epoch: 202/300 Iteration: 2016 Training loss: 0.02623\n",
      "Epoch: 202/300 Iteration: 2017 Training loss: 0.02992\n",
      "Epoch: 202/300 Iteration: 2018 Training loss: 0.03403\n",
      "Epoch: 202/300 Iteration: 2019 Training loss: 0.03150\n",
      "Epoch: 201/300 Iteration: 2020 Validation Acc: 0.5947\n",
      "Epoch: 203/300 Iteration: 2020 Training loss: 0.03461\n",
      "Epoch: 203/300 Iteration: 2021 Training loss: 0.03026\n",
      "Epoch: 203/300 Iteration: 2022 Training loss: 0.03130\n",
      "Epoch: 203/300 Iteration: 2023 Training loss: 0.03030\n",
      "Epoch: 203/300 Iteration: 2024 Training loss: 0.03405\n",
      "Epoch: 202/300 Iteration: 2025 Validation Acc: 0.5944\n",
      "Epoch: 203/300 Iteration: 2025 Training loss: 0.03081\n",
      "Epoch: 203/300 Iteration: 2026 Training loss: 0.02583\n",
      "Epoch: 203/300 Iteration: 2027 Training loss: 0.02961\n",
      "Epoch: 203/300 Iteration: 2028 Training loss: 0.03366\n",
      "Epoch: 203/300 Iteration: 2029 Training loss: 0.03112\n",
      "Epoch: 202/300 Iteration: 2030 Validation Acc: 0.5949\n",
      "Epoch: 204/300 Iteration: 2030 Training loss: 0.03429\n",
      "Epoch: 204/300 Iteration: 2031 Training loss: 0.02991\n",
      "Epoch: 204/300 Iteration: 2032 Training loss: 0.03096\n",
      "Epoch: 204/300 Iteration: 2033 Training loss: 0.02990\n",
      "Epoch: 204/300 Iteration: 2034 Training loss: 0.03364\n",
      "Epoch: 203/300 Iteration: 2035 Validation Acc: 0.5940\n",
      "Epoch: 204/300 Iteration: 2035 Training loss: 0.03044\n",
      "Epoch: 204/300 Iteration: 2036 Training loss: 0.02550\n",
      "Epoch: 204/300 Iteration: 2037 Training loss: 0.02929\n",
      "Epoch: 204/300 Iteration: 2038 Training loss: 0.03342\n",
      "Epoch: 204/300 Iteration: 2039 Training loss: 0.03084\n",
      "Epoch: 203/300 Iteration: 2040 Validation Acc: 0.5951\n",
      "Epoch: 205/300 Iteration: 2040 Training loss: 0.03395\n",
      "Epoch: 205/300 Iteration: 2041 Training loss: 0.02952\n",
      "Epoch: 205/300 Iteration: 2042 Training loss: 0.03071\n",
      "Epoch: 205/300 Iteration: 2043 Training loss: 0.02962\n",
      "Epoch: 205/300 Iteration: 2044 Training loss: 0.03328\n",
      "Epoch: 204/300 Iteration: 2045 Validation Acc: 0.5942\n",
      "Epoch: 205/300 Iteration: 2045 Training loss: 0.03015\n",
      "Epoch: 205/300 Iteration: 2046 Training loss: 0.02525\n",
      "Epoch: 205/300 Iteration: 2047 Training loss: 0.02903\n",
      "Epoch: 205/300 Iteration: 2048 Training loss: 0.03316\n",
      "Epoch: 205/300 Iteration: 2049 Training loss: 0.03067\n",
      "Epoch: 204/300 Iteration: 2050 Validation Acc: 0.5942\n",
      "Epoch: 206/300 Iteration: 2050 Training loss: 0.03359\n",
      "Epoch: 206/300 Iteration: 2051 Training loss: 0.02917\n",
      "Epoch: 206/300 Iteration: 2052 Training loss: 0.03041\n",
      "Epoch: 206/300 Iteration: 2053 Training loss: 0.02936\n",
      "Epoch: 206/300 Iteration: 2054 Training loss: 0.03301\n",
      "Epoch: 205/300 Iteration: 2055 Validation Acc: 0.5949\n",
      "Epoch: 206/300 Iteration: 2055 Training loss: 0.02998\n",
      "Epoch: 206/300 Iteration: 2056 Training loss: 0.02497\n",
      "Epoch: 206/300 Iteration: 2057 Training loss: 0.02865\n",
      "Epoch: 206/300 Iteration: 2058 Training loss: 0.03298\n",
      "Epoch: 206/300 Iteration: 2059 Training loss: 0.03057\n",
      "Epoch: 205/300 Iteration: 2060 Validation Acc: 0.5947\n",
      "Epoch: 207/300 Iteration: 2060 Training loss: 0.03332\n",
      "Epoch: 207/300 Iteration: 2061 Training loss: 0.02877\n",
      "Epoch: 207/300 Iteration: 2062 Training loss: 0.03007\n",
      "Epoch: 207/300 Iteration: 2063 Training loss: 0.02898\n",
      "Epoch: 207/300 Iteration: 2064 Training loss: 0.03268\n",
      "Epoch: 206/300 Iteration: 2065 Validation Acc: 0.5949\n",
      "Epoch: 207/300 Iteration: 2065 Training loss: 0.02968\n",
      "Epoch: 207/300 Iteration: 2066 Training loss: 0.02469\n",
      "Epoch: 207/300 Iteration: 2067 Training loss: 0.02819\n",
      "Epoch: 207/300 Iteration: 2068 Training loss: 0.03261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207/300 Iteration: 2069 Training loss: 0.03022\n",
      "Epoch: 206/300 Iteration: 2070 Validation Acc: 0.5947\n",
      "Epoch: 208/300 Iteration: 2070 Training loss: 0.03298\n",
      "Epoch: 208/300 Iteration: 2071 Training loss: 0.02838\n",
      "Epoch: 208/300 Iteration: 2072 Training loss: 0.02963\n",
      "Epoch: 208/300 Iteration: 2073 Training loss: 0.02868\n",
      "Epoch: 208/300 Iteration: 2074 Training loss: 0.03236\n",
      "Epoch: 207/300 Iteration: 2075 Validation Acc: 0.5953\n",
      "Epoch: 208/300 Iteration: 2075 Training loss: 0.02933\n",
      "Epoch: 208/300 Iteration: 2076 Training loss: 0.02442\n",
      "Epoch: 208/300 Iteration: 2077 Training loss: 0.02781\n",
      "Epoch: 208/300 Iteration: 2078 Training loss: 0.03220\n",
      "Epoch: 208/300 Iteration: 2079 Training loss: 0.02972\n",
      "Epoch: 207/300 Iteration: 2080 Validation Acc: 0.5944\n",
      "Epoch: 209/300 Iteration: 2080 Training loss: 0.03268\n",
      "Epoch: 209/300 Iteration: 2081 Training loss: 0.02809\n",
      "Epoch: 209/300 Iteration: 2082 Training loss: 0.02927\n",
      "Epoch: 209/300 Iteration: 2083 Training loss: 0.02823\n",
      "Epoch: 209/300 Iteration: 2084 Training loss: 0.03199\n",
      "Epoch: 208/300 Iteration: 2085 Validation Acc: 0.5949\n",
      "Epoch: 209/300 Iteration: 2085 Training loss: 0.02906\n",
      "Epoch: 209/300 Iteration: 2086 Training loss: 0.02414\n",
      "Epoch: 209/300 Iteration: 2087 Training loss: 0.02755\n",
      "Epoch: 209/300 Iteration: 2088 Training loss: 0.03188\n",
      "Epoch: 209/300 Iteration: 2089 Training loss: 0.02936\n",
      "Epoch: 208/300 Iteration: 2090 Validation Acc: 0.5949\n",
      "Epoch: 210/300 Iteration: 2090 Training loss: 0.03241\n",
      "Epoch: 210/300 Iteration: 2091 Training loss: 0.02779\n",
      "Epoch: 210/300 Iteration: 2092 Training loss: 0.02911\n",
      "Epoch: 210/300 Iteration: 2093 Training loss: 0.02792\n",
      "Epoch: 210/300 Iteration: 2094 Training loss: 0.03155\n",
      "Epoch: 209/300 Iteration: 2095 Validation Acc: 0.5955\n",
      "Epoch: 210/300 Iteration: 2095 Training loss: 0.02866\n",
      "Epoch: 210/300 Iteration: 2096 Training loss: 0.02392\n",
      "Epoch: 210/300 Iteration: 2097 Training loss: 0.02742\n",
      "Epoch: 210/300 Iteration: 2098 Training loss: 0.03159\n",
      "Epoch: 210/300 Iteration: 2099 Training loss: 0.02902\n",
      "Epoch: 209/300 Iteration: 2100 Validation Acc: 0.5949\n",
      "Epoch: 211/300 Iteration: 2100 Training loss: 0.03194\n",
      "Epoch: 211/300 Iteration: 2101 Training loss: 0.02736\n",
      "Epoch: 211/300 Iteration: 2102 Training loss: 0.02884\n",
      "Epoch: 211/300 Iteration: 2103 Training loss: 0.02783\n",
      "Epoch: 211/300 Iteration: 2104 Training loss: 0.03134\n",
      "Epoch: 210/300 Iteration: 2105 Validation Acc: 0.5949\n",
      "Epoch: 211/300 Iteration: 2105 Training loss: 0.02827\n",
      "Epoch: 211/300 Iteration: 2106 Training loss: 0.02349\n",
      "Epoch: 211/300 Iteration: 2107 Training loss: 0.02698\n",
      "Epoch: 211/300 Iteration: 2108 Training loss: 0.03124\n",
      "Epoch: 211/300 Iteration: 2109 Training loss: 0.02884\n",
      "Epoch: 210/300 Iteration: 2110 Validation Acc: 0.5951\n",
      "Epoch: 212/300 Iteration: 2110 Training loss: 0.03174\n",
      "Epoch: 212/300 Iteration: 2111 Training loss: 0.02698\n",
      "Epoch: 212/300 Iteration: 2112 Training loss: 0.02847\n",
      "Epoch: 212/300 Iteration: 2113 Training loss: 0.02751\n",
      "Epoch: 212/300 Iteration: 2114 Training loss: 0.03114\n",
      "Epoch: 211/300 Iteration: 2115 Validation Acc: 0.5953\n",
      "Epoch: 212/300 Iteration: 2115 Training loss: 0.02804\n",
      "Epoch: 212/300 Iteration: 2116 Training loss: 0.02334\n",
      "Epoch: 212/300 Iteration: 2117 Training loss: 0.02657\n",
      "Epoch: 212/300 Iteration: 2118 Training loss: 0.03090\n",
      "Epoch: 212/300 Iteration: 2119 Training loss: 0.02851\n",
      "Epoch: 211/300 Iteration: 2120 Validation Acc: 0.5951\n",
      "Epoch: 213/300 Iteration: 2120 Training loss: 0.03146\n",
      "Epoch: 213/300 Iteration: 2121 Training loss: 0.02673\n",
      "Epoch: 213/300 Iteration: 2122 Training loss: 0.02817\n",
      "Epoch: 213/300 Iteration: 2123 Training loss: 0.02712\n",
      "Epoch: 213/300 Iteration: 2124 Training loss: 0.03079\n",
      "Epoch: 212/300 Iteration: 2125 Validation Acc: 0.5955\n",
      "Epoch: 213/300 Iteration: 2125 Training loss: 0.02778\n",
      "Epoch: 213/300 Iteration: 2126 Training loss: 0.02310\n",
      "Epoch: 213/300 Iteration: 2127 Training loss: 0.02617\n",
      "Epoch: 213/300 Iteration: 2128 Training loss: 0.03062\n",
      "Epoch: 213/300 Iteration: 2129 Training loss: 0.02815\n",
      "Epoch: 212/300 Iteration: 2130 Validation Acc: 0.5957\n",
      "Epoch: 214/300 Iteration: 2130 Training loss: 0.03122\n",
      "Epoch: 214/300 Iteration: 2131 Training loss: 0.02645\n",
      "Epoch: 214/300 Iteration: 2132 Training loss: 0.02788\n",
      "Epoch: 214/300 Iteration: 2133 Training loss: 0.02675\n",
      "Epoch: 214/300 Iteration: 2134 Training loss: 0.03041\n",
      "Epoch: 213/300 Iteration: 2135 Validation Acc: 0.5951\n",
      "Epoch: 214/300 Iteration: 2135 Training loss: 0.02744\n",
      "Epoch: 214/300 Iteration: 2136 Training loss: 0.02274\n",
      "Epoch: 214/300 Iteration: 2137 Training loss: 0.02590\n",
      "Epoch: 214/300 Iteration: 2138 Training loss: 0.03039\n",
      "Epoch: 214/300 Iteration: 2139 Training loss: 0.02791\n",
      "Epoch: 213/300 Iteration: 2140 Validation Acc: 0.5951\n",
      "Epoch: 215/300 Iteration: 2140 Training loss: 0.03089\n",
      "Epoch: 215/300 Iteration: 2141 Training loss: 0.02617\n",
      "Epoch: 215/300 Iteration: 2142 Training loss: 0.02765\n",
      "Epoch: 215/300 Iteration: 2143 Training loss: 0.02641\n",
      "Epoch: 215/300 Iteration: 2144 Training loss: 0.03010\n",
      "Epoch: 214/300 Iteration: 2145 Validation Acc: 0.5955\n",
      "Epoch: 215/300 Iteration: 2145 Training loss: 0.02720\n",
      "Epoch: 215/300 Iteration: 2146 Training loss: 0.02258\n",
      "Epoch: 215/300 Iteration: 2147 Training loss: 0.02568\n",
      "Epoch: 215/300 Iteration: 2148 Training loss: 0.03018\n",
      "Epoch: 215/300 Iteration: 2149 Training loss: 0.02763\n",
      "Epoch: 214/300 Iteration: 2150 Validation Acc: 0.5951\n",
      "Epoch: 216/300 Iteration: 2150 Training loss: 0.03063\n",
      "Epoch: 216/300 Iteration: 2151 Training loss: 0.02588\n",
      "Epoch: 216/300 Iteration: 2152 Training loss: 0.02742\n",
      "Epoch: 216/300 Iteration: 2153 Training loss: 0.02621\n",
      "Epoch: 216/300 Iteration: 2154 Training loss: 0.02976\n",
      "Epoch: 215/300 Iteration: 2155 Validation Acc: 0.5955\n",
      "Epoch: 216/300 Iteration: 2155 Training loss: 0.02695\n",
      "Epoch: 216/300 Iteration: 2156 Training loss: 0.02238\n",
      "Epoch: 216/300 Iteration: 2157 Training loss: 0.02550\n",
      "Epoch: 216/300 Iteration: 2158 Training loss: 0.02984\n",
      "Epoch: 216/300 Iteration: 2159 Training loss: 0.02745\n",
      "Epoch: 215/300 Iteration: 2160 Validation Acc: 0.5953\n",
      "Epoch: 217/300 Iteration: 2160 Training loss: 0.03037\n",
      "Epoch: 217/300 Iteration: 2161 Training loss: 0.02559\n",
      "Epoch: 217/300 Iteration: 2162 Training loss: 0.02716\n",
      "Epoch: 217/300 Iteration: 2163 Training loss: 0.02589\n",
      "Epoch: 217/300 Iteration: 2164 Training loss: 0.02948\n",
      "Epoch: 216/300 Iteration: 2165 Validation Acc: 0.5961\n",
      "Epoch: 217/300 Iteration: 2165 Training loss: 0.02680\n",
      "Epoch: 217/300 Iteration: 2166 Training loss: 0.02210\n",
      "Epoch: 217/300 Iteration: 2167 Training loss: 0.02529\n",
      "Epoch: 217/300 Iteration: 2168 Training loss: 0.02969\n",
      "Epoch: 217/300 Iteration: 2169 Training loss: 0.02735\n",
      "Epoch: 216/300 Iteration: 2170 Validation Acc: 0.5947\n",
      "Epoch: 218/300 Iteration: 2170 Training loss: 0.03012\n",
      "Epoch: 218/300 Iteration: 2171 Training loss: 0.02525\n",
      "Epoch: 218/300 Iteration: 2172 Training loss: 0.02686\n",
      "Epoch: 218/300 Iteration: 2173 Training loss: 0.02549\n",
      "Epoch: 218/300 Iteration: 2174 Training loss: 0.02929\n",
      "Epoch: 217/300 Iteration: 2175 Validation Acc: 0.5959\n",
      "Epoch: 218/300 Iteration: 2175 Training loss: 0.02666\n",
      "Epoch: 218/300 Iteration: 2176 Training loss: 0.02194\n",
      "Epoch: 218/300 Iteration: 2177 Training loss: 0.02488\n",
      "Epoch: 218/300 Iteration: 2178 Training loss: 0.02918\n",
      "Epoch: 218/300 Iteration: 2179 Training loss: 0.02710\n",
      "Epoch: 217/300 Iteration: 2180 Validation Acc: 0.5953\n",
      "Epoch: 219/300 Iteration: 2180 Training loss: 0.03000\n",
      "Epoch: 219/300 Iteration: 2181 Training loss: 0.02498\n",
      "Epoch: 219/300 Iteration: 2182 Training loss: 0.02659\n",
      "Epoch: 219/300 Iteration: 2183 Training loss: 0.02512\n",
      "Epoch: 219/300 Iteration: 2184 Training loss: 0.02901\n",
      "Epoch: 218/300 Iteration: 2185 Validation Acc: 0.5957\n",
      "Epoch: 219/300 Iteration: 2185 Training loss: 0.02641\n",
      "Epoch: 219/300 Iteration: 2186 Training loss: 0.02179\n",
      "Epoch: 219/300 Iteration: 2187 Training loss: 0.02476\n",
      "Epoch: 219/300 Iteration: 2188 Training loss: 0.02904\n",
      "Epoch: 219/300 Iteration: 2189 Training loss: 0.02661\n",
      "Epoch: 218/300 Iteration: 2190 Validation Acc: 0.5957\n",
      "Epoch: 220/300 Iteration: 2190 Training loss: 0.02964\n",
      "Epoch: 220/300 Iteration: 2191 Training loss: 0.02480\n",
      "Epoch: 220/300 Iteration: 2192 Training loss: 0.02647\n",
      "Epoch: 220/300 Iteration: 2193 Training loss: 0.02488\n",
      "Epoch: 220/300 Iteration: 2194 Training loss: 0.02865\n",
      "Epoch: 219/300 Iteration: 2195 Validation Acc: 0.5955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220/300 Iteration: 2195 Training loss: 0.02599\n",
      "Epoch: 220/300 Iteration: 2196 Training loss: 0.02144\n",
      "Epoch: 220/300 Iteration: 2197 Training loss: 0.02454\n",
      "Epoch: 220/300 Iteration: 2198 Training loss: 0.02894\n",
      "Epoch: 220/300 Iteration: 2199 Training loss: 0.02624\n",
      "Epoch: 219/300 Iteration: 2200 Validation Acc: 0.5951\n",
      "Epoch: 221/300 Iteration: 2200 Training loss: 0.02930\n",
      "Epoch: 221/300 Iteration: 2201 Training loss: 0.02442\n",
      "Epoch: 221/300 Iteration: 2202 Training loss: 0.02621\n",
      "Epoch: 221/300 Iteration: 2203 Training loss: 0.02466\n",
      "Epoch: 221/300 Iteration: 2204 Training loss: 0.02848\n",
      "Epoch: 220/300 Iteration: 2205 Validation Acc: 0.5961\n",
      "Epoch: 221/300 Iteration: 2205 Training loss: 0.02557\n",
      "Epoch: 221/300 Iteration: 2206 Training loss: 0.02104\n",
      "Epoch: 221/300 Iteration: 2207 Training loss: 0.02418\n",
      "Epoch: 221/300 Iteration: 2208 Training loss: 0.02869\n",
      "Epoch: 221/300 Iteration: 2209 Training loss: 0.02600\n",
      "Epoch: 220/300 Iteration: 2210 Validation Acc: 0.5959\n",
      "Epoch: 222/300 Iteration: 2210 Training loss: 0.02920\n",
      "Epoch: 222/300 Iteration: 2211 Training loss: 0.02408\n",
      "Epoch: 222/300 Iteration: 2212 Training loss: 0.02582\n",
      "Epoch: 222/300 Iteration: 2213 Training loss: 0.02435\n",
      "Epoch: 222/300 Iteration: 2214 Training loss: 0.02825\n",
      "Epoch: 221/300 Iteration: 2215 Validation Acc: 0.5959\n",
      "Epoch: 222/300 Iteration: 2215 Training loss: 0.02542\n",
      "Epoch: 222/300 Iteration: 2216 Training loss: 0.02083\n",
      "Epoch: 222/300 Iteration: 2217 Training loss: 0.02386\n",
      "Epoch: 222/300 Iteration: 2218 Training loss: 0.02831\n",
      "Epoch: 222/300 Iteration: 2219 Training loss: 0.02575\n",
      "Epoch: 221/300 Iteration: 2220 Validation Acc: 0.5957\n",
      "Epoch: 223/300 Iteration: 2220 Training loss: 0.02894\n",
      "Epoch: 223/300 Iteration: 2221 Training loss: 0.02393\n",
      "Epoch: 223/300 Iteration: 2222 Training loss: 0.02557\n",
      "Epoch: 223/300 Iteration: 2223 Training loss: 0.02400\n",
      "Epoch: 223/300 Iteration: 2224 Training loss: 0.02782\n",
      "Epoch: 222/300 Iteration: 2225 Validation Acc: 0.5957\n",
      "Epoch: 223/300 Iteration: 2225 Training loss: 0.02520\n",
      "Epoch: 223/300 Iteration: 2226 Training loss: 0.02073\n",
      "Epoch: 223/300 Iteration: 2227 Training loss: 0.02372\n",
      "Epoch: 223/300 Iteration: 2228 Training loss: 0.02807\n",
      "Epoch: 223/300 Iteration: 2229 Training loss: 0.02541\n",
      "Epoch: 222/300 Iteration: 2230 Validation Acc: 0.5957\n",
      "Epoch: 224/300 Iteration: 2230 Training loss: 0.02866\n",
      "Epoch: 224/300 Iteration: 2231 Training loss: 0.02373\n",
      "Epoch: 224/300 Iteration: 2232 Training loss: 0.02543\n",
      "Epoch: 224/300 Iteration: 2233 Training loss: 0.02381\n",
      "Epoch: 224/300 Iteration: 2234 Training loss: 0.02753\n",
      "Epoch: 223/300 Iteration: 2235 Validation Acc: 0.5953\n",
      "Epoch: 224/300 Iteration: 2235 Training loss: 0.02499\n",
      "Epoch: 224/300 Iteration: 2236 Training loss: 0.02049\n",
      "Epoch: 224/300 Iteration: 2237 Training loss: 0.02366\n",
      "Epoch: 224/300 Iteration: 2238 Training loss: 0.02780\n",
      "Epoch: 224/300 Iteration: 2239 Training loss: 0.02527\n",
      "Epoch: 223/300 Iteration: 2240 Validation Acc: 0.5957\n",
      "Epoch: 225/300 Iteration: 2240 Training loss: 0.02838\n",
      "Epoch: 225/300 Iteration: 2241 Training loss: 0.02354\n",
      "Epoch: 225/300 Iteration: 2242 Training loss: 0.02519\n",
      "Epoch: 225/300 Iteration: 2243 Training loss: 0.02355\n",
      "Epoch: 225/300 Iteration: 2244 Training loss: 0.02727\n",
      "Epoch: 224/300 Iteration: 2245 Validation Acc: 0.5949\n",
      "Epoch: 225/300 Iteration: 2245 Training loss: 0.02478\n",
      "Epoch: 225/300 Iteration: 2246 Training loss: 0.02033\n",
      "Epoch: 225/300 Iteration: 2247 Training loss: 0.02338\n",
      "Epoch: 225/300 Iteration: 2248 Training loss: 0.02759\n",
      "Epoch: 225/300 Iteration: 2249 Training loss: 0.02517\n",
      "Epoch: 224/300 Iteration: 2250 Validation Acc: 0.5955\n",
      "Epoch: 226/300 Iteration: 2250 Training loss: 0.02807\n",
      "Epoch: 226/300 Iteration: 2251 Training loss: 0.02305\n",
      "Epoch: 226/300 Iteration: 2252 Training loss: 0.02492\n",
      "Epoch: 226/300 Iteration: 2253 Training loss: 0.02334\n",
      "Epoch: 226/300 Iteration: 2254 Training loss: 0.02703\n",
      "Epoch: 225/300 Iteration: 2255 Validation Acc: 0.5959\n",
      "Epoch: 226/300 Iteration: 2255 Training loss: 0.02453\n",
      "Epoch: 226/300 Iteration: 2256 Training loss: 0.02005\n",
      "Epoch: 226/300 Iteration: 2257 Training loss: 0.02301\n",
      "Epoch: 226/300 Iteration: 2258 Training loss: 0.02738\n",
      "Epoch: 226/300 Iteration: 2259 Training loss: 0.02490\n",
      "Epoch: 225/300 Iteration: 2260 Validation Acc: 0.5955\n",
      "Epoch: 227/300 Iteration: 2260 Training loss: 0.02798\n",
      "Epoch: 227/300 Iteration: 2261 Training loss: 0.02280\n",
      "Epoch: 227/300 Iteration: 2262 Training loss: 0.02476\n",
      "Epoch: 227/300 Iteration: 2263 Training loss: 0.02300\n",
      "Epoch: 227/300 Iteration: 2264 Training loss: 0.02681\n",
      "Epoch: 226/300 Iteration: 2265 Validation Acc: 0.5963\n",
      "Epoch: 227/300 Iteration: 2265 Training loss: 0.02438\n",
      "Epoch: 227/300 Iteration: 2266 Training loss: 0.01983\n",
      "Epoch: 227/300 Iteration: 2267 Training loss: 0.02283\n",
      "Epoch: 227/300 Iteration: 2268 Training loss: 0.02723\n",
      "Epoch: 227/300 Iteration: 2269 Training loss: 0.02460\n",
      "Epoch: 226/300 Iteration: 2270 Validation Acc: 0.5959\n",
      "Epoch: 228/300 Iteration: 2270 Training loss: 0.02772\n",
      "Epoch: 228/300 Iteration: 2271 Training loss: 0.02262\n",
      "Epoch: 228/300 Iteration: 2272 Training loss: 0.02453\n",
      "Epoch: 228/300 Iteration: 2273 Training loss: 0.02280\n",
      "Epoch: 228/300 Iteration: 2274 Training loss: 0.02653\n",
      "Epoch: 227/300 Iteration: 2275 Validation Acc: 0.5970\n",
      "Epoch: 228/300 Iteration: 2275 Training loss: 0.02404\n",
      "Epoch: 228/300 Iteration: 2276 Training loss: 0.01960\n",
      "Epoch: 228/300 Iteration: 2277 Training loss: 0.02260\n",
      "Epoch: 228/300 Iteration: 2278 Training loss: 0.02697\n",
      "Epoch: 228/300 Iteration: 2279 Training loss: 0.02442\n",
      "Epoch: 227/300 Iteration: 2280 Validation Acc: 0.5961\n",
      "Epoch: 229/300 Iteration: 2280 Training loss: 0.02747\n",
      "Epoch: 229/300 Iteration: 2281 Training loss: 0.02235\n",
      "Epoch: 229/300 Iteration: 2282 Training loss: 0.02421\n",
      "Epoch: 229/300 Iteration: 2283 Training loss: 0.02249\n",
      "Epoch: 229/300 Iteration: 2284 Training loss: 0.02631\n",
      "Epoch: 228/300 Iteration: 2285 Validation Acc: 0.5953\n",
      "Epoch: 229/300 Iteration: 2285 Training loss: 0.02397\n",
      "Epoch: 229/300 Iteration: 2286 Training loss: 0.01953\n",
      "Epoch: 229/300 Iteration: 2287 Training loss: 0.02239\n",
      "Epoch: 229/300 Iteration: 2288 Training loss: 0.02665\n",
      "Epoch: 229/300 Iteration: 2289 Training loss: 0.02409\n",
      "Epoch: 228/300 Iteration: 2290 Validation Acc: 0.5961\n",
      "Epoch: 230/300 Iteration: 2290 Training loss: 0.02722\n",
      "Epoch: 230/300 Iteration: 2291 Training loss: 0.02214\n",
      "Epoch: 230/300 Iteration: 2292 Training loss: 0.02399\n",
      "Epoch: 230/300 Iteration: 2293 Training loss: 0.02219\n",
      "Epoch: 230/300 Iteration: 2294 Training loss: 0.02595\n",
      "Epoch: 229/300 Iteration: 2295 Validation Acc: 0.5957\n",
      "Epoch: 230/300 Iteration: 2295 Training loss: 0.02372\n",
      "Epoch: 230/300 Iteration: 2296 Training loss: 0.01936\n",
      "Epoch: 230/300 Iteration: 2297 Training loss: 0.02225\n",
      "Epoch: 230/300 Iteration: 2298 Training loss: 0.02633\n",
      "Epoch: 230/300 Iteration: 2299 Training loss: 0.02382\n",
      "Epoch: 229/300 Iteration: 2300 Validation Acc: 0.5959\n",
      "Epoch: 231/300 Iteration: 2300 Training loss: 0.02690\n",
      "Epoch: 231/300 Iteration: 2301 Training loss: 0.02188\n",
      "Epoch: 231/300 Iteration: 2302 Training loss: 0.02381\n",
      "Epoch: 231/300 Iteration: 2303 Training loss: 0.02204\n",
      "Epoch: 231/300 Iteration: 2304 Training loss: 0.02571\n",
      "Epoch: 230/300 Iteration: 2305 Validation Acc: 0.5955\n",
      "Epoch: 231/300 Iteration: 2305 Training loss: 0.02346\n",
      "Epoch: 231/300 Iteration: 2306 Training loss: 0.01910\n",
      "Epoch: 231/300 Iteration: 2307 Training loss: 0.02205\n",
      "Epoch: 231/300 Iteration: 2308 Training loss: 0.02620\n",
      "Epoch: 231/300 Iteration: 2309 Training loss: 0.02363\n",
      "Epoch: 230/300 Iteration: 2310 Validation Acc: 0.5961\n",
      "Epoch: 232/300 Iteration: 2310 Training loss: 0.02664\n",
      "Epoch: 232/300 Iteration: 2311 Training loss: 0.02153\n",
      "Epoch: 232/300 Iteration: 2312 Training loss: 0.02360\n",
      "Epoch: 232/300 Iteration: 2313 Training loss: 0.02192\n",
      "Epoch: 232/300 Iteration: 2314 Training loss: 0.02558\n",
      "Epoch: 231/300 Iteration: 2315 Validation Acc: 0.5953\n",
      "Epoch: 232/300 Iteration: 2315 Training loss: 0.02322\n",
      "Epoch: 232/300 Iteration: 2316 Training loss: 0.01890\n",
      "Epoch: 232/300 Iteration: 2317 Training loss: 0.02185\n",
      "Epoch: 232/300 Iteration: 2318 Training loss: 0.02598\n",
      "Epoch: 232/300 Iteration: 2319 Training loss: 0.02335\n",
      "Epoch: 231/300 Iteration: 2320 Validation Acc: 0.5963\n",
      "Epoch: 233/300 Iteration: 2320 Training loss: 0.02641\n",
      "Epoch: 233/300 Iteration: 2321 Training loss: 0.02134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 233/300 Iteration: 2322 Training loss: 0.02332\n",
      "Epoch: 233/300 Iteration: 2323 Training loss: 0.02174\n",
      "Epoch: 233/300 Iteration: 2324 Training loss: 0.02540\n",
      "Epoch: 232/300 Iteration: 2325 Validation Acc: 0.5951\n",
      "Epoch: 233/300 Iteration: 2325 Training loss: 0.02297\n",
      "Epoch: 233/300 Iteration: 2326 Training loss: 0.01873\n",
      "Epoch: 233/300 Iteration: 2327 Training loss: 0.02163\n",
      "Epoch: 233/300 Iteration: 2328 Training loss: 0.02579\n",
      "Epoch: 233/300 Iteration: 2329 Training loss: 0.02312\n",
      "Epoch: 232/300 Iteration: 2330 Validation Acc: 0.5961\n",
      "Epoch: 234/300 Iteration: 2330 Training loss: 0.02621\n",
      "Epoch: 234/300 Iteration: 2331 Training loss: 0.02114\n",
      "Epoch: 234/300 Iteration: 2332 Training loss: 0.02309\n",
      "Epoch: 234/300 Iteration: 2333 Training loss: 0.02140\n",
      "Epoch: 234/300 Iteration: 2334 Training loss: 0.02513\n",
      "Epoch: 233/300 Iteration: 2335 Validation Acc: 0.5955\n",
      "Epoch: 234/300 Iteration: 2335 Training loss: 0.02274\n",
      "Epoch: 234/300 Iteration: 2336 Training loss: 0.01848\n",
      "Epoch: 234/300 Iteration: 2337 Training loss: 0.02139\n",
      "Epoch: 234/300 Iteration: 2338 Training loss: 0.02557\n",
      "Epoch: 234/300 Iteration: 2339 Training loss: 0.02292\n",
      "Epoch: 233/300 Iteration: 2340 Validation Acc: 0.5957\n",
      "Epoch: 235/300 Iteration: 2340 Training loss: 0.02588\n",
      "Epoch: 235/300 Iteration: 2341 Training loss: 0.02093\n",
      "Epoch: 235/300 Iteration: 2342 Training loss: 0.02293\n",
      "Epoch: 235/300 Iteration: 2343 Training loss: 0.02118\n",
      "Epoch: 235/300 Iteration: 2344 Training loss: 0.02445\n",
      "Epoch: 234/300 Iteration: 2345 Validation Acc: 0.5963\n",
      "Epoch: 235/300 Iteration: 2345 Training loss: 0.02263\n",
      "Epoch: 235/300 Iteration: 2346 Training loss: 0.01832\n",
      "Epoch: 235/300 Iteration: 2347 Training loss: 0.02092\n",
      "Epoch: 235/300 Iteration: 2348 Training loss: 0.02506\n",
      "Epoch: 235/300 Iteration: 2349 Training loss: 0.02277\n",
      "Epoch: 234/300 Iteration: 2350 Validation Acc: 0.5957\n",
      "Epoch: 236/300 Iteration: 2350 Training loss: 0.02548\n",
      "Epoch: 236/300 Iteration: 2351 Training loss: 0.02068\n",
      "Epoch: 236/300 Iteration: 2352 Training loss: 0.02268\n",
      "Epoch: 236/300 Iteration: 2353 Training loss: 0.02100\n",
      "Epoch: 236/300 Iteration: 2354 Training loss: 0.02381\n",
      "Epoch: 235/300 Iteration: 2355 Validation Acc: 0.5959\n",
      "Epoch: 236/300 Iteration: 2355 Training loss: 0.02243\n",
      "Epoch: 236/300 Iteration: 2356 Training loss: 0.01818\n",
      "Epoch: 236/300 Iteration: 2357 Training loss: 0.02061\n",
      "Epoch: 236/300 Iteration: 2358 Training loss: 0.02474\n",
      "Epoch: 236/300 Iteration: 2359 Training loss: 0.02262\n",
      "Epoch: 235/300 Iteration: 2360 Validation Acc: 0.5957\n",
      "Epoch: 237/300 Iteration: 2360 Training loss: 0.02522\n",
      "Epoch: 237/300 Iteration: 2361 Training loss: 0.02049\n",
      "Epoch: 237/300 Iteration: 2362 Training loss: 0.02254\n",
      "Epoch: 237/300 Iteration: 2363 Training loss: 0.02089\n",
      "Epoch: 237/300 Iteration: 2364 Training loss: 0.02352\n",
      "Epoch: 236/300 Iteration: 2365 Validation Acc: 0.5953\n",
      "Epoch: 237/300 Iteration: 2365 Training loss: 0.02228\n",
      "Epoch: 237/300 Iteration: 2366 Training loss: 0.01806\n",
      "Epoch: 237/300 Iteration: 2367 Training loss: 0.02050\n",
      "Epoch: 237/300 Iteration: 2368 Training loss: 0.02448\n",
      "Epoch: 237/300 Iteration: 2369 Training loss: 0.02246\n",
      "Epoch: 236/300 Iteration: 2370 Validation Acc: 0.5955\n",
      "Epoch: 238/300 Iteration: 2370 Training loss: 0.02502\n",
      "Epoch: 238/300 Iteration: 2371 Training loss: 0.02025\n",
      "Epoch: 238/300 Iteration: 2372 Training loss: 0.02235\n",
      "Epoch: 238/300 Iteration: 2373 Training loss: 0.02067\n",
      "Epoch: 238/300 Iteration: 2374 Training loss: 0.02334\n",
      "Epoch: 237/300 Iteration: 2375 Validation Acc: 0.5951\n",
      "Epoch: 238/300 Iteration: 2375 Training loss: 0.02228\n",
      "Epoch: 238/300 Iteration: 2376 Training loss: 0.01792\n",
      "Epoch: 238/300 Iteration: 2377 Training loss: 0.02026\n",
      "Epoch: 238/300 Iteration: 2378 Training loss: 0.02423\n",
      "Epoch: 238/300 Iteration: 2379 Training loss: 0.02239\n",
      "Epoch: 237/300 Iteration: 2380 Validation Acc: 0.5957\n",
      "Epoch: 239/300 Iteration: 2380 Training loss: 0.02471\n",
      "Epoch: 239/300 Iteration: 2381 Training loss: 0.02008\n",
      "Epoch: 239/300 Iteration: 2382 Training loss: 0.02213\n",
      "Epoch: 239/300 Iteration: 2383 Training loss: 0.02045\n",
      "Epoch: 239/300 Iteration: 2384 Training loss: 0.02308\n",
      "Epoch: 238/300 Iteration: 2385 Validation Acc: 0.5959\n",
      "Epoch: 239/300 Iteration: 2385 Training loss: 0.02194\n",
      "Epoch: 239/300 Iteration: 2386 Training loss: 0.01773\n",
      "Epoch: 239/300 Iteration: 2387 Training loss: 0.02006\n",
      "Epoch: 239/300 Iteration: 2388 Training loss: 0.02400\n",
      "Epoch: 239/300 Iteration: 2389 Training loss: 0.02230\n",
      "Epoch: 238/300 Iteration: 2390 Validation Acc: 0.5955\n",
      "Epoch: 240/300 Iteration: 2390 Training loss: 0.02484\n",
      "Epoch: 240/300 Iteration: 2391 Training loss: 0.01989\n",
      "Epoch: 240/300 Iteration: 2392 Training loss: 0.02202\n",
      "Epoch: 240/300 Iteration: 2393 Training loss: 0.02013\n",
      "Epoch: 240/300 Iteration: 2394 Training loss: 0.02296\n",
      "Epoch: 239/300 Iteration: 2395 Validation Acc: 0.5963\n",
      "Epoch: 240/300 Iteration: 2395 Training loss: 0.02167\n",
      "Epoch: 240/300 Iteration: 2396 Training loss: 0.01766\n",
      "Epoch: 240/300 Iteration: 2397 Training loss: 0.01987\n",
      "Epoch: 240/300 Iteration: 2398 Training loss: 0.02369\n",
      "Epoch: 240/300 Iteration: 2399 Training loss: 0.02189\n",
      "Epoch: 239/300 Iteration: 2400 Validation Acc: 0.5959\n",
      "Epoch: 241/300 Iteration: 2400 Training loss: 0.02438\n",
      "Epoch: 241/300 Iteration: 2401 Training loss: 0.01972\n",
      "Epoch: 241/300 Iteration: 2402 Training loss: 0.02185\n",
      "Epoch: 241/300 Iteration: 2403 Training loss: 0.01997\n",
      "Epoch: 241/300 Iteration: 2404 Training loss: 0.02274\n",
      "Epoch: 240/300 Iteration: 2405 Validation Acc: 0.5955\n",
      "Epoch: 241/300 Iteration: 2405 Training loss: 0.02138\n",
      "Epoch: 241/300 Iteration: 2406 Training loss: 0.01746\n",
      "Epoch: 241/300 Iteration: 2407 Training loss: 0.01974\n",
      "Epoch: 241/300 Iteration: 2408 Training loss: 0.02371\n",
      "Epoch: 241/300 Iteration: 2409 Training loss: 0.02172\n",
      "Epoch: 240/300 Iteration: 2410 Validation Acc: 0.5959\n",
      "Epoch: 242/300 Iteration: 2410 Training loss: 0.02426\n",
      "Epoch: 242/300 Iteration: 2411 Training loss: 0.01948\n",
      "Epoch: 242/300 Iteration: 2412 Training loss: 0.02165\n",
      "Epoch: 242/300 Iteration: 2413 Training loss: 0.01981\n",
      "Epoch: 242/300 Iteration: 2414 Training loss: 0.02251\n",
      "Epoch: 241/300 Iteration: 2415 Validation Acc: 0.5957\n",
      "Epoch: 242/300 Iteration: 2415 Training loss: 0.02124\n",
      "Epoch: 242/300 Iteration: 2416 Training loss: 0.01724\n",
      "Epoch: 242/300 Iteration: 2417 Training loss: 0.01948\n",
      "Epoch: 242/300 Iteration: 2418 Training loss: 0.02335\n",
      "Epoch: 242/300 Iteration: 2419 Training loss: 0.02150\n",
      "Epoch: 241/300 Iteration: 2420 Validation Acc: 0.5957\n",
      "Epoch: 243/300 Iteration: 2420 Training loss: 0.02398\n",
      "Epoch: 243/300 Iteration: 2421 Training loss: 0.01928\n",
      "Epoch: 243/300 Iteration: 2422 Training loss: 0.02145\n",
      "Epoch: 243/300 Iteration: 2423 Training loss: 0.01957\n",
      "Epoch: 243/300 Iteration: 2424 Training loss: 0.02230\n",
      "Epoch: 242/300 Iteration: 2425 Validation Acc: 0.5961\n",
      "Epoch: 243/300 Iteration: 2425 Training loss: 0.02103\n",
      "Epoch: 243/300 Iteration: 2426 Training loss: 0.01704\n",
      "Epoch: 243/300 Iteration: 2427 Training loss: 0.01927\n",
      "Epoch: 243/300 Iteration: 2428 Training loss: 0.02307\n",
      "Epoch: 243/300 Iteration: 2429 Training loss: 0.02135\n",
      "Epoch: 242/300 Iteration: 2430 Validation Acc: 0.5970\n",
      "Epoch: 244/300 Iteration: 2430 Training loss: 0.02388\n",
      "Epoch: 244/300 Iteration: 2431 Training loss: 0.01917\n",
      "Epoch: 244/300 Iteration: 2432 Training loss: 0.02121\n",
      "Epoch: 244/300 Iteration: 2433 Training loss: 0.01926\n",
      "Epoch: 244/300 Iteration: 2434 Training loss: 0.02207\n",
      "Epoch: 243/300 Iteration: 2435 Validation Acc: 0.5963\n",
      "Epoch: 244/300 Iteration: 2435 Training loss: 0.02076\n",
      "Epoch: 244/300 Iteration: 2436 Training loss: 0.01689\n",
      "Epoch: 244/300 Iteration: 2437 Training loss: 0.01910\n",
      "Epoch: 244/300 Iteration: 2438 Training loss: 0.02280\n",
      "Epoch: 244/300 Iteration: 2439 Training loss: 0.02112\n",
      "Epoch: 243/300 Iteration: 2440 Validation Acc: 0.5961\n",
      "Epoch: 245/300 Iteration: 2440 Training loss: 0.02366\n",
      "Epoch: 245/300 Iteration: 2441 Training loss: 0.01898\n",
      "Epoch: 245/300 Iteration: 2442 Training loss: 0.02096\n",
      "Epoch: 245/300 Iteration: 2443 Training loss: 0.01902\n",
      "Epoch: 245/300 Iteration: 2444 Training loss: 0.02179\n",
      "Epoch: 244/300 Iteration: 2445 Validation Acc: 0.5957\n",
      "Epoch: 245/300 Iteration: 2445 Training loss: 0.02052\n",
      "Epoch: 245/300 Iteration: 2446 Training loss: 0.01678\n",
      "Epoch: 245/300 Iteration: 2447 Training loss: 0.01901\n",
      "Epoch: 245/300 Iteration: 2448 Training loss: 0.02259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 245/300 Iteration: 2449 Training loss: 0.02096\n",
      "Epoch: 244/300 Iteration: 2450 Validation Acc: 0.5963\n",
      "Epoch: 246/300 Iteration: 2450 Training loss: 0.02329\n",
      "Epoch: 246/300 Iteration: 2451 Training loss: 0.01882\n",
      "Epoch: 246/300 Iteration: 2452 Training loss: 0.02082\n",
      "Epoch: 246/300 Iteration: 2453 Training loss: 0.01887\n",
      "Epoch: 246/300 Iteration: 2454 Training loss: 0.02149\n",
      "Epoch: 245/300 Iteration: 2455 Validation Acc: 0.5961\n",
      "Epoch: 246/300 Iteration: 2455 Training loss: 0.02018\n",
      "Epoch: 246/300 Iteration: 2456 Training loss: 0.01655\n",
      "Epoch: 246/300 Iteration: 2457 Training loss: 0.01884\n",
      "Epoch: 246/300 Iteration: 2458 Training loss: 0.02258\n",
      "Epoch: 246/300 Iteration: 2459 Training loss: 0.02096\n",
      "Epoch: 245/300 Iteration: 2460 Validation Acc: 0.5957\n",
      "Epoch: 247/300 Iteration: 2460 Training loss: 0.02304\n",
      "Epoch: 247/300 Iteration: 2461 Training loss: 0.01853\n",
      "Epoch: 247/300 Iteration: 2462 Training loss: 0.02070\n",
      "Epoch: 247/300 Iteration: 2463 Training loss: 0.01876\n",
      "Epoch: 247/300 Iteration: 2464 Training loss: 0.02137\n",
      "Epoch: 246/300 Iteration: 2465 Validation Acc: 0.5959\n",
      "Epoch: 247/300 Iteration: 2465 Training loss: 0.01996\n",
      "Epoch: 247/300 Iteration: 2466 Training loss: 0.01642\n",
      "Epoch: 247/300 Iteration: 2467 Training loss: 0.01866\n",
      "Epoch: 247/300 Iteration: 2468 Training loss: 0.02235\n",
      "Epoch: 247/300 Iteration: 2469 Training loss: 0.02084\n",
      "Epoch: 246/300 Iteration: 2470 Validation Acc: 0.5961\n",
      "Epoch: 248/300 Iteration: 2470 Training loss: 0.02292\n",
      "Epoch: 248/300 Iteration: 2471 Training loss: 0.01834\n",
      "Epoch: 248/300 Iteration: 2472 Training loss: 0.02041\n",
      "Epoch: 248/300 Iteration: 2473 Training loss: 0.01854\n",
      "Epoch: 248/300 Iteration: 2474 Training loss: 0.02115\n",
      "Epoch: 247/300 Iteration: 2475 Validation Acc: 0.5965\n",
      "Epoch: 248/300 Iteration: 2475 Training loss: 0.01990\n",
      "Epoch: 248/300 Iteration: 2476 Training loss: 0.01628\n",
      "Epoch: 248/300 Iteration: 2477 Training loss: 0.01839\n",
      "Epoch: 248/300 Iteration: 2478 Training loss: 0.02212\n",
      "Epoch: 248/300 Iteration: 2479 Training loss: 0.02067\n",
      "Epoch: 247/300 Iteration: 2480 Validation Acc: 0.5957\n",
      "Epoch: 249/300 Iteration: 2480 Training loss: 0.02281\n",
      "Epoch: 249/300 Iteration: 2481 Training loss: 0.01819\n",
      "Epoch: 249/300 Iteration: 2482 Training loss: 0.02026\n",
      "Epoch: 249/300 Iteration: 2483 Training loss: 0.01833\n",
      "Epoch: 249/300 Iteration: 2484 Training loss: 0.02088\n",
      "Epoch: 248/300 Iteration: 2485 Validation Acc: 0.5963\n",
      "Epoch: 249/300 Iteration: 2485 Training loss: 0.01967\n",
      "Epoch: 249/300 Iteration: 2486 Training loss: 0.01614\n",
      "Epoch: 249/300 Iteration: 2487 Training loss: 0.01824\n",
      "Epoch: 249/300 Iteration: 2488 Training loss: 0.02188\n",
      "Epoch: 249/300 Iteration: 2489 Training loss: 0.02042\n",
      "Epoch: 248/300 Iteration: 2490 Validation Acc: 0.5957\n",
      "Epoch: 250/300 Iteration: 2490 Training loss: 0.02265\n",
      "Epoch: 250/300 Iteration: 2491 Training loss: 0.01803\n",
      "Epoch: 250/300 Iteration: 2492 Training loss: 0.02004\n",
      "Epoch: 250/300 Iteration: 2493 Training loss: 0.01816\n",
      "Epoch: 250/300 Iteration: 2494 Training loss: 0.02068\n",
      "Epoch: 249/300 Iteration: 2495 Validation Acc: 0.5959\n",
      "Epoch: 250/300 Iteration: 2495 Training loss: 0.01948\n",
      "Epoch: 250/300 Iteration: 2496 Training loss: 0.01603\n",
      "Epoch: 250/300 Iteration: 2497 Training loss: 0.01810\n",
      "Epoch: 250/300 Iteration: 2498 Training loss: 0.02170\n",
      "Epoch: 250/300 Iteration: 2499 Training loss: 0.02010\n",
      "Epoch: 249/300 Iteration: 2500 Validation Acc: 0.5965\n",
      "Epoch: 251/300 Iteration: 2500 Training loss: 0.02243\n",
      "Epoch: 251/300 Iteration: 2501 Training loss: 0.01790\n",
      "Epoch: 251/300 Iteration: 2502 Training loss: 0.01995\n",
      "Epoch: 251/300 Iteration: 2503 Training loss: 0.01800\n",
      "Epoch: 251/300 Iteration: 2504 Training loss: 0.02042\n",
      "Epoch: 250/300 Iteration: 2505 Validation Acc: 0.5957\n",
      "Epoch: 251/300 Iteration: 2505 Training loss: 0.01917\n",
      "Epoch: 251/300 Iteration: 2506 Training loss: 0.01587\n",
      "Epoch: 251/300 Iteration: 2507 Training loss: 0.01803\n",
      "Epoch: 251/300 Iteration: 2508 Training loss: 0.02158\n",
      "Epoch: 251/300 Iteration: 2509 Training loss: 0.01992\n",
      "Epoch: 250/300 Iteration: 2510 Validation Acc: 0.5963\n",
      "Epoch: 252/300 Iteration: 2510 Training loss: 0.02220\n",
      "Epoch: 252/300 Iteration: 2511 Training loss: 0.01769\n",
      "Epoch: 252/300 Iteration: 2512 Training loss: 0.01979\n",
      "Epoch: 252/300 Iteration: 2513 Training loss: 0.01790\n",
      "Epoch: 252/300 Iteration: 2514 Training loss: 0.02029\n",
      "Epoch: 251/300 Iteration: 2515 Validation Acc: 0.5961\n",
      "Epoch: 252/300 Iteration: 2515 Training loss: 0.01896\n",
      "Epoch: 252/300 Iteration: 2516 Training loss: 0.01572\n",
      "Epoch: 252/300 Iteration: 2517 Training loss: 0.01787\n",
      "Epoch: 252/300 Iteration: 2518 Training loss: 0.02141\n",
      "Epoch: 252/300 Iteration: 2519 Training loss: 0.01977\n",
      "Epoch: 251/300 Iteration: 2520 Validation Acc: 0.5963\n",
      "Epoch: 253/300 Iteration: 2520 Training loss: 0.02197\n",
      "Epoch: 253/300 Iteration: 2521 Training loss: 0.01748\n",
      "Epoch: 253/300 Iteration: 2522 Training loss: 0.01962\n",
      "Epoch: 253/300 Iteration: 2523 Training loss: 0.01777\n",
      "Epoch: 253/300 Iteration: 2524 Training loss: 0.02009\n",
      "Epoch: 252/300 Iteration: 2525 Validation Acc: 0.5959\n",
      "Epoch: 253/300 Iteration: 2525 Training loss: 0.01879\n",
      "Epoch: 253/300 Iteration: 2526 Training loss: 0.01557\n",
      "Epoch: 253/300 Iteration: 2527 Training loss: 0.01767\n",
      "Epoch: 253/300 Iteration: 2528 Training loss: 0.02128\n",
      "Epoch: 253/300 Iteration: 2529 Training loss: 0.01961\n",
      "Epoch: 252/300 Iteration: 2530 Validation Acc: 0.5955\n",
      "Epoch: 254/300 Iteration: 2530 Training loss: 0.02183\n",
      "Epoch: 254/300 Iteration: 2531 Training loss: 0.01731\n",
      "Epoch: 254/300 Iteration: 2532 Training loss: 0.01944\n",
      "Epoch: 254/300 Iteration: 2533 Training loss: 0.01757\n",
      "Epoch: 254/300 Iteration: 2534 Training loss: 0.01994\n",
      "Epoch: 253/300 Iteration: 2535 Validation Acc: 0.5961\n",
      "Epoch: 254/300 Iteration: 2535 Training loss: 0.01862\n",
      "Epoch: 254/300 Iteration: 2536 Training loss: 0.01537\n",
      "Epoch: 254/300 Iteration: 2537 Training loss: 0.01744\n",
      "Epoch: 254/300 Iteration: 2538 Training loss: 0.02109\n",
      "Epoch: 254/300 Iteration: 2539 Training loss: 0.01946\n",
      "Epoch: 253/300 Iteration: 2540 Validation Acc: 0.5957\n",
      "Epoch: 255/300 Iteration: 2540 Training loss: 0.02167\n",
      "Epoch: 255/300 Iteration: 2541 Training loss: 0.01724\n",
      "Epoch: 255/300 Iteration: 2542 Training loss: 0.01921\n",
      "Epoch: 255/300 Iteration: 2543 Training loss: 0.01732\n",
      "Epoch: 255/300 Iteration: 2544 Training loss: 0.01967\n",
      "Epoch: 254/300 Iteration: 2545 Validation Acc: 0.5963\n",
      "Epoch: 255/300 Iteration: 2545 Training loss: 0.01850\n",
      "Epoch: 255/300 Iteration: 2546 Training loss: 0.01526\n",
      "Epoch: 255/300 Iteration: 2547 Training loss: 0.01732\n",
      "Epoch: 255/300 Iteration: 2548 Training loss: 0.02092\n",
      "Epoch: 255/300 Iteration: 2549 Training loss: 0.01927\n",
      "Epoch: 254/300 Iteration: 2550 Validation Acc: 0.5965\n",
      "Epoch: 256/300 Iteration: 2550 Training loss: 0.02144\n",
      "Epoch: 256/300 Iteration: 2551 Training loss: 0.01710\n",
      "Epoch: 256/300 Iteration: 2552 Training loss: 0.01912\n",
      "Epoch: 256/300 Iteration: 2553 Training loss: 0.01723\n",
      "Epoch: 256/300 Iteration: 2554 Training loss: 0.01946\n",
      "Epoch: 255/300 Iteration: 2555 Validation Acc: 0.5963\n",
      "Epoch: 256/300 Iteration: 2555 Training loss: 0.01827\n",
      "Epoch: 256/300 Iteration: 2556 Training loss: 0.01510\n",
      "Epoch: 256/300 Iteration: 2557 Training loss: 0.01724\n",
      "Epoch: 256/300 Iteration: 2558 Training loss: 0.02086\n",
      "Epoch: 256/300 Iteration: 2559 Training loss: 0.01923\n",
      "Epoch: 255/300 Iteration: 2560 Validation Acc: 0.5965\n",
      "Epoch: 257/300 Iteration: 2560 Training loss: 0.02127\n",
      "Epoch: 257/300 Iteration: 2561 Training loss: 0.01685\n",
      "Epoch: 257/300 Iteration: 2562 Training loss: 0.01895\n",
      "Epoch: 257/300 Iteration: 2563 Training loss: 0.01711\n",
      "Epoch: 257/300 Iteration: 2564 Training loss: 0.01937\n",
      "Epoch: 256/300 Iteration: 2565 Validation Acc: 0.5965\n",
      "Epoch: 257/300 Iteration: 2565 Training loss: 0.01822\n",
      "Epoch: 257/300 Iteration: 2566 Training loss: 0.01502\n",
      "Epoch: 257/300 Iteration: 2567 Training loss: 0.01706\n",
      "Epoch: 257/300 Iteration: 2568 Training loss: 0.02064\n",
      "Epoch: 257/300 Iteration: 2569 Training loss: 0.01912\n",
      "Epoch: 256/300 Iteration: 2570 Validation Acc: 0.5965\n",
      "Epoch: 258/300 Iteration: 2570 Training loss: 0.02122\n",
      "Epoch: 258/300 Iteration: 2571 Training loss: 0.01675\n",
      "Epoch: 258/300 Iteration: 2572 Training loss: 0.01881\n",
      "Epoch: 258/300 Iteration: 2573 Training loss: 0.01688\n",
      "Epoch: 258/300 Iteration: 2574 Training loss: 0.01915\n",
      "Epoch: 257/300 Iteration: 2575 Validation Acc: 0.5961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258/300 Iteration: 2575 Training loss: 0.01812\n",
      "Epoch: 258/300 Iteration: 2576 Training loss: 0.01497\n",
      "Epoch: 258/300 Iteration: 2577 Training loss: 0.01692\n",
      "Epoch: 258/300 Iteration: 2578 Training loss: 0.02046\n",
      "Epoch: 258/300 Iteration: 2579 Training loss: 0.01894\n",
      "Epoch: 257/300 Iteration: 2580 Validation Acc: 0.5959\n",
      "Epoch: 259/300 Iteration: 2580 Training loss: 0.02097\n",
      "Epoch: 259/300 Iteration: 2581 Training loss: 0.01657\n",
      "Epoch: 259/300 Iteration: 2582 Training loss: 0.01873\n",
      "Epoch: 259/300 Iteration: 2583 Training loss: 0.01676\n",
      "Epoch: 259/300 Iteration: 2584 Training loss: 0.01904\n",
      "Epoch: 258/300 Iteration: 2585 Validation Acc: 0.5965\n",
      "Epoch: 259/300 Iteration: 2585 Training loss: 0.01787\n",
      "Epoch: 259/300 Iteration: 2586 Training loss: 0.01475\n",
      "Epoch: 259/300 Iteration: 2587 Training loss: 0.01678\n",
      "Epoch: 259/300 Iteration: 2588 Training loss: 0.02036\n",
      "Epoch: 259/300 Iteration: 2589 Training loss: 0.01873\n",
      "Epoch: 258/300 Iteration: 2590 Validation Acc: 0.5959\n",
      "Epoch: 260/300 Iteration: 2590 Training loss: 0.02089\n",
      "Epoch: 260/300 Iteration: 2591 Training loss: 0.01645\n",
      "Epoch: 260/300 Iteration: 2592 Training loss: 0.01855\n",
      "Epoch: 260/300 Iteration: 2593 Training loss: 0.01669\n",
      "Epoch: 260/300 Iteration: 2594 Training loss: 0.01894\n",
      "Epoch: 259/300 Iteration: 2595 Validation Acc: 0.5965\n",
      "Epoch: 260/300 Iteration: 2595 Training loss: 0.01771\n",
      "Epoch: 260/300 Iteration: 2596 Training loss: 0.01459\n",
      "Epoch: 260/300 Iteration: 2597 Training loss: 0.01666\n",
      "Epoch: 260/300 Iteration: 2598 Training loss: 0.02014\n",
      "Epoch: 260/300 Iteration: 2599 Training loss: 0.01863\n",
      "Epoch: 259/300 Iteration: 2600 Validation Acc: 0.5955\n",
      "Epoch: 261/300 Iteration: 2600 Training loss: 0.02069\n",
      "Epoch: 261/300 Iteration: 2601 Training loss: 0.01630\n",
      "Epoch: 261/300 Iteration: 2602 Training loss: 0.01840\n",
      "Epoch: 261/300 Iteration: 2603 Training loss: 0.01653\n",
      "Epoch: 261/300 Iteration: 2604 Training loss: 0.01876\n",
      "Epoch: 260/300 Iteration: 2605 Validation Acc: 0.5970\n",
      "Epoch: 261/300 Iteration: 2605 Training loss: 0.01759\n",
      "Epoch: 261/300 Iteration: 2606 Training loss: 0.01445\n",
      "Epoch: 261/300 Iteration: 2607 Training loss: 0.01651\n",
      "Epoch: 261/300 Iteration: 2608 Training loss: 0.02001\n",
      "Epoch: 261/300 Iteration: 2609 Training loss: 0.01840\n",
      "Epoch: 260/300 Iteration: 2610 Validation Acc: 0.5963\n",
      "Epoch: 262/300 Iteration: 2610 Training loss: 0.02051\n",
      "Epoch: 262/300 Iteration: 2611 Training loss: 0.01610\n",
      "Epoch: 262/300 Iteration: 2612 Training loss: 0.01820\n",
      "Epoch: 262/300 Iteration: 2613 Training loss: 0.01639\n",
      "Epoch: 262/300 Iteration: 2614 Training loss: 0.01854\n",
      "Epoch: 261/300 Iteration: 2615 Validation Acc: 0.5967\n",
      "Epoch: 262/300 Iteration: 2615 Training loss: 0.01736\n",
      "Epoch: 262/300 Iteration: 2616 Training loss: 0.01422\n",
      "Epoch: 262/300 Iteration: 2617 Training loss: 0.01634\n",
      "Epoch: 262/300 Iteration: 2618 Training loss: 0.01981\n",
      "Epoch: 262/300 Iteration: 2619 Training loss: 0.01836\n",
      "Epoch: 261/300 Iteration: 2620 Validation Acc: 0.5965\n",
      "Epoch: 263/300 Iteration: 2620 Training loss: 0.02037\n",
      "Epoch: 263/300 Iteration: 2621 Training loss: 0.01598\n",
      "Epoch: 263/300 Iteration: 2622 Training loss: 0.01807\n",
      "Epoch: 263/300 Iteration: 2623 Training loss: 0.01624\n",
      "Epoch: 263/300 Iteration: 2624 Training loss: 0.01839\n",
      "Epoch: 262/300 Iteration: 2625 Validation Acc: 0.5961\n",
      "Epoch: 263/300 Iteration: 2625 Training loss: 0.01724\n",
      "Epoch: 263/300 Iteration: 2626 Training loss: 0.01416\n",
      "Epoch: 263/300 Iteration: 2627 Training loss: 0.01622\n",
      "Epoch: 263/300 Iteration: 2628 Training loss: 0.01970\n",
      "Epoch: 263/300 Iteration: 2629 Training loss: 0.01817\n",
      "Epoch: 262/300 Iteration: 2630 Validation Acc: 0.5967\n",
      "Epoch: 264/300 Iteration: 2630 Training loss: 0.02022\n",
      "Epoch: 264/300 Iteration: 2631 Training loss: 0.01583\n",
      "Epoch: 264/300 Iteration: 2632 Training loss: 0.01794\n",
      "Epoch: 264/300 Iteration: 2633 Training loss: 0.01610\n",
      "Epoch: 264/300 Iteration: 2634 Training loss: 0.01824\n",
      "Epoch: 263/300 Iteration: 2635 Validation Acc: 0.5965\n",
      "Epoch: 264/300 Iteration: 2635 Training loss: 0.01708\n",
      "Epoch: 264/300 Iteration: 2636 Training loss: 0.01402\n",
      "Epoch: 264/300 Iteration: 2637 Training loss: 0.01604\n",
      "Epoch: 264/300 Iteration: 2638 Training loss: 0.01959\n",
      "Epoch: 264/300 Iteration: 2639 Training loss: 0.01807\n",
      "Epoch: 263/300 Iteration: 2640 Validation Acc: 0.5972\n",
      "Epoch: 265/300 Iteration: 2640 Training loss: 0.02010\n",
      "Epoch: 265/300 Iteration: 2641 Training loss: 0.01568\n",
      "Epoch: 265/300 Iteration: 2642 Training loss: 0.01777\n",
      "Epoch: 265/300 Iteration: 2643 Training loss: 0.01597\n",
      "Epoch: 265/300 Iteration: 2644 Training loss: 0.01805\n",
      "Epoch: 264/300 Iteration: 2645 Validation Acc: 0.5965\n",
      "Epoch: 265/300 Iteration: 2645 Training loss: 0.01693\n",
      "Epoch: 265/300 Iteration: 2646 Training loss: 0.01388\n",
      "Epoch: 265/300 Iteration: 2647 Training loss: 0.01594\n",
      "Epoch: 265/300 Iteration: 2648 Training loss: 0.01947\n",
      "Epoch: 265/300 Iteration: 2649 Training loss: 0.01792\n",
      "Epoch: 264/300 Iteration: 2650 Validation Acc: 0.5965\n",
      "Epoch: 266/300 Iteration: 2650 Training loss: 0.01993\n",
      "Epoch: 266/300 Iteration: 2651 Training loss: 0.01557\n",
      "Epoch: 266/300 Iteration: 2652 Training loss: 0.01767\n",
      "Epoch: 266/300 Iteration: 2653 Training loss: 0.01587\n",
      "Epoch: 266/300 Iteration: 2654 Training loss: 0.01791\n",
      "Epoch: 265/300 Iteration: 2655 Validation Acc: 0.5967\n",
      "Epoch: 266/300 Iteration: 2655 Training loss: 0.01682\n",
      "Epoch: 266/300 Iteration: 2656 Training loss: 0.01376\n",
      "Epoch: 266/300 Iteration: 2657 Training loss: 0.01584\n",
      "Epoch: 266/300 Iteration: 2658 Training loss: 0.01937\n",
      "Epoch: 266/300 Iteration: 2659 Training loss: 0.01789\n",
      "Epoch: 265/300 Iteration: 2660 Validation Acc: 0.5972\n",
      "Epoch: 267/300 Iteration: 2660 Training loss: 0.01981\n",
      "Epoch: 267/300 Iteration: 2661 Training loss: 0.01546\n",
      "Epoch: 267/300 Iteration: 2662 Training loss: 0.01750\n",
      "Epoch: 267/300 Iteration: 2663 Training loss: 0.01573\n",
      "Epoch: 267/300 Iteration: 2664 Training loss: 0.01781\n",
      "Epoch: 266/300 Iteration: 2665 Validation Acc: 0.5965\n",
      "Epoch: 267/300 Iteration: 2665 Training loss: 0.01673\n",
      "Epoch: 267/300 Iteration: 2666 Training loss: 0.01367\n",
      "Epoch: 267/300 Iteration: 2667 Training loss: 0.01571\n",
      "Epoch: 267/300 Iteration: 2668 Training loss: 0.01923\n",
      "Epoch: 267/300 Iteration: 2669 Training loss: 0.01779\n",
      "Epoch: 266/300 Iteration: 2670 Validation Acc: 0.5963\n",
      "Epoch: 268/300 Iteration: 2670 Training loss: 0.01965\n",
      "Epoch: 268/300 Iteration: 2671 Training loss: 0.01534\n",
      "Epoch: 268/300 Iteration: 2672 Training loss: 0.01738\n",
      "Epoch: 268/300 Iteration: 2673 Training loss: 0.01561\n",
      "Epoch: 268/300 Iteration: 2674 Training loss: 0.01763\n",
      "Epoch: 267/300 Iteration: 2675 Validation Acc: 0.5970\n",
      "Epoch: 268/300 Iteration: 2675 Training loss: 0.01656\n",
      "Epoch: 268/300 Iteration: 2676 Training loss: 0.01355\n",
      "Epoch: 268/300 Iteration: 2677 Training loss: 0.01556\n",
      "Epoch: 268/300 Iteration: 2678 Training loss: 0.01903\n",
      "Epoch: 268/300 Iteration: 2679 Training loss: 0.01768\n",
      "Epoch: 267/300 Iteration: 2680 Validation Acc: 0.5959\n",
      "Epoch: 269/300 Iteration: 2680 Training loss: 0.01946\n",
      "Epoch: 269/300 Iteration: 2681 Training loss: 0.01516\n",
      "Epoch: 269/300 Iteration: 2682 Training loss: 0.01724\n",
      "Epoch: 269/300 Iteration: 2683 Training loss: 0.01546\n",
      "Epoch: 269/300 Iteration: 2684 Training loss: 0.01748\n",
      "Epoch: 268/300 Iteration: 2685 Validation Acc: 0.5967\n",
      "Epoch: 269/300 Iteration: 2685 Training loss: 0.01644\n",
      "Epoch: 269/300 Iteration: 2686 Training loss: 0.01348\n",
      "Epoch: 269/300 Iteration: 2687 Training loss: 0.01543\n",
      "Epoch: 269/300 Iteration: 2688 Training loss: 0.01894\n",
      "Epoch: 269/300 Iteration: 2689 Training loss: 0.01751\n",
      "Epoch: 268/300 Iteration: 2690 Validation Acc: 0.5967\n",
      "Epoch: 270/300 Iteration: 2690 Training loss: 0.01934\n",
      "Epoch: 270/300 Iteration: 2691 Training loss: 0.01507\n",
      "Epoch: 270/300 Iteration: 2692 Training loss: 0.01716\n",
      "Epoch: 270/300 Iteration: 2693 Training loss: 0.01534\n",
      "Epoch: 270/300 Iteration: 2694 Training loss: 0.01728\n",
      "Epoch: 269/300 Iteration: 2695 Validation Acc: 0.5959\n",
      "Epoch: 270/300 Iteration: 2695 Training loss: 0.01626\n",
      "Epoch: 270/300 Iteration: 2696 Training loss: 0.01334\n",
      "Epoch: 270/300 Iteration: 2697 Training loss: 0.01535\n",
      "Epoch: 270/300 Iteration: 2698 Training loss: 0.01884\n",
      "Epoch: 270/300 Iteration: 2699 Training loss: 0.01734\n",
      "Epoch: 269/300 Iteration: 2700 Validation Acc: 0.5963\n",
      "Epoch: 271/300 Iteration: 2700 Training loss: 0.01912\n",
      "Epoch: 271/300 Iteration: 2701 Training loss: 0.01490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 271/300 Iteration: 2702 Training loss: 0.01708\n",
      "Epoch: 271/300 Iteration: 2703 Training loss: 0.01529\n",
      "Epoch: 271/300 Iteration: 2704 Training loss: 0.01720\n",
      "Epoch: 270/300 Iteration: 2705 Validation Acc: 0.5967\n",
      "Epoch: 271/300 Iteration: 2705 Training loss: 0.01607\n",
      "Epoch: 271/300 Iteration: 2706 Training loss: 0.01312\n",
      "Epoch: 271/300 Iteration: 2707 Training loss: 0.01518\n",
      "Epoch: 271/300 Iteration: 2708 Training loss: 0.01879\n",
      "Epoch: 271/300 Iteration: 2709 Training loss: 0.01720\n",
      "Epoch: 270/300 Iteration: 2710 Validation Acc: 0.5963\n",
      "Epoch: 272/300 Iteration: 2710 Training loss: 0.01904\n",
      "Epoch: 272/300 Iteration: 2711 Training loss: 0.01476\n",
      "Epoch: 272/300 Iteration: 2712 Training loss: 0.01697\n",
      "Epoch: 272/300 Iteration: 2713 Training loss: 0.01518\n",
      "Epoch: 272/300 Iteration: 2714 Training loss: 0.01707\n",
      "Epoch: 271/300 Iteration: 2715 Validation Acc: 0.5967\n",
      "Epoch: 272/300 Iteration: 2715 Training loss: 0.01599\n",
      "Epoch: 272/300 Iteration: 2716 Training loss: 0.01299\n",
      "Epoch: 272/300 Iteration: 2717 Training loss: 0.01506\n",
      "Epoch: 272/300 Iteration: 2718 Training loss: 0.01860\n",
      "Epoch: 272/300 Iteration: 2719 Training loss: 0.01716\n",
      "Epoch: 271/300 Iteration: 2720 Validation Acc: 0.5972\n",
      "Epoch: 273/300 Iteration: 2720 Training loss: 0.01897\n",
      "Epoch: 273/300 Iteration: 2721 Training loss: 0.01466\n",
      "Epoch: 273/300 Iteration: 2722 Training loss: 0.01677\n",
      "Epoch: 273/300 Iteration: 2723 Training loss: 0.01503\n",
      "Epoch: 273/300 Iteration: 2724 Training loss: 0.01687\n",
      "Epoch: 272/300 Iteration: 2725 Validation Acc: 0.5974\n",
      "Epoch: 273/300 Iteration: 2725 Training loss: 0.01593\n",
      "Epoch: 273/300 Iteration: 2726 Training loss: 0.01290\n",
      "Epoch: 273/300 Iteration: 2727 Training loss: 0.01493\n",
      "Epoch: 273/300 Iteration: 2728 Training loss: 0.01845\n",
      "Epoch: 273/300 Iteration: 2729 Training loss: 0.01704\n",
      "Epoch: 272/300 Iteration: 2730 Validation Acc: 0.5974\n",
      "Epoch: 274/300 Iteration: 2730 Training loss: 0.01883\n",
      "Epoch: 274/300 Iteration: 2731 Training loss: 0.01460\n",
      "Epoch: 274/300 Iteration: 2732 Training loss: 0.01662\n",
      "Epoch: 274/300 Iteration: 2733 Training loss: 0.01486\n",
      "Epoch: 274/300 Iteration: 2734 Training loss: 0.01670\n",
      "Epoch: 273/300 Iteration: 2735 Validation Acc: 0.5970\n",
      "Epoch: 274/300 Iteration: 2735 Training loss: 0.01572\n",
      "Epoch: 274/300 Iteration: 2736 Training loss: 0.01279\n",
      "Epoch: 274/300 Iteration: 2737 Training loss: 0.01491\n",
      "Epoch: 274/300 Iteration: 2738 Training loss: 0.01829\n",
      "Epoch: 274/300 Iteration: 2739 Training loss: 0.01697\n",
      "Epoch: 273/300 Iteration: 2740 Validation Acc: 0.5974\n",
      "Epoch: 275/300 Iteration: 2740 Training loss: 0.01867\n",
      "Epoch: 275/300 Iteration: 2741 Training loss: 0.01449\n",
      "Epoch: 275/300 Iteration: 2742 Training loss: 0.01651\n",
      "Epoch: 275/300 Iteration: 2743 Training loss: 0.01474\n",
      "Epoch: 275/300 Iteration: 2744 Training loss: 0.01664\n",
      "Epoch: 274/300 Iteration: 2745 Validation Acc: 0.5972\n",
      "Epoch: 275/300 Iteration: 2745 Training loss: 0.01559\n",
      "Epoch: 275/300 Iteration: 2746 Training loss: 0.01271\n",
      "Epoch: 275/300 Iteration: 2747 Training loss: 0.01481\n",
      "Epoch: 275/300 Iteration: 2748 Training loss: 0.01788\n",
      "Epoch: 275/300 Iteration: 2749 Training loss: 0.01694\n",
      "Epoch: 274/300 Iteration: 2750 Validation Acc: 0.5974\n",
      "Epoch: 276/300 Iteration: 2750 Training loss: 0.01851\n",
      "Epoch: 276/300 Iteration: 2751 Training loss: 0.01429\n",
      "Epoch: 276/300 Iteration: 2752 Training loss: 0.01648\n",
      "Epoch: 276/300 Iteration: 2753 Training loss: 0.01471\n",
      "Epoch: 276/300 Iteration: 2754 Training loss: 0.01646\n",
      "Epoch: 275/300 Iteration: 2755 Validation Acc: 0.5976\n",
      "Epoch: 276/300 Iteration: 2755 Training loss: 0.01548\n",
      "Epoch: 276/300 Iteration: 2756 Training loss: 0.01259\n",
      "Epoch: 276/300 Iteration: 2757 Training loss: 0.01475\n",
      "Epoch: 276/300 Iteration: 2758 Training loss: 0.01767\n",
      "Epoch: 276/300 Iteration: 2759 Training loss: 0.01680\n",
      "Epoch: 275/300 Iteration: 2760 Validation Acc: 0.5967\n",
      "Epoch: 277/300 Iteration: 2760 Training loss: 0.01837\n",
      "Epoch: 277/300 Iteration: 2761 Training loss: 0.01419\n",
      "Epoch: 277/300 Iteration: 2762 Training loss: 0.01632\n",
      "Epoch: 277/300 Iteration: 2763 Training loss: 0.01459\n",
      "Epoch: 277/300 Iteration: 2764 Training loss: 0.01639\n",
      "Epoch: 276/300 Iteration: 2765 Validation Acc: 0.5974\n",
      "Epoch: 277/300 Iteration: 2765 Training loss: 0.01536\n",
      "Epoch: 277/300 Iteration: 2766 Training loss: 0.01245\n",
      "Epoch: 277/300 Iteration: 2767 Training loss: 0.01453\n",
      "Epoch: 277/300 Iteration: 2768 Training loss: 0.01750\n",
      "Epoch: 277/300 Iteration: 2769 Training loss: 0.01674\n",
      "Epoch: 276/300 Iteration: 2770 Validation Acc: 0.5972\n",
      "Epoch: 278/300 Iteration: 2770 Training loss: 0.01825\n",
      "Epoch: 278/300 Iteration: 2771 Training loss: 0.01408\n",
      "Epoch: 278/300 Iteration: 2772 Training loss: 0.01616\n",
      "Epoch: 278/300 Iteration: 2773 Training loss: 0.01442\n",
      "Epoch: 278/300 Iteration: 2774 Training loss: 0.01617\n",
      "Epoch: 277/300 Iteration: 2775 Validation Acc: 0.5972\n",
      "Epoch: 278/300 Iteration: 2775 Training loss: 0.01523\n",
      "Epoch: 278/300 Iteration: 2776 Training loss: 0.01233\n",
      "Epoch: 278/300 Iteration: 2777 Training loss: 0.01440\n",
      "Epoch: 278/300 Iteration: 2778 Training loss: 0.01725\n",
      "Epoch: 278/300 Iteration: 2779 Training loss: 0.01662\n",
      "Epoch: 277/300 Iteration: 2780 Validation Acc: 0.5963\n",
      "Epoch: 279/300 Iteration: 2780 Training loss: 0.01818\n",
      "Epoch: 279/300 Iteration: 2781 Training loss: 0.01398\n",
      "Epoch: 279/300 Iteration: 2782 Training loss: 0.01602\n",
      "Epoch: 279/300 Iteration: 2783 Training loss: 0.01423\n",
      "Epoch: 279/300 Iteration: 2784 Training loss: 0.01603\n",
      "Epoch: 278/300 Iteration: 2785 Validation Acc: 0.5972\n",
      "Epoch: 279/300 Iteration: 2785 Training loss: 0.01508\n",
      "Epoch: 279/300 Iteration: 2786 Training loss: 0.01228\n",
      "Epoch: 279/300 Iteration: 2787 Training loss: 0.01431\n",
      "Epoch: 279/300 Iteration: 2788 Training loss: 0.01714\n",
      "Epoch: 279/300 Iteration: 2789 Training loss: 0.01645\n",
      "Epoch: 278/300 Iteration: 2790 Validation Acc: 0.5965\n",
      "Epoch: 280/300 Iteration: 2790 Training loss: 0.01803\n",
      "Epoch: 280/300 Iteration: 2791 Training loss: 0.01383\n",
      "Epoch: 280/300 Iteration: 2792 Training loss: 0.01591\n",
      "Epoch: 280/300 Iteration: 2793 Training loss: 0.01414\n",
      "Epoch: 280/300 Iteration: 2794 Training loss: 0.01592\n",
      "Epoch: 279/300 Iteration: 2795 Validation Acc: 0.5967\n",
      "Epoch: 280/300 Iteration: 2795 Training loss: 0.01493\n",
      "Epoch: 280/300 Iteration: 2796 Training loss: 0.01215\n",
      "Epoch: 280/300 Iteration: 2797 Training loss: 0.01422\n",
      "Epoch: 280/300 Iteration: 2798 Training loss: 0.01699\n",
      "Epoch: 280/300 Iteration: 2799 Training loss: 0.01639\n",
      "Epoch: 279/300 Iteration: 2800 Validation Acc: 0.5967\n",
      "Epoch: 281/300 Iteration: 2800 Training loss: 0.01790\n",
      "Epoch: 281/300 Iteration: 2801 Training loss: 0.01369\n",
      "Epoch: 281/300 Iteration: 2802 Training loss: 0.01581\n",
      "Epoch: 281/300 Iteration: 2803 Training loss: 0.01404\n",
      "Epoch: 281/300 Iteration: 2804 Training loss: 0.01581\n",
      "Epoch: 280/300 Iteration: 2805 Validation Acc: 0.5974\n",
      "Epoch: 281/300 Iteration: 2805 Training loss: 0.01483\n",
      "Epoch: 281/300 Iteration: 2806 Training loss: 0.01204\n",
      "Epoch: 281/300 Iteration: 2807 Training loss: 0.01407\n",
      "Epoch: 281/300 Iteration: 2808 Training loss: 0.01689\n",
      "Epoch: 281/300 Iteration: 2809 Training loss: 0.01618\n",
      "Epoch: 280/300 Iteration: 2810 Validation Acc: 0.5963\n",
      "Epoch: 282/300 Iteration: 2810 Training loss: 0.01771\n",
      "Epoch: 282/300 Iteration: 2811 Training loss: 0.01358\n",
      "Epoch: 282/300 Iteration: 2812 Training loss: 0.01569\n",
      "Epoch: 282/300 Iteration: 2813 Training loss: 0.01395\n",
      "Epoch: 282/300 Iteration: 2814 Training loss: 0.01562\n",
      "Epoch: 281/300 Iteration: 2815 Validation Acc: 0.5978\n",
      "Epoch: 282/300 Iteration: 2815 Training loss: 0.01465\n",
      "Epoch: 282/300 Iteration: 2816 Training loss: 0.01190\n",
      "Epoch: 282/300 Iteration: 2817 Training loss: 0.01392\n",
      "Epoch: 282/300 Iteration: 2818 Training loss: 0.01678\n",
      "Epoch: 282/300 Iteration: 2819 Training loss: 0.01607\n",
      "Epoch: 281/300 Iteration: 2820 Validation Acc: 0.5967\n",
      "Epoch: 283/300 Iteration: 2820 Training loss: 0.01754\n",
      "Epoch: 283/300 Iteration: 2821 Training loss: 0.01345\n",
      "Epoch: 283/300 Iteration: 2822 Training loss: 0.01559\n",
      "Epoch: 283/300 Iteration: 2823 Training loss: 0.01384\n",
      "Epoch: 283/300 Iteration: 2824 Training loss: 0.01548\n",
      "Epoch: 282/300 Iteration: 2825 Validation Acc: 0.5970\n",
      "Epoch: 283/300 Iteration: 2825 Training loss: 0.01454\n",
      "Epoch: 283/300 Iteration: 2826 Training loss: 0.01180\n",
      "Epoch: 283/300 Iteration: 2827 Training loss: 0.01375\n",
      "Epoch: 283/300 Iteration: 2828 Training loss: 0.01660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 283/300 Iteration: 2829 Training loss: 0.01597\n",
      "Epoch: 282/300 Iteration: 2830 Validation Acc: 0.5970\n",
      "Epoch: 284/300 Iteration: 2830 Training loss: 0.01737\n",
      "Epoch: 284/300 Iteration: 2831 Training loss: 0.01337\n",
      "Epoch: 284/300 Iteration: 2832 Training loss: 0.01548\n",
      "Epoch: 284/300 Iteration: 2833 Training loss: 0.01369\n",
      "Epoch: 284/300 Iteration: 2834 Training loss: 0.01531\n",
      "Epoch: 283/300 Iteration: 2835 Validation Acc: 0.5972\n",
      "Epoch: 284/300 Iteration: 2835 Training loss: 0.01438\n",
      "Epoch: 284/300 Iteration: 2836 Training loss: 0.01171\n",
      "Epoch: 284/300 Iteration: 2837 Training loss: 0.01368\n",
      "Epoch: 284/300 Iteration: 2838 Training loss: 0.01649\n",
      "Epoch: 284/300 Iteration: 2839 Training loss: 0.01588\n",
      "Epoch: 283/300 Iteration: 2840 Validation Acc: 0.5970\n",
      "Epoch: 285/300 Iteration: 2840 Training loss: 0.01722\n",
      "Epoch: 285/300 Iteration: 2841 Training loss: 0.01327\n",
      "Epoch: 285/300 Iteration: 2842 Training loss: 0.01535\n",
      "Epoch: 285/300 Iteration: 2843 Training loss: 0.01355\n",
      "Epoch: 285/300 Iteration: 2844 Training loss: 0.01521\n",
      "Epoch: 284/300 Iteration: 2845 Validation Acc: 0.5972\n",
      "Epoch: 285/300 Iteration: 2845 Training loss: 0.01432\n",
      "Epoch: 285/300 Iteration: 2846 Training loss: 0.01163\n",
      "Epoch: 285/300 Iteration: 2847 Training loss: 0.01357\n",
      "Epoch: 285/300 Iteration: 2848 Training loss: 0.01639\n",
      "Epoch: 285/300 Iteration: 2849 Training loss: 0.01583\n",
      "Epoch: 284/300 Iteration: 2850 Validation Acc: 0.5972\n",
      "Epoch: 286/300 Iteration: 2850 Training loss: 0.01710\n",
      "Epoch: 286/300 Iteration: 2851 Training loss: 0.01313\n",
      "Epoch: 286/300 Iteration: 2852 Training loss: 0.01527\n",
      "Epoch: 286/300 Iteration: 2853 Training loss: 0.01352\n",
      "Epoch: 286/300 Iteration: 2854 Training loss: 0.01507\n",
      "Epoch: 285/300 Iteration: 2855 Validation Acc: 0.5970\n",
      "Epoch: 286/300 Iteration: 2855 Training loss: 0.01420\n",
      "Epoch: 286/300 Iteration: 2856 Training loss: 0.01151\n",
      "Epoch: 286/300 Iteration: 2857 Training loss: 0.01351\n",
      "Epoch: 286/300 Iteration: 2858 Training loss: 0.01633\n",
      "Epoch: 286/300 Iteration: 2859 Training loss: 0.01576\n",
      "Epoch: 285/300 Iteration: 2860 Validation Acc: 0.5967\n",
      "Epoch: 287/300 Iteration: 2860 Training loss: 0.01700\n",
      "Epoch: 287/300 Iteration: 2861 Training loss: 0.01302\n",
      "Epoch: 287/300 Iteration: 2862 Training loss: 0.01521\n",
      "Epoch: 287/300 Iteration: 2863 Training loss: 0.01342\n",
      "Epoch: 287/300 Iteration: 2864 Training loss: 0.01499\n",
      "Epoch: 286/300 Iteration: 2865 Validation Acc: 0.5970\n",
      "Epoch: 287/300 Iteration: 2865 Training loss: 0.01410\n",
      "Epoch: 287/300 Iteration: 2866 Training loss: 0.01142\n",
      "Epoch: 287/300 Iteration: 2867 Training loss: 0.01338\n",
      "Epoch: 287/300 Iteration: 2868 Training loss: 0.01620\n",
      "Epoch: 287/300 Iteration: 2869 Training loss: 0.01566\n",
      "Epoch: 286/300 Iteration: 2870 Validation Acc: 0.5963\n",
      "Epoch: 288/300 Iteration: 2870 Training loss: 0.01691\n",
      "Epoch: 288/300 Iteration: 2871 Training loss: 0.01292\n",
      "Epoch: 288/300 Iteration: 2872 Training loss: 0.01510\n",
      "Epoch: 288/300 Iteration: 2873 Training loss: 0.01332\n",
      "Epoch: 288/300 Iteration: 2874 Training loss: 0.01487\n",
      "Epoch: 287/300 Iteration: 2875 Validation Acc: 0.5972\n",
      "Epoch: 288/300 Iteration: 2875 Training loss: 0.01401\n",
      "Epoch: 288/300 Iteration: 2876 Training loss: 0.01135\n",
      "Epoch: 288/300 Iteration: 2877 Training loss: 0.01327\n",
      "Epoch: 288/300 Iteration: 2878 Training loss: 0.01606\n",
      "Epoch: 288/300 Iteration: 2879 Training loss: 0.01561\n",
      "Epoch: 287/300 Iteration: 2880 Validation Acc: 0.5970\n",
      "Epoch: 289/300 Iteration: 2880 Training loss: 0.01681\n",
      "Epoch: 289/300 Iteration: 2881 Training loss: 0.01280\n",
      "Epoch: 289/300 Iteration: 2882 Training loss: 0.01496\n",
      "Epoch: 289/300 Iteration: 2883 Training loss: 0.01319\n",
      "Epoch: 289/300 Iteration: 2884 Training loss: 0.01479\n",
      "Epoch: 288/300 Iteration: 2885 Validation Acc: 0.5963\n",
      "Epoch: 289/300 Iteration: 2885 Training loss: 0.01388\n",
      "Epoch: 289/300 Iteration: 2886 Training loss: 0.01128\n",
      "Epoch: 289/300 Iteration: 2887 Training loss: 0.01317\n",
      "Epoch: 289/300 Iteration: 2888 Training loss: 0.01593\n",
      "Epoch: 289/300 Iteration: 2889 Training loss: 0.01548\n",
      "Epoch: 288/300 Iteration: 2890 Validation Acc: 0.5972\n",
      "Epoch: 290/300 Iteration: 2890 Training loss: 0.01671\n",
      "Epoch: 290/300 Iteration: 2891 Training loss: 0.01274\n",
      "Epoch: 290/300 Iteration: 2892 Training loss: 0.01490\n",
      "Epoch: 290/300 Iteration: 2893 Training loss: 0.01308\n",
      "Epoch: 290/300 Iteration: 2894 Training loss: 0.01462\n",
      "Epoch: 289/300 Iteration: 2895 Validation Acc: 0.5967\n",
      "Epoch: 290/300 Iteration: 2895 Training loss: 0.01372\n",
      "Epoch: 290/300 Iteration: 2896 Training loss: 0.01116\n",
      "Epoch: 290/300 Iteration: 2897 Training loss: 0.01313\n",
      "Epoch: 290/300 Iteration: 2898 Training loss: 0.01585\n",
      "Epoch: 290/300 Iteration: 2899 Training loss: 0.01533\n",
      "Epoch: 289/300 Iteration: 2900 Validation Acc: 0.5972\n",
      "Epoch: 291/300 Iteration: 2900 Training loss: 0.01655\n",
      "Epoch: 291/300 Iteration: 2901 Training loss: 0.01259\n",
      "Epoch: 291/300 Iteration: 2902 Training loss: 0.01483\n",
      "Epoch: 291/300 Iteration: 2903 Training loss: 0.01299\n",
      "Epoch: 291/300 Iteration: 2904 Training loss: 0.01455\n",
      "Epoch: 290/300 Iteration: 2905 Validation Acc: 0.5978\n",
      "Epoch: 291/300 Iteration: 2905 Training loss: 0.01360\n",
      "Epoch: 291/300 Iteration: 2906 Training loss: 0.01100\n",
      "Epoch: 291/300 Iteration: 2907 Training loss: 0.01298\n",
      "Epoch: 291/300 Iteration: 2908 Training loss: 0.01574\n",
      "Epoch: 291/300 Iteration: 2909 Training loss: 0.01527\n",
      "Epoch: 290/300 Iteration: 2910 Validation Acc: 0.5976\n",
      "Epoch: 292/300 Iteration: 2910 Training loss: 0.01647\n",
      "Epoch: 292/300 Iteration: 2911 Training loss: 0.01245\n",
      "Epoch: 292/300 Iteration: 2912 Training loss: 0.01467\n",
      "Epoch: 292/300 Iteration: 2913 Training loss: 0.01285\n",
      "Epoch: 292/300 Iteration: 2914 Training loss: 0.01446\n",
      "Epoch: 291/300 Iteration: 2915 Validation Acc: 0.5974\n",
      "Epoch: 292/300 Iteration: 2915 Training loss: 0.01356\n",
      "Epoch: 292/300 Iteration: 2916 Training loss: 0.01091\n",
      "Epoch: 292/300 Iteration: 2917 Training loss: 0.01287\n",
      "Epoch: 292/300 Iteration: 2918 Training loss: 0.01563\n",
      "Epoch: 292/300 Iteration: 2919 Training loss: 0.01517\n",
      "Epoch: 291/300 Iteration: 2920 Validation Acc: 0.5967\n",
      "Epoch: 293/300 Iteration: 2920 Training loss: 0.01639\n",
      "Epoch: 293/300 Iteration: 2921 Training loss: 0.01246\n",
      "Epoch: 293/300 Iteration: 2922 Training loss: 0.01463\n",
      "Epoch: 293/300 Iteration: 2923 Training loss: 0.01271\n",
      "Epoch: 293/300 Iteration: 2924 Training loss: 0.01426\n",
      "Epoch: 292/300 Iteration: 2925 Validation Acc: 0.5972\n",
      "Epoch: 293/300 Iteration: 2925 Training loss: 0.01343\n",
      "Epoch: 293/300 Iteration: 2926 Training loss: 0.01085\n",
      "Epoch: 293/300 Iteration: 2927 Training loss: 0.01287\n",
      "Epoch: 293/300 Iteration: 2928 Training loss: 0.01549\n",
      "Epoch: 293/300 Iteration: 2929 Training loss: 0.01506\n",
      "Epoch: 292/300 Iteration: 2930 Validation Acc: 0.5970\n",
      "Epoch: 294/300 Iteration: 2930 Training loss: 0.01622\n",
      "Epoch: 294/300 Iteration: 2931 Training loss: 0.01238\n",
      "Epoch: 294/300 Iteration: 2932 Training loss: 0.01457\n",
      "Epoch: 294/300 Iteration: 2933 Training loss: 0.01265\n",
      "Epoch: 294/300 Iteration: 2934 Training loss: 0.01413\n",
      "Epoch: 293/300 Iteration: 2935 Validation Acc: 0.5972\n",
      "Epoch: 294/300 Iteration: 2935 Training loss: 0.01332\n",
      "Epoch: 294/300 Iteration: 2936 Training loss: 0.01071\n",
      "Epoch: 294/300 Iteration: 2937 Training loss: 0.01274\n",
      "Epoch: 294/300 Iteration: 2938 Training loss: 0.01546\n",
      "Epoch: 294/300 Iteration: 2939 Training loss: 0.01506\n",
      "Epoch: 293/300 Iteration: 2940 Validation Acc: 0.5974\n",
      "Epoch: 295/300 Iteration: 2940 Training loss: 0.01607\n",
      "Epoch: 295/300 Iteration: 2941 Training loss: 0.01218\n",
      "Epoch: 295/300 Iteration: 2942 Training loss: 0.01440\n",
      "Epoch: 295/300 Iteration: 2943 Training loss: 0.01261\n",
      "Epoch: 295/300 Iteration: 2944 Training loss: 0.01405\n",
      "Epoch: 294/300 Iteration: 2945 Validation Acc: 0.5965\n",
      "Epoch: 295/300 Iteration: 2945 Training loss: 0.01325\n",
      "Epoch: 295/300 Iteration: 2946 Training loss: 0.01061\n",
      "Epoch: 295/300 Iteration: 2947 Training loss: 0.01254\n",
      "Epoch: 295/300 Iteration: 2948 Training loss: 0.01533\n",
      "Epoch: 295/300 Iteration: 2949 Training loss: 0.01503\n",
      "Epoch: 294/300 Iteration: 2950 Validation Acc: 0.5970\n",
      "Epoch: 296/300 Iteration: 2950 Training loss: 0.01599\n",
      "Epoch: 296/300 Iteration: 2951 Training loss: 0.01212\n",
      "Epoch: 296/300 Iteration: 2952 Training loss: 0.01432\n",
      "Epoch: 296/300 Iteration: 2953 Training loss: 0.01243\n",
      "Epoch: 296/300 Iteration: 2954 Training loss: 0.01397\n",
      "Epoch: 295/300 Iteration: 2955 Validation Acc: 0.5965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 296/300 Iteration: 2955 Training loss: 0.01322\n",
      "Epoch: 296/300 Iteration: 2956 Training loss: 0.01059\n",
      "Epoch: 296/300 Iteration: 2957 Training loss: 0.01209\n",
      "Epoch: 296/300 Iteration: 2958 Training loss: 0.01517\n",
      "Epoch: 296/300 Iteration: 2959 Training loss: 0.01499\n",
      "Epoch: 295/300 Iteration: 2960 Validation Acc: 0.5970\n",
      "Epoch: 297/300 Iteration: 2960 Training loss: 0.01590\n",
      "Epoch: 297/300 Iteration: 2961 Training loss: 0.01200\n",
      "Epoch: 297/300 Iteration: 2962 Training loss: 0.01425\n",
      "Epoch: 297/300 Iteration: 2963 Training loss: 0.01229\n",
      "Epoch: 297/300 Iteration: 2964 Training loss: 0.01381\n",
      "Epoch: 296/300 Iteration: 2965 Validation Acc: 0.5970\n",
      "Epoch: 297/300 Iteration: 2965 Training loss: 0.01310\n",
      "Epoch: 297/300 Iteration: 2966 Training loss: 0.01056\n",
      "Epoch: 297/300 Iteration: 2967 Training loss: 0.01201\n",
      "Epoch: 297/300 Iteration: 2968 Training loss: 0.01510\n",
      "Epoch: 297/300 Iteration: 2969 Training loss: 0.01477\n",
      "Epoch: 296/300 Iteration: 2970 Validation Acc: 0.5961\n",
      "Epoch: 298/300 Iteration: 2970 Training loss: 0.01575\n",
      "Epoch: 298/300 Iteration: 2971 Training loss: 0.01189\n",
      "Epoch: 298/300 Iteration: 2972 Training loss: 0.01420\n",
      "Epoch: 298/300 Iteration: 2973 Training loss: 0.01228\n",
      "Epoch: 298/300 Iteration: 2974 Training loss: 0.01375\n",
      "Epoch: 297/300 Iteration: 2975 Validation Acc: 0.5967\n",
      "Epoch: 298/300 Iteration: 2975 Training loss: 0.01293\n",
      "Epoch: 298/300 Iteration: 2976 Training loss: 0.01038\n",
      "Epoch: 298/300 Iteration: 2977 Training loss: 0.01193\n",
      "Epoch: 298/300 Iteration: 2978 Training loss: 0.01496\n",
      "Epoch: 298/300 Iteration: 2979 Training loss: 0.01470\n",
      "Epoch: 297/300 Iteration: 2980 Validation Acc: 0.5970\n",
      "Epoch: 299/300 Iteration: 2980 Training loss: 0.01564\n",
      "Epoch: 299/300 Iteration: 2981 Training loss: 0.01180\n",
      "Epoch: 299/300 Iteration: 2982 Training loss: 0.01403\n",
      "Epoch: 299/300 Iteration: 2983 Training loss: 0.01214\n",
      "Epoch: 299/300 Iteration: 2984 Training loss: 0.01362\n",
      "Epoch: 298/300 Iteration: 2985 Validation Acc: 0.5965\n",
      "Epoch: 299/300 Iteration: 2985 Training loss: 0.01285\n",
      "Epoch: 299/300 Iteration: 2986 Training loss: 0.01027\n",
      "Epoch: 299/300 Iteration: 2987 Training loss: 0.01181\n",
      "Epoch: 299/300 Iteration: 2988 Training loss: 0.01486\n",
      "Epoch: 299/300 Iteration: 2989 Training loss: 0.01459\n",
      "Epoch: 298/300 Iteration: 2990 Validation Acc: 0.5982\n",
      "Epoch: 300/300 Iteration: 2990 Training loss: 0.01553\n",
      "Epoch: 300/300 Iteration: 2991 Training loss: 0.01169\n",
      "Epoch: 300/300 Iteration: 2992 Training loss: 0.01399\n",
      "Epoch: 300/300 Iteration: 2993 Training loss: 0.01208\n",
      "Epoch: 300/300 Iteration: 2994 Training loss: 0.01352\n",
      "Epoch: 299/300 Iteration: 2995 Validation Acc: 0.5959\n",
      "Epoch: 300/300 Iteration: 2995 Training loss: 0.01274\n",
      "Epoch: 300/300 Iteration: 2996 Training loss: 0.01017\n",
      "Epoch: 300/300 Iteration: 2997 Training loss: 0.01171\n",
      "Epoch: 300/300 Iteration: 2998 Training loss: 0.01474\n",
      "Epoch: 300/300 Iteration: 2999 Training loss: 0.01456\n",
      "Epoch: 299/300 Iteration: 3000 Validation Acc: 0.5980\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "epochs = 300\n",
    "iteration = 0\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter('summaries/train', sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            summary, loss, _ = sess.run([merged, cost, optimizer], feed_dict=feed)\n",
    "            train_writer.add_summary(summary, iteration)\n",
    "            \n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x,\n",
    "                        labels_: val_y}\n",
    "                summary, val_acc = sess.run([merged, accuracy], feed_dict=feed)                \n",
    "                train_writer.add_summary(summary, iteration)\n",
    "                \n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "                \n",
    "            if iteration % 50 == 0:\n",
    "                saver.save(sess, \"checkpoints/flowers.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Below you see the test accuracy. You can also see the predictions returned for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6003\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: test_x,\n",
    "            labels_: test_y}\n",
    "    test_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, feel free to choose images and see how the trained classifier predicts the flowers in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc035381358>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc039621278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img_path = 'food_images/cid11_max2048/6/2294.jpg'\n",
    "test_img = imread(test_img_path)\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aleksas/labs/food_nutrition_classifier_tf/model/tensorflow_vgg/vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you don't have a vgg graph built\n",
    "with tf.Session() as sess:\n",
    "    input_ = tf.placeholder(tf.float32, [None, 224, 224, 3], name='input')\n",
    "    vgg = vgg16.Vgg16()\n",
    "    vgg.build(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    img = utils.load_image(test_img_path)\n",
    "    img = img.reshape((1, 224, 224, 3))\n",
    "\n",
    "    feed_dict = {input_: img}\n",
    "    code = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "        \n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: code}\n",
    "    prediction = sess.run(predicted, feed_dict=feed).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:         \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    graph = tf.get_default_graph() \n",
    "    \n",
    "    img = utils.load_image(test_img_path)\n",
    "    img = img.reshape((1, 224, 224, 3))\n",
    "    \n",
    "    image_buffer_input = graph.get_tensor_by_name('input:0')\n",
    "    \n",
    "    feed_dict = {image_buffer_input: img}\n",
    "    prediction = sess.run(predicted, feed_dict=feed_dict).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc035570ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(np.arange(len(lb.classes_)), prediction)\n",
    "_ = plt.yticks(np.arange(len(lb.classes_)), lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: test_x,\n",
    "            labels_: test_y}\n",
    "    predictions = sess.run(predicted, feed_dict=feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (predictions.shape)\n",
    "print(labels[test_idx])\n",
    "print(np.argmax(test_y, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(np.argmax(test_y, 1), np.argmax(predictions, 1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plot_confusion_matrix(cnf_matrix, classes=lb.classes_, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    #tf.train.write_graph(sess.graph_def, \"./\", \"vgg16_food_transfer_learning.pb\", False)\n",
    "    output_node_names = ['final_result', \"final_training_ops/BiasAdd\"]\n",
    "    \n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        output_node_names # The output node names are used to select the usefull nodes\n",
    "    ) \n",
    "\n",
    "    # Finally we serialize and dump the output graph to the filesystem\n",
    "    with tf.gfile.GFile(\"vgg16_food_transfer_learning.pb\", \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
